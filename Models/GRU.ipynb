{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for issue loading Utils.preprocess_util\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from Utils.preprocess_util import *\n",
    "from Utils.visualize import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 1)\n"
     ]
    }
   ],
   "source": [
    "person_train_valid = np.load('../Data/person_train_valid.npy')\n",
    "print(person_train_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(person_train_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41]\n",
      " [43]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,4,5,1,4,1,5])\n",
    "c = np.argwhere(a==4)\n",
    "\n",
    "b = np.array([11,21,41,15,11,43,13,56])\n",
    "print(b[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 22, 1000)\n",
      "(237, 22, 1000)\n",
      "Cropping trials\n",
      "(19750, 22, 500)\n",
      "After cropping:\n",
      "Training data: (19750, 22, 500)\n",
      "Training target: (19750,)\n",
      "Validation data: (9875, 22, 500)\n",
      "Validation target: (9875,)\n",
      "Test data: (6250, 22, 500)\n",
      "Test target: (6250,)\n",
      "Person train/validation: (2115,)\n",
      "Person test: (443, 1)\n",
      "\n",
      "After cropping:\n",
      "Training data: (19750, 22, 500)\n",
      "Training target: (19750,)\n",
      "Validation data: (9875, 22, 500)\n",
      "Validation target: (9875,)\n",
      "Test data: (6250, 22, 500)\n",
      "Test target: (6250,)\n",
      "Person train/validation: (2115,)\n",
      "Person test: (443, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data(person=0,crop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "X_train = X_train[indices]\n",
    "Y_train = Y_train[indices]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train[0:1000]\n",
    "Y_train_small = Y_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_valid.shape[0], X_valid.shape[0], replace=False)\n",
    "X_valid = X_valid[indices]\n",
    "Y_valid = Y_valid[indices]\n",
    "\n",
    "indices = np.random.choice(X_test.shape[0], X_test.shape[0], replace=False)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19750, 22, 500)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and targets tensor for train set\n",
    "features_train = torch.from_numpy(X_train)\n",
    "targets_train = torch.from_numpy(Y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set\n",
    "features_test = torch.from_numpy(X_test)\n",
    "targets_test = torch.from_numpy(Y_test).type(torch.LongTensor)\n",
    "\n",
    "features_valid = torch.from_numpy(X_valid)\n",
    "targets_valid = torch.from_numpy(Y_valid).type(torch.LongTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs,n_layers,droput):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.num_layers = n_layers\n",
    "        self.lstm = nn.GRU(self.n_inputs, self.n_neurons,self.num_layers) \n",
    "        self.droput = nn.Dropout(p=droput)\n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "            # (num_layers, batch_size, n_neurons)\n",
    "            return (torch.zeros(self.num_layers, self.batch_size, self.n_neurons))\n",
    "            #return torch.nn.init.xavier_uniform_((self.num_layers, self.batch_size, self.n_neurons), gain=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "            # transforms X to (n_steps, batch_size, n_inputs)\n",
    "            X = X.permute(1, 0, 2) \n",
    "            self.batch_size = X.size(1)\n",
    "            self.hidden = self.init_hidden()\n",
    "            lstm_out, self.hidden= self.lstm(X, self.hidden)\n",
    "            hidden_out =self.hidden[self.num_layers-1]\n",
    "            dropout_out = self.droput(hidden_out)\n",
    "            out = self.FC(dropout_out)\n",
    "\n",
    "            return out.view(-1, self.n_outputs) # (batch_size, n_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(features_train, targets_train)\n",
    "valid = torch.utils.data.TensorDataset(features_valid, targets_valid)\n",
    "test = torch.utils.data.TensorDataset(features_test, targets_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# pprint.pprint(test_loader.dataset.tensors[0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0719, -0.1039,  0.0046,  0.1418, -0.0374, -0.0426,  0.0073, -0.0949,\n",
      "          0.0587,  0.0172],\n",
      "        [ 0.2233, -0.0788,  0.0676,  0.0081,  0.1216,  0.0130,  0.1451, -0.1264,\n",
      "          0.3740,  0.1012],\n",
      "        [-0.1593, -0.0295, -0.0491, -0.1220, -0.0661,  0.1062, -0.0226,  0.1529,\n",
      "          0.0704,  0.2423],\n",
      "        [-0.2815, -0.0811, -0.0977,  0.0342, -0.0829,  0.0231, -0.0534,  0.0472,\n",
      "         -0.0861,  0.1302],\n",
      "        [-0.1828,  0.0939, -0.1142,  0.1718, -0.0302,  0.0251, -0.0057, -0.1583,\n",
      "         -0.0432, -0.0495],\n",
      "        [-0.1070, -0.1643,  0.0447,  0.0151,  0.0173, -0.0335, -0.0579,  0.0302,\n",
      "          0.0791,  0.0939],\n",
      "        [-0.1947, -0.0358, -0.2088,  0.2290,  0.0779,  0.0079, -0.0959, -0.1161,\n",
      "         -0.0375, -0.1907],\n",
      "        [-0.3672,  0.0984, -0.2005, -0.1235, -0.3256, -0.0364, -0.1644,  0.1563,\n",
      "         -0.2663,  0.2715],\n",
      "        [-0.1116, -0.1666, -0.0188,  0.0682,  0.0011, -0.0802,  0.0728,  0.0167,\n",
      "          0.1884, -0.0537],\n",
      "        [-0.3106,  0.1043, -0.0752,  0.3587, -0.1772,  0.0241, -0.0113, -0.3092,\n",
      "         -0.3404,  0.0389]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "N_STEPS = 500\n",
    "N_INPUTS = 22\n",
    "N_NEURONS = 44\n",
    "N_OUTPUTS = 10\n",
    "N_EPOCHS = 10\n",
    "N_LAYERS = 1# This actually corresponds to how many lsts are stacked one above the other\n",
    "droput = 0\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# (batch_size, n_steps, n_inputs)\n",
    "images_modified = images.view(-1, 500, 22)\n",
    "logits = model(images_modified.float())\n",
    "print(logits[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs =  25\n",
      "n_iters =  10000\n",
      "starting training..\n",
      "starting training..\n",
      "epoch= 0\n",
      "Iteration: 1  Loss: 2.290794849395752  Train Accuracy: 32.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 2  Loss: 2.2261366844177246  Train Accuracy: 32.0 Valid Accuracy: 34.0 %\n",
      "Iteration: 3  Loss: 2.122671365737915  Train Accuracy: 38.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 4  Loss: 1.9809743165969849  Train Accuracy: 42.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 5  Loss: 1.8483697175979614  Train Accuracy: 36.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 6  Loss: 1.7019860744476318  Train Accuracy: 34.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 7  Loss: 1.4710928201675415  Train Accuracy: 36.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 8  Loss: 1.5434521436691284  Train Accuracy: 32.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 9  Loss: 1.4732770919799805  Train Accuracy: 30.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 10  Loss: 1.4128928184509277  Train Accuracy: 32.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 11  Loss: 1.4343812465667725  Train Accuracy: 34.0 Valid Accuracy: 36.0 %\n",
      "Iteration: 12  Loss: 1.4701870679855347  Train Accuracy: 28.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 13  Loss: 1.417367696762085  Train Accuracy: 40.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 14  Loss: 1.4352710247039795  Train Accuracy: 34.0 Valid Accuracy: 36.0 %\n",
      "Iteration: 15  Loss: 1.4130789041519165  Train Accuracy: 38.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 16  Loss: 1.4285029172897339  Train Accuracy: 26.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 17  Loss: 1.4236243963241577  Train Accuracy: 30.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 18  Loss: 1.4039775133132935  Train Accuracy: 34.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 19  Loss: 1.4275028705596924  Train Accuracy: 28.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 20  Loss: 1.4084954261779785  Train Accuracy: 24.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 21  Loss: 1.3857736587524414  Train Accuracy: 38.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 22  Loss: 1.4290876388549805  Train Accuracy: 30.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 23  Loss: 1.4003708362579346  Train Accuracy: 30.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 24  Loss: 1.395015001296997  Train Accuracy: 24.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 25  Loss: 1.4077354669570923  Train Accuracy: 34.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 26  Loss: 1.3936970233917236  Train Accuracy: 34.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 27  Loss: 1.379073143005371  Train Accuracy: 34.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 28  Loss: 1.3947886228561401  Train Accuracy: 28.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 29  Loss: 1.4315625429153442  Train Accuracy: 28.0 Valid Accuracy: 14.0 %\n",
      "Iteration: 30  Loss: 1.385434627532959  Train Accuracy: 42.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 31  Loss: 1.4259769916534424  Train Accuracy: 22.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 32  Loss: 1.3974255323410034  Train Accuracy: 32.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 33  Loss: 1.39241361618042  Train Accuracy: 34.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 34  Loss: 1.4018723964691162  Train Accuracy: 22.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 35  Loss: 1.4102396965026855  Train Accuracy: 26.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 36  Loss: 1.3902652263641357  Train Accuracy: 32.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 37  Loss: 1.401564121246338  Train Accuracy: 40.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 38  Loss: 1.405809760093689  Train Accuracy: 30.0 Valid Accuracy: 14.0 %\n",
      "Iteration: 39  Loss: 1.380681037902832  Train Accuracy: 32.0 Valid Accuracy: 14.0 %\n",
      "Iteration: 40  Loss: 1.400917649269104  Train Accuracy: 28.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 41  Loss: 1.424910545349121  Train Accuracy: 32.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 42  Loss: 1.4042330980300903  Train Accuracy: 30.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 43  Loss: 1.3705178499221802  Train Accuracy: 46.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 44  Loss: 1.4000996351242065  Train Accuracy: 28.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 45  Loss: 1.425930380821228  Train Accuracy: 22.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 46  Loss: 1.414415717124939  Train Accuracy: 26.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 47  Loss: 1.3749531507492065  Train Accuracy: 32.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 48  Loss: 1.3913977146148682  Train Accuracy: 34.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 49  Loss: 1.3925095796585083  Train Accuracy: 24.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 50  Loss: 1.4108772277832031  Train Accuracy: 24.0 Valid Accuracy: 38.0 %\n",
      "Iteration: 51  Loss: 1.3796764612197876  Train Accuracy: 30.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 52  Loss: 1.3675894737243652  Train Accuracy: 42.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 53  Loss: 1.3848823308944702  Train Accuracy: 32.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 54  Loss: 1.4200245141983032  Train Accuracy: 26.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 55  Loss: 1.364438533782959  Train Accuracy: 34.0 Valid Accuracy: 36.0 %\n",
      "Iteration: 56  Loss: 1.4258828163146973  Train Accuracy: 24.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 57  Loss: 1.3904250860214233  Train Accuracy: 40.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 58  Loss: 1.422397255897522  Train Accuracy: 38.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 59  Loss: 1.3952891826629639  Train Accuracy: 40.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 60  Loss: 1.403557538986206  Train Accuracy: 24.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 61  Loss: 1.3733210563659668  Train Accuracy: 34.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 62  Loss: 1.397343397140503  Train Accuracy: 38.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 63  Loss: 1.3866161108016968  Train Accuracy: 30.0 Valid Accuracy: 14.0 %\n",
      "Iteration: 64  Loss: 1.3779542446136475  Train Accuracy: 40.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 65  Loss: 1.402723789215088  Train Accuracy: 26.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 66  Loss: 1.4009597301483154  Train Accuracy: 36.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 67  Loss: 1.3957819938659668  Train Accuracy: 28.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 68  Loss: 1.3926299810409546  Train Accuracy: 26.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 69  Loss: 1.392417550086975  Train Accuracy: 18.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 70  Loss: 1.3884270191192627  Train Accuracy: 28.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 71  Loss: 1.388312816619873  Train Accuracy: 32.0 Valid Accuracy: 34.0 %\n",
      "Iteration: 72  Loss: 1.3847029209136963  Train Accuracy: 38.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 73  Loss: 1.3800225257873535  Train Accuracy: 36.0 Valid Accuracy: 36.0 %\n",
      "Iteration: 74  Loss: 1.3961071968078613  Train Accuracy: 32.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 75  Loss: 1.402931571006775  Train Accuracy: 26.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 76  Loss: 1.377180814743042  Train Accuracy: 30.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 77  Loss: 1.3908569812774658  Train Accuracy: 38.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 78  Loss: 1.3962070941925049  Train Accuracy: 32.0 Valid Accuracy: 36.0 %\n",
      "Iteration: 79  Loss: 1.4008851051330566  Train Accuracy: 26.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 80  Loss: 1.3979345560073853  Train Accuracy: 24.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 81  Loss: 1.380028247833252  Train Accuracy: 34.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 82  Loss: 1.3924705982208252  Train Accuracy: 32.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 83  Loss: 1.4104094505310059  Train Accuracy: 20.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 84  Loss: 1.3998368978500366  Train Accuracy: 30.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 85  Loss: 1.3934673070907593  Train Accuracy: 36.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 86  Loss: 1.406638741493225  Train Accuracy: 22.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 87  Loss: 1.3831393718719482  Train Accuracy: 34.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 88  Loss: 1.383468747138977  Train Accuracy: 36.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 89  Loss: 1.3927011489868164  Train Accuracy: 30.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 90  Loss: 1.3746190071105957  Train Accuracy: 36.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 91  Loss: 1.3983198404312134  Train Accuracy: 28.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 92  Loss: 1.400328516960144  Train Accuracy: 34.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 93  Loss: 1.3909956216812134  Train Accuracy: 36.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 94  Loss: 1.394614577293396  Train Accuracy: 22.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 95  Loss: 1.39219069480896  Train Accuracy: 38.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 96  Loss: 1.4044569730758667  Train Accuracy: 26.0 Valid Accuracy: 24.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 97  Loss: 1.3840237855911255  Train Accuracy: 38.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 98  Loss: 1.3922898769378662  Train Accuracy: 30.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 99  Loss: 1.3828011751174927  Train Accuracy: 36.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 100  Loss: 1.3820263147354126  Train Accuracy: 30.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 101  Loss: 1.3858752250671387  Train Accuracy: 26.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 102  Loss: 1.414750337600708  Train Accuracy: 26.0 Valid Accuracy: 36.0 %\n",
      "Iteration: 103  Loss: 1.3853780031204224  Train Accuracy: 32.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 104  Loss: 1.37367844581604  Train Accuracy: 36.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 105  Loss: 1.3724114894866943  Train Accuracy: 36.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 106  Loss: 1.3905689716339111  Train Accuracy: 24.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 107  Loss: 1.4015023708343506  Train Accuracy: 38.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 108  Loss: 1.393295407295227  Train Accuracy: 28.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 109  Loss: 1.381515383720398  Train Accuracy: 44.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 110  Loss: 1.3904379606246948  Train Accuracy: 28.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 111  Loss: 1.3578503131866455  Train Accuracy: 32.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 112  Loss: 1.3795028924942017  Train Accuracy: 30.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 113  Loss: 1.3890020847320557  Train Accuracy: 28.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 114  Loss: 1.4075268507003784  Train Accuracy: 22.0 Valid Accuracy: 34.0 %\n",
      "Iteration: 115  Loss: 1.4099037647247314  Train Accuracy: 30.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 116  Loss: 1.404734492301941  Train Accuracy: 24.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 117  Loss: 1.3853589296340942  Train Accuracy: 46.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 118  Loss: 1.3820350170135498  Train Accuracy: 30.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 119  Loss: 1.3544096946716309  Train Accuracy: 40.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 120  Loss: 1.3981316089630127  Train Accuracy: 28.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 121  Loss: 1.3895888328552246  Train Accuracy: 24.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 122  Loss: 1.3654042482376099  Train Accuracy: 34.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 123  Loss: 1.3562105894088745  Train Accuracy: 34.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 124  Loss: 1.3850159645080566  Train Accuracy: 42.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 125  Loss: 1.366348385810852  Train Accuracy: 42.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 126  Loss: 1.4219889640808105  Train Accuracy: 30.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 127  Loss: 1.3884103298187256  Train Accuracy: 32.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 128  Loss: 1.398842215538025  Train Accuracy: 24.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 129  Loss: 1.3577667474746704  Train Accuracy: 36.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 130  Loss: 1.3977301120758057  Train Accuracy: 40.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 131  Loss: 1.3770744800567627  Train Accuracy: 34.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 132  Loss: 1.371405005455017  Train Accuracy: 26.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 133  Loss: 1.379204273223877  Train Accuracy: 38.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 134  Loss: 1.371354341506958  Train Accuracy: 32.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 135  Loss: 1.4319463968276978  Train Accuracy: 20.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 136  Loss: 1.4077882766723633  Train Accuracy: 30.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 137  Loss: 1.3898108005523682  Train Accuracy: 34.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 138  Loss: 1.3705787658691406  Train Accuracy: 32.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 139  Loss: 1.369106650352478  Train Accuracy: 34.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 140  Loss: 1.3463962078094482  Train Accuracy: 38.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 141  Loss: 1.4178133010864258  Train Accuracy: 20.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 142  Loss: 1.3746522665023804  Train Accuracy: 38.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 143  Loss: 1.3928248882293701  Train Accuracy: 26.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 144  Loss: 1.3956997394561768  Train Accuracy: 32.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 145  Loss: 1.365659236907959  Train Accuracy: 44.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 146  Loss: 1.3730249404907227  Train Accuracy: 32.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 147  Loss: 1.38117253780365  Train Accuracy: 34.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 148  Loss: 1.3529475927352905  Train Accuracy: 36.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 149  Loss: 1.3761019706726074  Train Accuracy: 36.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 150  Loss: 1.3507096767425537  Train Accuracy: 36.0 Valid Accuracy: 40.0 %\n",
      "Iteration: 151  Loss: 1.4255995750427246  Train Accuracy: 24.0 Valid Accuracy: 36.0 %\n",
      "Iteration: 152  Loss: 1.4112448692321777  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 153  Loss: 1.393570065498352  Train Accuracy: 30.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 154  Loss: 1.3663750886917114  Train Accuracy: 40.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 155  Loss: 1.3835334777832031  Train Accuracy: 36.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 156  Loss: 1.3610981702804565  Train Accuracy: 30.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 157  Loss: 1.3672295808792114  Train Accuracy: 34.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 158  Loss: 1.3684823513031006  Train Accuracy: 34.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 159  Loss: 1.3686834573745728  Train Accuracy: 32.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 160  Loss: 1.3954529762268066  Train Accuracy: 38.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 161  Loss: 1.3766469955444336  Train Accuracy: 40.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 162  Loss: 1.3680680990219116  Train Accuracy: 36.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 163  Loss: 1.3606746196746826  Train Accuracy: 32.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 164  Loss: 1.3796652555465698  Train Accuracy: 32.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 165  Loss: 1.3996199369430542  Train Accuracy: 22.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 166  Loss: 1.3802779912948608  Train Accuracy: 34.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 167  Loss: 1.3455852270126343  Train Accuracy: 38.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 168  Loss: 1.3806405067443848  Train Accuracy: 32.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 169  Loss: 1.3879855871200562  Train Accuracy: 38.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 170  Loss: 1.3478237390518188  Train Accuracy: 34.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 171  Loss: 1.3910813331604004  Train Accuracy: 28.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 172  Loss: 1.405124545097351  Train Accuracy: 26.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 173  Loss: 1.3647122383117676  Train Accuracy: 34.0 Valid Accuracy: 34.0 %\n",
      "Iteration: 174  Loss: 1.3742666244506836  Train Accuracy: 28.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 175  Loss: 1.3960790634155273  Train Accuracy: 24.0 Valid Accuracy: 32.0 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-72cdf7fdaf80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0my_pred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\UCLA\\deep learning\\final_project\\eeg-Classification\\Utils\\visualize.py\u001b[0m in \u001b[0;36mget_accuracy\u001b[1;34m(ouput, target, batch_size)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m''' Obtain accuracy for training round '''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mclasses_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcorrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_predicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# corrects = (max_values[1].view(target.size()).data == target.data).sum()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "n_iters = 10000\n",
    "num_epochs = int(n_iters / (len(X_train)/batch_size))\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "# batch GD\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01,weight_decay =0,betas=(0.9, 0.999),amsgrad=False)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(),lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.1)\n",
    "\n",
    "# Create RNN\n",
    "input_dim = 22\n",
    "seq_dim = 500\n",
    "\n",
    "train_loss = []\n",
    "iterations = []\n",
    "train_acc = []\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "\n",
    "print(\"num_epochs = \", num_epochs)\n",
    "print(\"n_iters = \", n_iters)\n",
    "print(\"starting training..\")\n",
    "\n",
    "count = 0\n",
    "num_epochs = 2\n",
    "print(\"starting training..\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch=\",epoch)\n",
    "    # reset hidden states\n",
    "    \n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        train  = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden() \n",
    "                \n",
    "        # Forward propagation\n",
    "        outputs = model(train.float())\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "                    \n",
    "        #print(\"parameters===\",list(model.parameters())[0].data)\n",
    "\n",
    "        count += 1\n",
    "        train_loss.append(loss.data)\n",
    "        iterations.append(count)\n",
    "        if count % 1 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            #indices = np.random.choice(X_train.shape[0], 50, replace=False)\n",
    "            #X_train_tensor = torch.from_numpy(X_train[indices].reshape(-1, seq_dim, input_dim))\n",
    "            #y_pred_valid = model( X_valid_tensor.float())\n",
    "            #val_acc = get_accuracy(y_pred_valid, Y_valid,batch_size=X_valid.shape[0])\n",
    "            \n",
    "            y_pred_train = model( train.float())\n",
    "            train_acc = get_accuracy(y_pred_train,labels,batch_size=labels.shape[0])\n",
    "            \n",
    "            indices = np.random.choice(X_valid.shape[0], 50, replace=False)\n",
    "            \n",
    "            X_valid_tensor = torch.from_numpy(X_valid[indices].reshape(-1, seq_dim, input_dim))\n",
    "            \n",
    "            y_pred_valid = model( X_valid_tensor.float())\n",
    "            val_acc = get_accuracy(y_pred_valid, Y_valid[indices],\n",
    "            batch_size=50)\n",
    "            \n",
    "            #print('Iteration: {}  Loss: {}' .format(count, loss.data))\n",
    "\n",
    "            print('Iteration: {}  Loss: {}  Train Accuracy: {} Valid Accuracy: {} %'.format(count, loss.data,train_acc,\n",
    "                                                                                            val_acc))\n",
    "            #if(train_acc> 35 and val_acc>35):\n",
    "                #return\n",
    "            '''\n",
    "            # Iterate through test dataset\n",
    "            for signals, labels in valid_loader:\n",
    "                signals = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "                #print(signals.shape)\n",
    "                # Forward propagation\n",
    "                outputs_valid = model(signals.float())\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs_valid.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            train_loss.append(loss.data)\n",
    "            iterations.append(count)\n",
    "            train_acc.append(accuracy)\n",
    "            print('Iteration: {}  Loss: {}  Valid Accuracy: {} %'.format(count, loss.data, accuracy))\n",
    "          '''  \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "print(X_train_tensor.shape)\n",
    "y_pred_train = model( X_train_tensor.float())\n",
    "train_acc = get_accuracy(y_pred_train, Y_train,\n",
    "    batch_size=len(Y_train))\n",
    "print('train accuracy:', train_acc)\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "print(X_valid_tensor.shape)\n",
    "y_pred_valid = model( X_valid_tensor.float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid,\n",
    "    batch_size=len(Y_valid))\n",
    "print('validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(iterations,train_loss)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-82-e672ddfbaeab>, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-82-e672ddfbaeab>\"\u001b[1;36m, line \u001b[1;32m62\u001b[0m\n\u001b[1;33m    if count % 1 == 0:\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "n_iters = 1000\n",
    "num_epochs = int(n_iters / (len(X_train)/batch_size))\n",
    "\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "# batch GD\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1,weight_decay = 0, amsgrad=False)\n",
    "\n",
    "# Create RNN\n",
    "input_dim = 22\n",
    "seq_dim = 1000\n",
    "\n",
    "train_loss = []\n",
    "iterations = []\n",
    "train_acc = []\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "\n",
    "print(\"num_epochs = \", num_epochs)\n",
    "print(\"n_iters = \", n_iters)\n",
    "print(\"starting training..\")\n",
    "\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch=\",epoch)\n",
    "    # reset hidden states\n",
    "    model.hidden = model.init_hidden()\n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        train  = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        #model.hidden = model.init_hidden() \n",
    "                \n",
    "        # Forward propagation\n",
    "        outputs = model(train.float())\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "                    \n",
    "        #print(\"parameters===\",list(model.parameters())[0].data)\n",
    "\n",
    "        count += 1\n",
    "        train_loss.append(loss.data)\n",
    "        iterations.append(count\n",
    "                          \n",
    "        if count % 1 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            \n",
    "            y_pred_valid = model( X_valid_tensor.float())\n",
    "            val_acc = get_accuracy(y_pred_valid, Y_valid,batch_size=X_valid.shape[0])\n",
    "            \n",
    "            y_pred_train = model( X_train_tensor.float())\n",
    "            train_acc = get_accuracy(y_pred_train, Y_train,batch_size=X_train.shape[0])\n",
    "            \n",
    "            print('Iteration: {}  Loss: {}  Train Accuracy: {} Valid Accuracy: {} %'.format(count, loss.data,train_acc,\n",
    "                                                                                            val_acc))\n",
    "            '''\n",
    "            # Iterate through test dataset\n",
    "            for signals, labels in valid_loader:\n",
    "                signals = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "                #print(signals.shape)\n",
    "                # Forward propagation\n",
    "                outputs_valid = model(signals.float())\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs_valid.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            train_loss.append(loss.data)\n",
    "            iterations.append(count)\n",
    "            train_acc.append(accuracy)\n",
    "            print('Iteration: {}  Loss: {}  Valid Accuracy: {} %'.format(count, loss.data, accuracy))\n",
    "            '''\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 500, 22])\n",
      "validation accuracy: 23.51\n"
     ]
    }
   ],
   "source": [
    "X_valid_tensor = torch.from_numpy(X_valid[0:10000].reshape(-1, seq_dim, input_dim))\n",
    "print(X_valid_tensor.shape)\n",
    "y_pred_valid = model( X_valid_tensor.float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid[0:10000],\n",
    "    batch_size=10000)\n",
    "print('validation accuracy:', val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3290\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3291\u001b[1;33m                     \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3292\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-d8f0033a0184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_test_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_test_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m test_acc = get_accuracy(y_pred_test, Y_test,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-baf1dc696013>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mhidden_out\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.from_numpy(X_test.reshape(-1, seq_dim, input_dim))\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=X_test.shape[0])\n",
    "print('test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
