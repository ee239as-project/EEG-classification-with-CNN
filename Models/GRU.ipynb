{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for issue loading Utils.preprocess_util\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from Utils.preprocess_util import *\n",
    "from Utils.visualize import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(person_train_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41]\n",
      " [43]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,4,5,1,4,1,5])\n",
    "c = np.argwhere(a==4)\n",
    "\n",
    "b = np.array([11,21,41,15,11,43,13,56])\n",
    "print(b[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 22, 1000)\n",
      "Cropping trials\n",
      "(177125, 22, 500)\n",
      "After cropping:\n",
      "Training data: (177125, 22, 500)\n",
      "Training target: (177125,)\n",
      "Validation data: (87250, 22, 500)\n",
      "Validation target: (87250,)\n",
      "Test data: (55375, 22, 500)\n",
      "Test target: (55375,)\n",
      "Person train/validation: (2115, 1)\n",
      "Person test: (443, 1)\n",
      "\n",
      "After cropping:\n",
      "Training data: (177125, 22, 500)\n",
      "Training target: (177125,)\n",
      "Validation data: (87250, 22, 500)\n",
      "Validation target: (87250,)\n",
      "Test data: (55375, 22, 500)\n",
      "Test target: (55375,)\n",
      "Person train/validation: (2115, 1)\n",
      "Person test: (443, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data(person=None,crop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "X_train = X_train[indices]\n",
    "Y_train = Y_train[indices]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 1)\n"
     ]
    }
   ],
   "source": [
    "person_train_valid = np.load('../Data/person_train_valid.npy')\n",
    "print(person_train_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train[0:1000]\n",
    "Y_train_small = Y_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_valid.shape[0], X_valid.shape[0], replace=False)\n",
    "X_valid = X_valid[indices]\n",
    "Y_valid = Y_valid[indices]\n",
    "\n",
    "indices = np.random.choice(X_test.shape[0], X_test.shape[0], replace=False)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177125, 22, 500)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and targets tensor for train set\n",
    "features_train = torch.from_numpy(X_train)\n",
    "targets_train = torch.from_numpy(Y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set\n",
    "features_test = torch.from_numpy(X_test)\n",
    "targets_test = torch.from_numpy(Y_test).type(torch.LongTensor)\n",
    "\n",
    "features_valid = torch.from_numpy(X_valid)\n",
    "targets_valid = torch.from_numpy(Y_valid).type(torch.LongTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs,n_layers,droput):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.num_layers = n_layers\n",
    "        self.lstm = nn.GRU(self.n_inputs, self.n_neurons,self.num_layers) \n",
    "        \n",
    "        ih_size = list(self.lstm.weight_ih_l0.data.shape)\n",
    "        hh_size =list(self.lstm.weight_hh_l0.data.shape)\n",
    "        self.lstm.weight_ih_l0.data.copy_(torch.eye(ih_size[0],ih_size[1]))\n",
    "        self.lstm.weight_hh_l0.data.copy_(torch.eye(hh_size[0],hh_size[1]))\n",
    "        \n",
    "        self.lstm.bias_ih_l0.data.fill_(0)\n",
    "        self.lstm.bias_hh_l0.data.fill_(0)\n",
    "        \n",
    "        \n",
    "        self.droput = nn.Dropout(p=droput)\n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "            # (num_layers, batch_size, n_neurons)\n",
    "            return (torch.zeros(self.num_layers, self.batch_size, self.n_neurons))\n",
    "            #return torch.nn.init.xavier_uniform_((self.num_layers, self.batch_size, self.n_neurons), gain=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "            # transforms X to (n_steps, batch_size, n_inputs)\n",
    "            X = X.permute(1, 0, 2) \n",
    "            self.batch_size = X.size(1)\n",
    "            self.hidden = self.init_hidden()\n",
    "            lstm_out, self.hidden= self.lstm(X, self.hidden)\n",
    "            hidden_out =self.hidden[self.num_layers-1]\n",
    "            dropout_out = self.droput(hidden_out)\n",
    "            out = self.FC(dropout_out)\n",
    "\n",
    "            return out.view(-1, self.n_outputs) # (batch_size, n_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(features_train, targets_train)\n",
    "valid = torch.utils.data.TensorDataset(features_valid, targets_valid)\n",
    "test = torch.utils.data.TensorDataset(features_test, targets_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# pprint.pprint(test_loader.dataset.tensors[0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203],\n",
      "        [-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203],\n",
      "        [-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203],\n",
      "        [-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203],\n",
      "        [-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203],\n",
      "        [-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203],\n",
      "        [-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203],\n",
      "        [-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203],\n",
      "        [-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203],\n",
      "        [-0.0158, -0.0287, -0.0124, -0.0551, -0.0352,  0.0486, -0.0373, -0.0135,\n",
      "         -0.0146,  0.0203]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "N_STEPS = 500\n",
    "N_INPUTS = 22\n",
    "N_NEURONS = 200\n",
    "N_OUTPUTS = 10\n",
    "N_EPOCHS = 10\n",
    "N_LAYERS = 1# This actually corresponds to how many lsts are stacked one above the other\n",
    "droput = 0\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# (batch_size, n_steps, n_inputs)\n",
    "images_modified = images.view(-1, 500, 22)\n",
    "logits = model(images_modified.float())\n",
    "print(logits[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs =  28\n",
      "n_iters =  10000\n",
      "starting training..\n",
      "starting training..\n",
      "epoch= 0\n",
      "Iteration: 1  Loss: 2.3085198402404785  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 2  Loss: 2.3110010623931885  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 3  Loss: 2.311781406402588  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 4  Loss: 2.3107078075408936  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 5  Loss: 2.308931350708008  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 6  Loss: 2.309894323348999  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 7  Loss: 2.3094358444213867  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 8  Loss: 2.3119912147521973  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 9  Loss: 2.312741756439209  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 10  Loss: 2.31199049949646  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 11  Loss: 2.309495449066162  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 12  Loss: 2.3094706535339355  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 13  Loss: 2.312763214111328  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 14  Loss: 2.3108813762664795  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 15  Loss: 2.3099985122680664  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 16  Loss: 2.3127520084381104  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 17  Loss: 2.312276601791382  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 18  Loss: 2.3099989891052246  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 19  Loss: 2.310717821121216  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 20  Loss: 2.3111138343811035  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 21  Loss: 2.310561180114746  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 22  Loss: 2.309992790222168  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 23  Loss: 2.3116393089294434  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 24  Loss: 2.3097293376922607  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 25  Loss: 2.3089144229888916  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 26  Loss: 2.3109686374664307  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 27  Loss: 2.3103439807891846  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 28  Loss: 2.3119425773620605  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 29  Loss: 2.3103835582733154  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 30  Loss: 2.3086342811584473  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 31  Loss: 2.30826997756958  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 32  Loss: 2.3092551231384277  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 33  Loss: 2.30865478515625  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 34  Loss: 2.3105599880218506  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 35  Loss: 2.305130958557129  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 36  Loss: 2.3093197345733643  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 37  Loss: 2.3095526695251465  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 38  Loss: 2.3093578815460205  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 39  Loss: 2.311098575592041  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 40  Loss: 2.3094961643218994  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 41  Loss: 2.310260772705078  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 42  Loss: 2.308685779571533  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 43  Loss: 2.3086049556732178  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 44  Loss: 2.3099114894866943  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 45  Loss: 2.310030460357666  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 46  Loss: 2.3109281063079834  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 47  Loss: 2.3067092895507812  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 48  Loss: 2.3099324703216553  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 49  Loss: 2.3071391582489014  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 50  Loss: 2.3098697662353516  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 51  Loss: 2.3085012435913086  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 52  Loss: 2.3082754611968994  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 53  Loss: 2.3082997798919678  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 54  Loss: 2.3063769340515137  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 55  Loss: 2.3068439960479736  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 56  Loss: 2.308131694793701  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 57  Loss: 2.307079315185547  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 58  Loss: 2.3093254566192627  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 59  Loss: 2.3100552558898926  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 60  Loss: 2.3076765537261963  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 61  Loss: 2.306875705718994  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 62  Loss: 2.3080713748931885  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 63  Loss: 2.3095436096191406  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 64  Loss: 2.30808424949646  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 65  Loss: 2.307424545288086  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 66  Loss: 2.3062078952789307  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 67  Loss: 2.306440591812134  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 68  Loss: 2.310593843460083  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 69  Loss: 2.308875322341919  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 70  Loss: 2.3066012859344482  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 71  Loss: 2.3068313598632812  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 72  Loss: 2.3065884113311768  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 73  Loss: 2.3077783584594727  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 74  Loss: 2.307516098022461  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 75  Loss: 2.3084025382995605  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 76  Loss: 2.307785987854004  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 77  Loss: 2.308882236480713  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 78  Loss: 2.306946039199829  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 79  Loss: 2.3080296516418457  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 80  Loss: 2.3053178787231445  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 81  Loss: 2.3048746585845947  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 82  Loss: 2.307060718536377  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 83  Loss: 2.30771541595459  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 84  Loss: 2.3053979873657227  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 85  Loss: 2.3087425231933594  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 86  Loss: 2.308300495147705  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 87  Loss: 2.304425001144409  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 88  Loss: 2.3059284687042236  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 89  Loss: 2.3039157390594482  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 90  Loss: 2.3044424057006836  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 91  Loss: 2.307969093322754  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 92  Loss: 2.3069262504577637  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 93  Loss: 2.3030343055725098  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 94  Loss: 2.3050377368927  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 95  Loss: 2.3052568435668945  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 96  Loss: 2.3060712814331055  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 97  Loss: 2.305354595184326  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 98  Loss: 2.30649733543396  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 99  Loss: 2.308943271636963  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100  Loss: 2.3050100803375244  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 101  Loss: 2.3044230937957764  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 102  Loss: 2.3054287433624268  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 103  Loss: 2.3043289184570312  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 104  Loss: 2.304281711578369  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 105  Loss: 2.3040146827697754  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 106  Loss: 2.302905321121216  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 107  Loss: 2.300880193710327  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 108  Loss: 2.3035855293273926  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 109  Loss: 2.3042123317718506  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 110  Loss: 2.3032870292663574  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 111  Loss: 2.30366587638855  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 112  Loss: 2.3025312423706055  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 113  Loss: 2.3016228675842285  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 114  Loss: 2.3038196563720703  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 115  Loss: 2.3024137020111084  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 116  Loss: 2.30267333984375  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 117  Loss: 2.303191900253296  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 118  Loss: 2.302384614944458  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 119  Loss: 2.303495168685913  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 120  Loss: 2.303818941116333  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 121  Loss: 2.3013558387756348  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 122  Loss: 2.3035776615142822  Train Accuracy: 0.8 Valid Accuracy: 0.0 %\n",
      "Iteration: 123  Loss: 2.3032448291778564  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 124  Loss: 2.3029842376708984  Train Accuracy: 0.4 Valid Accuracy: 2.0 %\n",
      "Iteration: 125  Loss: 2.303853750228882  Train Accuracy: 1.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 126  Loss: 2.3022117614746094  Train Accuracy: 0.6 Valid Accuracy: 0.0 %\n",
      "Iteration: 127  Loss: 2.301795244216919  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 128  Loss: 2.298339605331421  Train Accuracy: 0.6 Valid Accuracy: 0.0 %\n",
      "Iteration: 129  Loss: 2.3032572269439697  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 130  Loss: 2.3030614852905273  Train Accuracy: 1.4 Valid Accuracy: 0.0 %\n",
      "Iteration: 131  Loss: 2.302445888519287  Train Accuracy: 0.8 Valid Accuracy: 0.0 %\n",
      "Iteration: 132  Loss: 2.3006515502929688  Train Accuracy: 0.6 Valid Accuracy: 0.0 %\n",
      "Iteration: 133  Loss: 2.30180287361145  Train Accuracy: 1.6 Valid Accuracy: 2.0 %\n",
      "Iteration: 134  Loss: 2.3023436069488525  Train Accuracy: 1.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 135  Loss: 2.301758050918579  Train Accuracy: 0.6 Valid Accuracy: 0.0 %\n",
      "Iteration: 136  Loss: 2.302030324935913  Train Accuracy: 0.2 Valid Accuracy: 2.0 %\n",
      "Iteration: 137  Loss: 2.30246901512146  Train Accuracy: 0.4 Valid Accuracy: 0.0 %\n",
      "Iteration: 138  Loss: 2.2999465465545654  Train Accuracy: 1.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 139  Loss: 2.300767183303833  Train Accuracy: 1.2 Valid Accuracy: 2.0 %\n",
      "Iteration: 140  Loss: 2.3018641471862793  Train Accuracy: 1.6 Valid Accuracy: 2.0 %\n",
      "Iteration: 141  Loss: 2.3003299236297607  Train Accuracy: 0.8 Valid Accuracy: 0.0 %\n",
      "Iteration: 142  Loss: 2.3014423847198486  Train Accuracy: 1.2 Valid Accuracy: 4.0 %\n",
      "Iteration: 143  Loss: 2.2995383739471436  Train Accuracy: 1.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 144  Loss: 2.2995026111602783  Train Accuracy: 0.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 145  Loss: 2.3002336025238037  Train Accuracy: 1.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 146  Loss: 2.302440643310547  Train Accuracy: 1.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 147  Loss: 2.3017494678497314  Train Accuracy: 2.0 Valid Accuracy: 2.0 %\n",
      "Iteration: 148  Loss: 2.3016772270202637  Train Accuracy: 0.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 149  Loss: 2.3002748489379883  Train Accuracy: 0.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 150  Loss: 2.300615072250366  Train Accuracy: 1.6 Valid Accuracy: 4.0 %\n",
      "Iteration: 151  Loss: 2.2997677326202393  Train Accuracy: 2.8 Valid Accuracy: 0.0 %\n",
      "Iteration: 152  Loss: 2.2999253273010254  Train Accuracy: 1.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 153  Loss: 2.3002331256866455  Train Accuracy: 0.8 Valid Accuracy: 0.0 %\n",
      "Iteration: 154  Loss: 2.297055721282959  Train Accuracy: 1.4 Valid Accuracy: 0.0 %\n",
      "Iteration: 155  Loss: 2.299349546432495  Train Accuracy: 1.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 156  Loss: 2.297154426574707  Train Accuracy: 2.2 Valid Accuracy: 2.0 %\n",
      "Iteration: 157  Loss: 2.2961459159851074  Train Accuracy: 3.6 Valid Accuracy: 4.0 %\n",
      "Iteration: 158  Loss: 2.298975944519043  Train Accuracy: 1.6 Valid Accuracy: 0.0 %\n",
      "Iteration: 159  Loss: 2.299356698989868  Train Accuracy: 3.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 160  Loss: 2.298597574234009  Train Accuracy: 3.0 Valid Accuracy: 2.0 %\n",
      "Iteration: 161  Loss: 2.297598361968994  Train Accuracy: 2.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 162  Loss: 2.2975645065307617  Train Accuracy: 3.8 Valid Accuracy: 0.0 %\n",
      "Iteration: 163  Loss: 2.2975690364837646  Train Accuracy: 2.4 Valid Accuracy: 4.0 %\n",
      "Iteration: 164  Loss: 2.298705577850342  Train Accuracy: 2.2 Valid Accuracy: 2.0 %\n",
      "Iteration: 165  Loss: 2.2969584465026855  Train Accuracy: 2.8 Valid Accuracy: 4.0 %\n",
      "Iteration: 166  Loss: 2.2990033626556396  Train Accuracy: 1.6 Valid Accuracy: 8.0 %\n",
      "Iteration: 167  Loss: 2.2972662448883057  Train Accuracy: 3.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 168  Loss: 2.298841953277588  Train Accuracy: 3.4 Valid Accuracy: 4.0 %\n",
      "Iteration: 169  Loss: 2.29632568359375  Train Accuracy: 2.0 Valid Accuracy: 6.0 %\n",
      "Iteration: 170  Loss: 2.2956902980804443  Train Accuracy: 4.2 Valid Accuracy: 4.0 %\n",
      "Iteration: 171  Loss: 2.298603057861328  Train Accuracy: 2.8 Valid Accuracy: 6.0 %\n",
      "Iteration: 172  Loss: 2.296046733856201  Train Accuracy: 3.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 173  Loss: 2.295353889465332  Train Accuracy: 3.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 174  Loss: 2.29830002784729  Train Accuracy: 2.6 Valid Accuracy: 0.0 %\n",
      "Iteration: 175  Loss: 2.2990386486053467  Train Accuracy: 3.0 Valid Accuracy: 2.0 %\n",
      "Iteration: 176  Loss: 2.295793056488037  Train Accuracy: 4.4 Valid Accuracy: 4.0 %\n",
      "Iteration: 177  Loss: 2.292625665664673  Train Accuracy: 4.6 Valid Accuracy: 4.0 %\n",
      "Iteration: 178  Loss: 2.2983222007751465  Train Accuracy: 4.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 179  Loss: 2.2980406284332275  Train Accuracy: 4.0 Valid Accuracy: 2.0 %\n",
      "Iteration: 180  Loss: 2.29773211479187  Train Accuracy: 2.8 Valid Accuracy: 6.0 %\n",
      "Iteration: 181  Loss: 2.295480251312256  Train Accuracy: 4.6 Valid Accuracy: 4.0 %\n",
      "Iteration: 182  Loss: 2.2954108715057373  Train Accuracy: 5.2 Valid Accuracy: 4.0 %\n",
      "Iteration: 183  Loss: 2.295893669128418  Train Accuracy: 4.6 Valid Accuracy: 4.0 %\n",
      "Iteration: 184  Loss: 2.295079231262207  Train Accuracy: 3.6 Valid Accuracy: 2.0 %\n",
      "Iteration: 185  Loss: 2.292874813079834  Train Accuracy: 6.4 Valid Accuracy: 8.0 %\n",
      "Iteration: 186  Loss: 2.2964577674865723  Train Accuracy: 3.0 Valid Accuracy: 2.0 %\n",
      "Iteration: 187  Loss: 2.2957520484924316  Train Accuracy: 4.8 Valid Accuracy: 4.0 %\n",
      "Iteration: 188  Loss: 2.294240713119507  Train Accuracy: 4.8 Valid Accuracy: 4.0 %\n",
      "Iteration: 189  Loss: 2.294620990753174  Train Accuracy: 5.6 Valid Accuracy: 4.0 %\n",
      "Iteration: 190  Loss: 2.2917609214782715  Train Accuracy: 6.2 Valid Accuracy: 8.0 %\n",
      "Iteration: 191  Loss: 2.293987274169922  Train Accuracy: 4.4 Valid Accuracy: 4.0 %\n",
      "Iteration: 192  Loss: 2.292165756225586  Train Accuracy: 6.8 Valid Accuracy: 14.0 %\n",
      "Iteration: 193  Loss: 2.2920475006103516  Train Accuracy: 7.8 Valid Accuracy: 6.0 %\n",
      "Iteration: 194  Loss: 2.2937629222869873  Train Accuracy: 5.0 Valid Accuracy: 4.0 %\n",
      "Iteration: 195  Loss: 2.2930681705474854  Train Accuracy: 4.6 Valid Accuracy: 6.0 %\n",
      "Iteration: 196  Loss: 2.29292368888855  Train Accuracy: 6.6 Valid Accuracy: 6.0 %\n",
      "Iteration: 197  Loss: 2.2932310104370117  Train Accuracy: 6.4 Valid Accuracy: 10.0 %\n",
      "Iteration: 198  Loss: 2.2943408489227295  Train Accuracy: 4.8 Valid Accuracy: 0.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 199  Loss: 2.2929599285125732  Train Accuracy: 6.0 Valid Accuracy: 6.0 %\n",
      "Iteration: 200  Loss: 2.293058156967163  Train Accuracy: 7.4 Valid Accuracy: 2.0 %\n",
      "Iteration: 201  Loss: 2.290253162384033  Train Accuracy: 8.6 Valid Accuracy: 6.0 %\n",
      "Iteration: 202  Loss: 2.2909812927246094  Train Accuracy: 6.8 Valid Accuracy: 10.0 %\n",
      "Iteration: 203  Loss: 2.290693759918213  Train Accuracy: 7.0 Valid Accuracy: 8.0 %\n",
      "Iteration: 204  Loss: 2.2894349098205566  Train Accuracy: 6.6 Valid Accuracy: 6.0 %\n",
      "Iteration: 205  Loss: 2.2902841567993164  Train Accuracy: 5.8 Valid Accuracy: 4.0 %\n",
      "Iteration: 206  Loss: 2.2906322479248047  Train Accuracy: 8.0 Valid Accuracy: 6.0 %\n",
      "Iteration: 207  Loss: 2.2901976108551025  Train Accuracy: 8.6 Valid Accuracy: 10.0 %\n",
      "Iteration: 208  Loss: 2.292163372039795  Train Accuracy: 5.4 Valid Accuracy: 10.0 %\n",
      "Iteration: 209  Loss: 2.291395425796509  Train Accuracy: 7.8 Valid Accuracy: 8.0 %\n",
      "Iteration: 210  Loss: 2.2891249656677246  Train Accuracy: 8.4 Valid Accuracy: 6.0 %\n",
      "Iteration: 211  Loss: 2.289633274078369  Train Accuracy: 9.0 Valid Accuracy: 6.0 %\n",
      "Iteration: 212  Loss: 2.2906599044799805  Train Accuracy: 9.0 Valid Accuracy: 8.0 %\n",
      "Iteration: 213  Loss: 2.2883732318878174  Train Accuracy: 10.2 Valid Accuracy: 8.0 %\n",
      "Iteration: 214  Loss: 2.290531873703003  Train Accuracy: 8.0 Valid Accuracy: 4.0 %\n",
      "Iteration: 215  Loss: 2.2914392948150635  Train Accuracy: 8.2 Valid Accuracy: 8.0 %\n",
      "Iteration: 216  Loss: 2.291010856628418  Train Accuracy: 7.4 Valid Accuracy: 8.0 %\n",
      "Iteration: 217  Loss: 2.2884976863861084  Train Accuracy: 8.6 Valid Accuracy: 8.0 %\n",
      "Iteration: 218  Loss: 2.2868032455444336  Train Accuracy: 10.2 Valid Accuracy: 2.0 %\n",
      "Iteration: 219  Loss: 2.2904317378997803  Train Accuracy: 9.4 Valid Accuracy: 14.0 %\n",
      "Iteration: 220  Loss: 2.2884531021118164  Train Accuracy: 8.4 Valid Accuracy: 12.0 %\n",
      "Iteration: 221  Loss: 2.2903831005096436  Train Accuracy: 7.8 Valid Accuracy: 8.0 %\n",
      "Iteration: 222  Loss: 2.289302349090576  Train Accuracy: 7.8 Valid Accuracy: 14.0 %\n",
      "Iteration: 223  Loss: 2.2888987064361572  Train Accuracy: 9.0 Valid Accuracy: 8.0 %\n",
      "Iteration: 224  Loss: 2.285752296447754  Train Accuracy: 11.6 Valid Accuracy: 6.0 %\n",
      "Iteration: 225  Loss: 2.286681652069092  Train Accuracy: 9.8 Valid Accuracy: 4.0 %\n",
      "Iteration: 226  Loss: 2.28483510017395  Train Accuracy: 10.0 Valid Accuracy: 4.0 %\n",
      "Iteration: 227  Loss: 2.284285306930542  Train Accuracy: 11.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 228  Loss: 2.286612033843994  Train Accuracy: 9.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 229  Loss: 2.2850258350372314  Train Accuracy: 11.2 Valid Accuracy: 6.0 %\n",
      "Iteration: 230  Loss: 2.284169912338257  Train Accuracy: 10.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 231  Loss: 2.2876622676849365  Train Accuracy: 10.6 Valid Accuracy: 12.0 %\n",
      "Iteration: 232  Loss: 2.2868435382843018  Train Accuracy: 9.0 Valid Accuracy: 2.0 %\n",
      "Iteration: 233  Loss: 2.284644603729248  Train Accuracy: 8.6 Valid Accuracy: 16.0 %\n",
      "Iteration: 234  Loss: 2.284140110015869  Train Accuracy: 9.4 Valid Accuracy: 6.0 %\n",
      "Iteration: 235  Loss: 2.2845609188079834  Train Accuracy: 10.4 Valid Accuracy: 4.0 %\n",
      "Iteration: 236  Loss: 2.2834410667419434  Train Accuracy: 10.6 Valid Accuracy: 16.0 %\n",
      "Iteration: 237  Loss: 2.2842373847961426  Train Accuracy: 12.2 Valid Accuracy: 8.0 %\n",
      "Iteration: 238  Loss: 2.283790111541748  Train Accuracy: 9.8 Valid Accuracy: 10.0 %\n",
      "Iteration: 239  Loss: 2.2846839427948  Train Accuracy: 12.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 240  Loss: 2.281663179397583  Train Accuracy: 11.0 Valid Accuracy: 4.0 %\n",
      "Iteration: 241  Loss: 2.2811214923858643  Train Accuracy: 12.6 Valid Accuracy: 6.0 %\n",
      "Iteration: 242  Loss: 2.2824597358703613  Train Accuracy: 11.4 Valid Accuracy: 14.0 %\n",
      "Iteration: 243  Loss: 2.2805004119873047  Train Accuracy: 12.6 Valid Accuracy: 12.0 %\n",
      "Iteration: 244  Loss: 2.2797417640686035  Train Accuracy: 13.8 Valid Accuracy: 4.0 %\n",
      "Iteration: 245  Loss: 2.2843198776245117  Train Accuracy: 10.0 Valid Accuracy: 6.0 %\n",
      "Iteration: 246  Loss: 2.279852867126465  Train Accuracy: 11.8 Valid Accuracy: 10.0 %\n",
      "Iteration: 247  Loss: 2.279223918914795  Train Accuracy: 13.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 248  Loss: 2.282398223876953  Train Accuracy: 10.6 Valid Accuracy: 8.0 %\n",
      "Iteration: 249  Loss: 2.2790229320526123  Train Accuracy: 14.2 Valid Accuracy: 16.0 %\n",
      "Iteration: 250  Loss: 2.282111167907715  Train Accuracy: 11.2 Valid Accuracy: 12.0 %\n",
      "Iteration: 251  Loss: 2.2809746265411377  Train Accuracy: 10.8 Valid Accuracy: 6.0 %\n",
      "Iteration: 252  Loss: 2.2796928882598877  Train Accuracy: 14.6 Valid Accuracy: 10.0 %\n",
      "Iteration: 253  Loss: 2.2803242206573486  Train Accuracy: 13.2 Valid Accuracy: 4.0 %\n",
      "Iteration: 254  Loss: 2.2798800468444824  Train Accuracy: 13.2 Valid Accuracy: 16.0 %\n",
      "Iteration: 255  Loss: 2.277604818344116  Train Accuracy: 14.8 Valid Accuracy: 10.0 %\n",
      "Iteration: 256  Loss: 2.277401924133301  Train Accuracy: 15.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 257  Loss: 2.279519557952881  Train Accuracy: 12.2 Valid Accuracy: 8.0 %\n",
      "Iteration: 258  Loss: 2.2754287719726562  Train Accuracy: 13.6 Valid Accuracy: 8.0 %\n",
      "Iteration: 259  Loss: 2.278040885925293  Train Accuracy: 15.0 Valid Accuracy: 14.0 %\n",
      "Iteration: 260  Loss: 2.273167133331299  Train Accuracy: 16.2 Valid Accuracy: 8.0 %\n",
      "Iteration: 261  Loss: 2.278320074081421  Train Accuracy: 13.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 262  Loss: 2.276644706726074  Train Accuracy: 14.6 Valid Accuracy: 12.0 %\n",
      "Iteration: 263  Loss: 2.2759017944335938  Train Accuracy: 15.2 Valid Accuracy: 10.0 %\n",
      "Iteration: 264  Loss: 2.2740206718444824  Train Accuracy: 15.4 Valid Accuracy: 8.0 %\n",
      "Iteration: 265  Loss: 2.274059534072876  Train Accuracy: 15.2 Valid Accuracy: 12.0 %\n",
      "Iteration: 266  Loss: 2.2732596397399902  Train Accuracy: 17.4 Valid Accuracy: 12.0 %\n",
      "Iteration: 267  Loss: 2.275033473968506  Train Accuracy: 14.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 268  Loss: 2.2743425369262695  Train Accuracy: 11.8 Valid Accuracy: 6.0 %\n",
      "Iteration: 269  Loss: 2.273423910140991  Train Accuracy: 15.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 270  Loss: 2.272245168685913  Train Accuracy: 16.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 271  Loss: 2.2745070457458496  Train Accuracy: 15.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 272  Loss: 2.27138090133667  Train Accuracy: 16.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 273  Loss: 2.274902582168579  Train Accuracy: 14.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 274  Loss: 2.2719168663024902  Train Accuracy: 16.4 Valid Accuracy: 18.0 %\n",
      "Iteration: 275  Loss: 2.2723746299743652  Train Accuracy: 14.8 Valid Accuracy: 14.0 %\n",
      "Iteration: 276  Loss: 2.2729973793029785  Train Accuracy: 17.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 277  Loss: 2.2670247554779053  Train Accuracy: 19.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 278  Loss: 2.2721972465515137  Train Accuracy: 15.6 Valid Accuracy: 8.0 %\n",
      "Iteration: 279  Loss: 2.270211696624756  Train Accuracy: 17.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 280  Loss: 2.270052194595337  Train Accuracy: 15.4 Valid Accuracy: 14.0 %\n",
      "Iteration: 281  Loss: 2.2679173946380615  Train Accuracy: 19.8 Valid Accuracy: 8.0 %\n",
      "Iteration: 282  Loss: 2.270317792892456  Train Accuracy: 17.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 283  Loss: 2.2693967819213867  Train Accuracy: 16.2 Valid Accuracy: 16.0 %\n",
      "Iteration: 284  Loss: 2.2645516395568848  Train Accuracy: 19.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 285  Loss: 2.2671427726745605  Train Accuracy: 18.4 Valid Accuracy: 12.0 %\n",
      "Iteration: 286  Loss: 2.266972064971924  Train Accuracy: 16.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 287  Loss: 2.2668957710266113  Train Accuracy: 19.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 288  Loss: 2.2687580585479736  Train Accuracy: 17.8 Valid Accuracy: 14.0 %\n",
      "Iteration: 289  Loss: 2.2638680934906006  Train Accuracy: 18.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 290  Loss: 2.2670810222625732  Train Accuracy: 17.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 291  Loss: 2.267270088195801  Train Accuracy: 16.8 Valid Accuracy: 12.0 %\n",
      "Iteration: 292  Loss: 2.2637267112731934  Train Accuracy: 22.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 293  Loss: 2.26151967048645  Train Accuracy: 21.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 294  Loss: 2.26273250579834  Train Accuracy: 18.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 295  Loss: 2.2597885131835938  Train Accuracy: 22.6 Valid Accuracy: 12.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 296  Loss: 2.2615718841552734  Train Accuracy: 20.4 Valid Accuracy: 18.0 %\n",
      "Iteration: 297  Loss: 2.2591164112091064  Train Accuracy: 23.2 Valid Accuracy: 16.0 %\n",
      "Iteration: 298  Loss: 2.2600510120391846  Train Accuracy: 23.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 299  Loss: 2.2552850246429443  Train Accuracy: 23.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 300  Loss: 2.259334087371826  Train Accuracy: 22.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 301  Loss: 2.2547621726989746  Train Accuracy: 21.4 Valid Accuracy: 12.0 %\n",
      "Iteration: 302  Loss: 2.254945755004883  Train Accuracy: 22.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 303  Loss: 2.2579989433288574  Train Accuracy: 22.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 304  Loss: 2.253835916519165  Train Accuracy: 24.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 305  Loss: 2.254988670349121  Train Accuracy: 21.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 306  Loss: 2.2550692558288574  Train Accuracy: 22.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 307  Loss: 2.253730297088623  Train Accuracy: 23.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 308  Loss: 2.2541353702545166  Train Accuracy: 22.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 309  Loss: 2.2540884017944336  Train Accuracy: 20.6 Valid Accuracy: 10.0 %\n",
      "Iteration: 310  Loss: 2.2502686977386475  Train Accuracy: 23.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 311  Loss: 2.253145694732666  Train Accuracy: 24.6 Valid Accuracy: 14.0 %\n",
      "Iteration: 312  Loss: 2.251349925994873  Train Accuracy: 22.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 313  Loss: 2.25203537940979  Train Accuracy: 21.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 314  Loss: 2.2469794750213623  Train Accuracy: 24.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 315  Loss: 2.2483203411102295  Train Accuracy: 21.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 316  Loss: 2.249037504196167  Train Accuracy: 22.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 317  Loss: 2.248352527618408  Train Accuracy: 21.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 318  Loss: 2.2483935356140137  Train Accuracy: 20.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 319  Loss: 2.250001907348633  Train Accuracy: 22.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 320  Loss: 2.2421176433563232  Train Accuracy: 26.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 321  Loss: 2.24487042427063  Train Accuracy: 23.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 322  Loss: 2.241847038269043  Train Accuracy: 25.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 323  Loss: 2.2466347217559814  Train Accuracy: 21.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 324  Loss: 2.2392077445983887  Train Accuracy: 22.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 325  Loss: 2.240082263946533  Train Accuracy: 22.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 326  Loss: 2.2417867183685303  Train Accuracy: 20.8 Valid Accuracy: 32.0 %\n",
      "Iteration: 327  Loss: 2.2412378787994385  Train Accuracy: 20.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 328  Loss: 2.2373838424682617  Train Accuracy: 21.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 329  Loss: 2.241579532623291  Train Accuracy: 21.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 330  Loss: 2.2366795539855957  Train Accuracy: 25.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 331  Loss: 2.2376811504364014  Train Accuracy: 24.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 332  Loss: 2.2354681491851807  Train Accuracy: 25.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 333  Loss: 2.2310898303985596  Train Accuracy: 25.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 334  Loss: 2.230808734893799  Train Accuracy: 22.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 335  Loss: 2.229978322982788  Train Accuracy: 27.2 Valid Accuracy: 30.0 %\n",
      "Iteration: 336  Loss: 2.231975555419922  Train Accuracy: 25.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 337  Loss: 2.229471445083618  Train Accuracy: 23.4 Valid Accuracy: 18.0 %\n",
      "Iteration: 338  Loss: 2.2261133193969727  Train Accuracy: 25.4 Valid Accuracy: 32.0 %\n",
      "Iteration: 339  Loss: 2.227524757385254  Train Accuracy: 21.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 340  Loss: 2.227226495742798  Train Accuracy: 22.4 Valid Accuracy: 34.0 %\n",
      "Iteration: 341  Loss: 2.2247040271759033  Train Accuracy: 23.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 342  Loss: 2.2228915691375732  Train Accuracy: 26.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 343  Loss: 2.2215328216552734  Train Accuracy: 24.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 344  Loss: 2.2204885482788086  Train Accuracy: 25.4 Valid Accuracy: 32.0 %\n",
      "Iteration: 345  Loss: 2.2189948558807373  Train Accuracy: 24.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 346  Loss: 2.219048261642456  Train Accuracy: 21.4 Valid Accuracy: 18.0 %\n",
      "Iteration: 347  Loss: 2.2147152423858643  Train Accuracy: 25.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 348  Loss: 2.2144358158111572  Train Accuracy: 21.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 349  Loss: 2.2084875106811523  Train Accuracy: 27.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 350  Loss: 2.2145369052886963  Train Accuracy: 23.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 351  Loss: 2.211033821105957  Train Accuracy: 24.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 352  Loss: 2.2095749378204346  Train Accuracy: 22.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 353  Loss: 2.2020227909088135  Train Accuracy: 26.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 354  Loss: 2.2067553997039795  Train Accuracy: 24.2 Valid Accuracy: 30.0 %\n",
      "Iteration: 355  Loss: 2.203687906265259  Train Accuracy: 26.4 Valid Accuracy: 16.0 %\n",
      "epoch= 1\n",
      "Iteration: 356  Loss: 2.1952104568481445  Train Accuracy: 29.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 357  Loss: 2.200247287750244  Train Accuracy: 24.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 358  Loss: 2.1963746547698975  Train Accuracy: 24.8 Valid Accuracy: 30.0 %\n",
      "Iteration: 359  Loss: 2.194533109664917  Train Accuracy: 27.2 Valid Accuracy: 30.0 %\n",
      "Iteration: 360  Loss: 2.191336154937744  Train Accuracy: 26.2 Valid Accuracy: 28.0 %\n",
      "Iteration: 361  Loss: 2.1867332458496094  Train Accuracy: 25.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 362  Loss: 2.1870110034942627  Train Accuracy: 23.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 363  Loss: 2.186537742614746  Train Accuracy: 25.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 364  Loss: 2.1869380474090576  Train Accuracy: 23.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 365  Loss: 2.1879591941833496  Train Accuracy: 25.4 Valid Accuracy: 30.0 %\n",
      "Iteration: 366  Loss: 2.1803576946258545  Train Accuracy: 22.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 367  Loss: 2.1700212955474854  Train Accuracy: 28.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 368  Loss: 2.1750259399414062  Train Accuracy: 24.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 369  Loss: 2.167072057723999  Train Accuracy: 24.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 370  Loss: 2.1608006954193115  Train Accuracy: 25.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 371  Loss: 2.1660079956054688  Train Accuracy: 24.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 372  Loss: 2.1620290279388428  Train Accuracy: 24.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 373  Loss: 2.1538798809051514  Train Accuracy: 26.6 Valid Accuracy: 14.0 %\n",
      "Iteration: 374  Loss: 2.1582953929901123  Train Accuracy: 23.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 375  Loss: 2.154862880706787  Train Accuracy: 25.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 376  Loss: 2.1483919620513916  Train Accuracy: 24.6 Valid Accuracy: 36.0 %\n",
      "Iteration: 377  Loss: 2.1408679485321045  Train Accuracy: 25.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 378  Loss: 2.144089460372925  Train Accuracy: 22.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 379  Loss: 2.133462905883789  Train Accuracy: 25.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 380  Loss: 2.1273062229156494  Train Accuracy: 25.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 381  Loss: 2.127098560333252  Train Accuracy: 21.6 Valid Accuracy: 16.0 %\n",
      "Iteration: 382  Loss: 2.1276865005493164  Train Accuracy: 25.8 Valid Accuracy: 30.0 %\n",
      "Iteration: 383  Loss: 2.1180672645568848  Train Accuracy: 25.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 384  Loss: 2.107937812805176  Train Accuracy: 24.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 385  Loss: 2.1033921241760254  Train Accuracy: 26.0 Valid Accuracy: 34.0 %\n",
      "Iteration: 386  Loss: 2.0921807289123535  Train Accuracy: 26.4 Valid Accuracy: 30.0 %\n",
      "Iteration: 387  Loss: 2.0895795822143555  Train Accuracy: 24.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 388  Loss: 2.0641608238220215  Train Accuracy: 23.8 Valid Accuracy: 32.0 %\n",
      "Iteration: 389  Loss: 2.0467727184295654  Train Accuracy: 27.6 Valid Accuracy: 32.0 %\n",
      "Iteration: 390  Loss: 2.030331611633301  Train Accuracy: 27.2 Valid Accuracy: 32.0 %\n",
      "Iteration: 391  Loss: 2.0093655586242676  Train Accuracy: 22.0 Valid Accuracy: 22.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 392  Loss: 1.978993535041809  Train Accuracy: 26.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 393  Loss: 1.9552597999572754  Train Accuracy: 22.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 394  Loss: 1.9335296154022217  Train Accuracy: 20.4 Valid Accuracy: 16.0 %\n",
      "Iteration: 395  Loss: 1.90555739402771  Train Accuracy: 24.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 396  Loss: 1.8694002628326416  Train Accuracy: 24.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 397  Loss: 1.8128612041473389  Train Accuracy: 23.8 Valid Accuracy: 34.0 %\n",
      "Iteration: 398  Loss: 1.8413532972335815  Train Accuracy: 23.4 Valid Accuracy: 36.0 %\n",
      "Iteration: 399  Loss: 1.792953372001648  Train Accuracy: 24.6 Valid Accuracy: 32.0 %\n",
      "Iteration: 400  Loss: 1.7501319646835327  Train Accuracy: 23.2 Valid Accuracy: 48.0 %\n",
      "Iteration: 401  Loss: 1.6933071613311768  Train Accuracy: 25.4 Valid Accuracy: 34.0 %\n",
      "Iteration: 402  Loss: 1.6862759590148926  Train Accuracy: 29.8 Valid Accuracy: 36.0 %\n",
      "Iteration: 403  Loss: 1.6595938205718994  Train Accuracy: 23.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 404  Loss: 1.6808018684387207  Train Accuracy: 26.6 Valid Accuracy: 40.0 %\n",
      "Iteration: 405  Loss: 1.6054495573043823  Train Accuracy: 23.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 406  Loss: 1.6144542694091797  Train Accuracy: 24.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 407  Loss: 1.576612114906311  Train Accuracy: 28.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 408  Loss: 1.5880969762802124  Train Accuracy: 25.4 Valid Accuracy: 30.0 %\n",
      "Iteration: 409  Loss: 1.5282824039459229  Train Accuracy: 27.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 410  Loss: 1.5512261390686035  Train Accuracy: 27.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 411  Loss: 1.5272881984710693  Train Accuracy: 25.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 412  Loss: 1.519957184791565  Train Accuracy: 27.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 413  Loss: 1.5102351903915405  Train Accuracy: 24.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 414  Loss: 1.5325030088424683  Train Accuracy: 23.4 Valid Accuracy: 34.0 %\n",
      "Iteration: 415  Loss: 1.5219078063964844  Train Accuracy: 24.2 Valid Accuracy: 30.0 %\n",
      "Iteration: 416  Loss: 1.4872535467147827  Train Accuracy: 25.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 417  Loss: 1.5060334205627441  Train Accuracy: 22.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 418  Loss: 1.4930886030197144  Train Accuracy: 21.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 419  Loss: 1.4794034957885742  Train Accuracy: 24.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 420  Loss: 1.4796466827392578  Train Accuracy: 24.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 421  Loss: 1.4762029647827148  Train Accuracy: 25.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 422  Loss: 1.4692238569259644  Train Accuracy: 26.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 423  Loss: 1.4637064933776855  Train Accuracy: 22.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 424  Loss: 1.4662007093429565  Train Accuracy: 22.2 Valid Accuracy: 28.0 %\n",
      "Iteration: 425  Loss: 1.4851378202438354  Train Accuracy: 22.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 426  Loss: 1.4625705480575562  Train Accuracy: 22.4 Valid Accuracy: 38.0 %\n",
      "Iteration: 427  Loss: 1.479852557182312  Train Accuracy: 23.2 Valid Accuracy: 28.0 %\n",
      "Iteration: 428  Loss: 1.468794822692871  Train Accuracy: 23.2 Valid Accuracy: 42.0 %\n",
      "Iteration: 429  Loss: 1.4554693698883057  Train Accuracy: 24.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 430  Loss: 1.4509997367858887  Train Accuracy: 23.8 Valid Accuracy: 32.0 %\n",
      "Iteration: 431  Loss: 1.4343477487564087  Train Accuracy: 26.0 Valid Accuracy: 40.0 %\n",
      "Iteration: 432  Loss: 1.4451731443405151  Train Accuracy: 22.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 433  Loss: 1.4489541053771973  Train Accuracy: 27.8 Valid Accuracy: 30.0 %\n",
      "Iteration: 434  Loss: 1.43474543094635  Train Accuracy: 25.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 435  Loss: 1.4318310022354126  Train Accuracy: 25.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 436  Loss: 1.425148367881775  Train Accuracy: 26.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 437  Loss: 1.4322680234909058  Train Accuracy: 25.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 438  Loss: 1.4345808029174805  Train Accuracy: 23.4 Valid Accuracy: 30.0 %\n",
      "Iteration: 439  Loss: 1.4301646947860718  Train Accuracy: 25.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 440  Loss: 1.4300181865692139  Train Accuracy: 22.8 Valid Accuracy: 38.0 %\n",
      "Iteration: 441  Loss: 1.4317070245742798  Train Accuracy: 23.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 442  Loss: 1.430176019668579  Train Accuracy: 26.4 Valid Accuracy: 40.0 %\n",
      "Iteration: 443  Loss: 1.425879955291748  Train Accuracy: 25.0 Valid Accuracy: 38.0 %\n",
      "Iteration: 444  Loss: 1.4137481451034546  Train Accuracy: 26.6 Valid Accuracy: 38.0 %\n",
      "Iteration: 445  Loss: 1.4379454851150513  Train Accuracy: 24.6 Valid Accuracy: 44.0 %\n",
      "Iteration: 446  Loss: 1.430932641029358  Train Accuracy: 25.4 Valid Accuracy: 18.0 %\n",
      "Iteration: 447  Loss: 1.4256219863891602  Train Accuracy: 22.8 Valid Accuracy: 34.0 %\n",
      "Iteration: 448  Loss: 1.420982837677002  Train Accuracy: 25.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 449  Loss: 1.4230180978775024  Train Accuracy: 21.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 450  Loss: 1.4158679246902466  Train Accuracy: 25.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 451  Loss: 1.4276819229125977  Train Accuracy: 20.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 452  Loss: 1.410740613937378  Train Accuracy: 23.8 Valid Accuracy: 34.0 %\n",
      "Iteration: 453  Loss: 1.4139024019241333  Train Accuracy: 26.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 454  Loss: 1.4247771501541138  Train Accuracy: 19.4 Valid Accuracy: 32.0 %\n",
      "Iteration: 455  Loss: 1.4227278232574463  Train Accuracy: 23.6 Valid Accuracy: 38.0 %\n",
      "Iteration: 456  Loss: 1.4146249294281006  Train Accuracy: 27.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 457  Loss: 1.4122923612594604  Train Accuracy: 27.6 Valid Accuracy: 34.0 %\n",
      "Iteration: 458  Loss: 1.41117525100708  Train Accuracy: 27.4 Valid Accuracy: 46.0 %\n",
      "Iteration: 459  Loss: 1.413742184638977  Train Accuracy: 25.6 Valid Accuracy: 36.0 %\n",
      "Iteration: 460  Loss: 1.4142004251480103  Train Accuracy: 25.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 461  Loss: 1.40579354763031  Train Accuracy: 24.8 Valid Accuracy: 34.0 %\n",
      "Iteration: 462  Loss: 1.409339427947998  Train Accuracy: 24.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 463  Loss: 1.4005491733551025  Train Accuracy: 23.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 464  Loss: 1.4013645648956299  Train Accuracy: 24.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 465  Loss: 1.4051302671432495  Train Accuracy: 26.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 466  Loss: 1.4120560884475708  Train Accuracy: 26.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 467  Loss: 1.4015964269638062  Train Accuracy: 27.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 468  Loss: 1.409729242324829  Train Accuracy: 24.2 Valid Accuracy: 32.0 %\n",
      "Iteration: 469  Loss: 1.4140056371688843  Train Accuracy: 22.0 Valid Accuracy: 34.0 %\n",
      "Iteration: 470  Loss: 1.3985637426376343  Train Accuracy: 26.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 471  Loss: 1.4113763570785522  Train Accuracy: 21.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 472  Loss: 1.4123724699020386  Train Accuracy: 28.4 Valid Accuracy: 32.0 %\n",
      "Iteration: 473  Loss: 1.4039393663406372  Train Accuracy: 28.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 474  Loss: 1.4045543670654297  Train Accuracy: 23.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 475  Loss: 1.4075857400894165  Train Accuracy: 22.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 476  Loss: 1.4012960195541382  Train Accuracy: 25.4 Valid Accuracy: 18.0 %\n",
      "Iteration: 477  Loss: 1.4115136861801147  Train Accuracy: 26.8 Valid Accuracy: 16.0 %\n",
      "Iteration: 478  Loss: 1.4050275087356567  Train Accuracy: 26.6 Valid Accuracy: 30.0 %\n",
      "Iteration: 479  Loss: 1.412556529045105  Train Accuracy: 20.2 Valid Accuracy: 28.0 %\n",
      "Iteration: 480  Loss: 1.4086405038833618  Train Accuracy: 20.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 481  Loss: 1.4066215753555298  Train Accuracy: 26.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 482  Loss: 1.4037437438964844  Train Accuracy: 26.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 483  Loss: 1.399963140487671  Train Accuracy: 27.4 Valid Accuracy: 38.0 %\n",
      "Iteration: 484  Loss: 1.4001719951629639  Train Accuracy: 26.0 Valid Accuracy: 34.0 %\n",
      "Iteration: 485  Loss: 1.4070645570755005  Train Accuracy: 21.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 486  Loss: 1.3952686786651611  Train Accuracy: 26.8 Valid Accuracy: 32.0 %\n",
      "Iteration: 487  Loss: 1.4011493921279907  Train Accuracy: 27.4 Valid Accuracy: 28.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 488  Loss: 1.400191068649292  Train Accuracy: 23.6 Valid Accuracy: 34.0 %\n",
      "Iteration: 489  Loss: 1.4112322330474854  Train Accuracy: 25.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 490  Loss: 1.4052575826644897  Train Accuracy: 27.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 491  Loss: 1.4006534814834595  Train Accuracy: 26.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 492  Loss: 1.398046612739563  Train Accuracy: 23.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 493  Loss: 1.3976294994354248  Train Accuracy: 24.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 494  Loss: 1.40007483959198  Train Accuracy: 25.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 495  Loss: 1.398053765296936  Train Accuracy: 25.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 496  Loss: 1.3938027620315552  Train Accuracy: 27.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 497  Loss: 1.4056679010391235  Train Accuracy: 25.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 498  Loss: 1.3923934698104858  Train Accuracy: 27.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 499  Loss: 1.4007364511489868  Train Accuracy: 27.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 500  Loss: 1.4010454416275024  Train Accuracy: 27.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 501  Loss: 1.3988710641860962  Train Accuracy: 25.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 502  Loss: 1.3976595401763916  Train Accuracy: 26.2 Valid Accuracy: 30.0 %\n",
      "Iteration: 503  Loss: 1.400342583656311  Train Accuracy: 23.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 504  Loss: 1.4050849676132202  Train Accuracy: 26.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 505  Loss: 1.393991470336914  Train Accuracy: 23.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 506  Loss: 1.399505376815796  Train Accuracy: 25.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 507  Loss: 1.3972394466400146  Train Accuracy: 26.6 Valid Accuracy: 16.0 %\n",
      "Iteration: 508  Loss: 1.394278883934021  Train Accuracy: 22.8 Valid Accuracy: 16.0 %\n",
      "Iteration: 509  Loss: 1.4047634601593018  Train Accuracy: 29.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 510  Loss: 1.3992685079574585  Train Accuracy: 25.8 Valid Accuracy: 30.0 %\n",
      "Iteration: 511  Loss: 1.3928098678588867  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 512  Loss: 1.3933848142623901  Train Accuracy: 27.8 Valid Accuracy: 30.0 %\n",
      "Iteration: 513  Loss: 1.40337336063385  Train Accuracy: 23.4 Valid Accuracy: 32.0 %\n",
      "Iteration: 514  Loss: 1.3979729413986206  Train Accuracy: 25.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 515  Loss: 1.3983532190322876  Train Accuracy: 29.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 516  Loss: 1.3951921463012695  Train Accuracy: 27.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 517  Loss: 1.3978615999221802  Train Accuracy: 24.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 518  Loss: 1.3976069688796997  Train Accuracy: 23.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 519  Loss: 1.3976432085037231  Train Accuracy: 26.2 Valid Accuracy: 32.0 %\n",
      "Iteration: 520  Loss: 1.392492651939392  Train Accuracy: 28.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 521  Loss: 1.395125389099121  Train Accuracy: 25.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 522  Loss: 1.402969479560852  Train Accuracy: 26.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 523  Loss: 1.3971683979034424  Train Accuracy: 26.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 524  Loss: 1.3935189247131348  Train Accuracy: 29.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 525  Loss: 1.395977258682251  Train Accuracy: 27.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 526  Loss: 1.3967106342315674  Train Accuracy: 23.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 527  Loss: 1.3986650705337524  Train Accuracy: 26.4 Valid Accuracy: 16.0 %\n",
      "Iteration: 528  Loss: 1.394856572151184  Train Accuracy: 25.8 Valid Accuracy: 30.0 %\n",
      "Iteration: 529  Loss: 1.3970463275909424  Train Accuracy: 21.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 530  Loss: 1.4008373022079468  Train Accuracy: 23.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 531  Loss: 1.3949967622756958  Train Accuracy: 26.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 532  Loss: 1.3962336778640747  Train Accuracy: 27.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 533  Loss: 1.3962123394012451  Train Accuracy: 27.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 534  Loss: 1.3943736553192139  Train Accuracy: 24.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 535  Loss: 1.3993313312530518  Train Accuracy: 25.8 Valid Accuracy: 36.0 %\n",
      "Iteration: 536  Loss: 1.3943170309066772  Train Accuracy: 24.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 537  Loss: 1.3963825702667236  Train Accuracy: 26.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 538  Loss: 1.3933850526809692  Train Accuracy: 25.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 539  Loss: 1.4005206823349  Train Accuracy: 25.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 540  Loss: 1.3927323818206787  Train Accuracy: 31.4 Valid Accuracy: 16.0 %\n",
      "Iteration: 541  Loss: 1.3983021974563599  Train Accuracy: 21.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 542  Loss: 1.3965158462524414  Train Accuracy: 26.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 543  Loss: 1.3939045667648315  Train Accuracy: 28.6 Valid Accuracy: 36.0 %\n",
      "Iteration: 544  Loss: 1.3960517644882202  Train Accuracy: 22.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 545  Loss: 1.393463134765625  Train Accuracy: 26.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 546  Loss: 1.3931022882461548  Train Accuracy: 24.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 547  Loss: 1.3930912017822266  Train Accuracy: 28.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 548  Loss: 1.391926884651184  Train Accuracy: 26.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 549  Loss: 1.3947571516036987  Train Accuracy: 27.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 550  Loss: 1.3929904699325562  Train Accuracy: 25.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 551  Loss: 1.391778826713562  Train Accuracy: 23.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 552  Loss: 1.3902467489242554  Train Accuracy: 26.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 553  Loss: 1.3927699327468872  Train Accuracy: 21.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 554  Loss: 1.3937244415283203  Train Accuracy: 24.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 555  Loss: 1.3911799192428589  Train Accuracy: 24.4 Valid Accuracy: 16.0 %\n",
      "Iteration: 556  Loss: 1.391124963760376  Train Accuracy: 24.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 557  Loss: 1.3922843933105469  Train Accuracy: 26.2 Valid Accuracy: 34.0 %\n",
      "Iteration: 558  Loss: 1.3933954238891602  Train Accuracy: 25.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 559  Loss: 1.389120101928711  Train Accuracy: 31.2 Valid Accuracy: 12.0 %\n",
      "Iteration: 560  Loss: 1.3944751024246216  Train Accuracy: 24.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 561  Loss: 1.3926737308502197  Train Accuracy: 25.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 562  Loss: 1.3926942348480225  Train Accuracy: 27.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 563  Loss: 1.392760992050171  Train Accuracy: 24.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 564  Loss: 1.394149661064148  Train Accuracy: 26.2 Valid Accuracy: 16.0 %\n",
      "Iteration: 565  Loss: 1.3921868801116943  Train Accuracy: 26.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 566  Loss: 1.3904316425323486  Train Accuracy: 24.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 567  Loss: 1.391396403312683  Train Accuracy: 25.2 Valid Accuracy: 32.0 %\n",
      "Iteration: 568  Loss: 1.3902949094772339  Train Accuracy: 29.4 Valid Accuracy: 16.0 %\n",
      "Iteration: 569  Loss: 1.3907393217086792  Train Accuracy: 26.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 570  Loss: 1.3940134048461914  Train Accuracy: 25.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 571  Loss: 1.3922761678695679  Train Accuracy: 25.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 572  Loss: 1.3946256637573242  Train Accuracy: 25.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 573  Loss: 1.388700008392334  Train Accuracy: 27.2 Valid Accuracy: 30.0 %\n",
      "Iteration: 574  Loss: 1.3948569297790527  Train Accuracy: 24.4 Valid Accuracy: 40.0 %\n",
      "Iteration: 575  Loss: 1.393286108970642  Train Accuracy: 26.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 576  Loss: 1.396176815032959  Train Accuracy: 26.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 577  Loss: 1.391867995262146  Train Accuracy: 25.8 Valid Accuracy: 16.0 %\n",
      "Iteration: 578  Loss: 1.3950432538986206  Train Accuracy: 23.2 Valid Accuracy: 34.0 %\n",
      "Iteration: 579  Loss: 1.3897390365600586  Train Accuracy: 28.2 Valid Accuracy: 28.0 %\n",
      "Iteration: 580  Loss: 1.3897719383239746  Train Accuracy: 28.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 581  Loss: 1.3911259174346924  Train Accuracy: 27.6 Valid Accuracy: 36.0 %\n",
      "Iteration: 582  Loss: 1.3900829553604126  Train Accuracy: 28.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 583  Loss: 1.391085147857666  Train Accuracy: 29.0 Valid Accuracy: 14.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 584  Loss: 1.3919249773025513  Train Accuracy: 26.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 585  Loss: 1.3894739151000977  Train Accuracy: 26.2 Valid Accuracy: 30.0 %\n",
      "Iteration: 586  Loss: 1.3916938304901123  Train Accuracy: 24.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 587  Loss: 1.3927799463272095  Train Accuracy: 25.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 588  Loss: 1.3908547163009644  Train Accuracy: 27.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 589  Loss: 1.3896913528442383  Train Accuracy: 26.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 590  Loss: 1.3923438787460327  Train Accuracy: 26.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 591  Loss: 1.3909130096435547  Train Accuracy: 29.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 592  Loss: 1.391666293144226  Train Accuracy: 28.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 593  Loss: 1.3925888538360596  Train Accuracy: 25.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 594  Loss: 1.3890845775604248  Train Accuracy: 29.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 595  Loss: 1.393064260482788  Train Accuracy: 25.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 596  Loss: 1.3901606798171997  Train Accuracy: 27.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 597  Loss: 1.388919711112976  Train Accuracy: 26.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 598  Loss: 1.3899272680282593  Train Accuracy: 27.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 599  Loss: 1.3904340267181396  Train Accuracy: 26.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 600  Loss: 1.3911092281341553  Train Accuracy: 25.4 Valid Accuracy: 18.0 %\n",
      "Iteration: 601  Loss: 1.3896385431289673  Train Accuracy: 25.8 Valid Accuracy: 32.0 %\n",
      "Iteration: 602  Loss: 1.390182614326477  Train Accuracy: 29.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 603  Loss: 1.3927475214004517  Train Accuracy: 25.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 604  Loss: 1.3880077600479126  Train Accuracy: 28.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 605  Loss: 1.3914543390274048  Train Accuracy: 25.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 606  Loss: 1.393142580986023  Train Accuracy: 23.4 Valid Accuracy: 30.0 %\n",
      "Iteration: 607  Loss: 1.39523184299469  Train Accuracy: 26.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 608  Loss: 1.392058253288269  Train Accuracy: 26.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 609  Loss: 1.389769196510315  Train Accuracy: 27.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 610  Loss: 1.3916648626327515  Train Accuracy: 26.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 611  Loss: 1.3927825689315796  Train Accuracy: 26.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 612  Loss: 1.3908038139343262  Train Accuracy: 25.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 613  Loss: 1.3896799087524414  Train Accuracy: 26.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 614  Loss: 1.3910417556762695  Train Accuracy: 27.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 615  Loss: 1.3903446197509766  Train Accuracy: 26.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 616  Loss: 1.391843318939209  Train Accuracy: 26.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 617  Loss: 1.393161416053772  Train Accuracy: 26.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 618  Loss: 1.3924157619476318  Train Accuracy: 25.2 Valid Accuracy: 12.0 %\n",
      "Iteration: 619  Loss: 1.3919976949691772  Train Accuracy: 26.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 620  Loss: 1.3923143148422241  Train Accuracy: 26.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 621  Loss: 1.3912694454193115  Train Accuracy: 29.4 Valid Accuracy: 14.0 %\n",
      "Iteration: 622  Loss: 1.3927146196365356  Train Accuracy: 25.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 623  Loss: 1.391589879989624  Train Accuracy: 23.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 624  Loss: 1.3901959657669067  Train Accuracy: 26.2 Valid Accuracy: 44.0 %\n",
      "Iteration: 625  Loss: 1.3878014087677002  Train Accuracy: 30.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 626  Loss: 1.3901629447937012  Train Accuracy: 25.8 Valid Accuracy: 14.0 %\n",
      "Iteration: 627  Loss: 1.3885060548782349  Train Accuracy: 28.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 628  Loss: 1.3901894092559814  Train Accuracy: 25.6 Valid Accuracy: 16.0 %\n",
      "Iteration: 629  Loss: 1.3890650272369385  Train Accuracy: 28.8 Valid Accuracy: 20.0 %\n",
      "Iteration: 630  Loss: 1.3928306102752686  Train Accuracy: 25.8 Valid Accuracy: 20.0 %\n",
      "Iteration: 631  Loss: 1.3902387619018555  Train Accuracy: 26.4 Valid Accuracy: 34.0 %\n",
      "Iteration: 632  Loss: 1.3885836601257324  Train Accuracy: 28.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 633  Loss: 1.3922398090362549  Train Accuracy: 25.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 634  Loss: 1.3915517330169678  Train Accuracy: 25.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 635  Loss: 1.3915588855743408  Train Accuracy: 23.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 636  Loss: 1.3930120468139648  Train Accuracy: 23.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 637  Loss: 1.3928829431533813  Train Accuracy: 23.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 638  Loss: 1.3928172588348389  Train Accuracy: 24.6 Valid Accuracy: 16.0 %\n",
      "Iteration: 639  Loss: 1.3885204792022705  Train Accuracy: 27.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 640  Loss: 1.3906970024108887  Train Accuracy: 25.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 641  Loss: 1.390486717224121  Train Accuracy: 26.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 642  Loss: 1.3915073871612549  Train Accuracy: 27.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 643  Loss: 1.3923946619033813  Train Accuracy: 24.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 644  Loss: 1.3901147842407227  Train Accuracy: 24.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 645  Loss: 1.3910633325576782  Train Accuracy: 25.6 Valid Accuracy: 32.0 %\n",
      "Iteration: 646  Loss: 1.391220211982727  Train Accuracy: 25.2 Valid Accuracy: 8.0 %\n",
      "Iteration: 647  Loss: 1.391539216041565  Train Accuracy: 25.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 648  Loss: 1.388023018836975  Train Accuracy: 29.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 649  Loss: 1.3921376466751099  Train Accuracy: 24.2 Valid Accuracy: 32.0 %\n",
      "Iteration: 650  Loss: 1.3873538970947266  Train Accuracy: 30.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 651  Loss: 1.3916720151901245  Train Accuracy: 25.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 652  Loss: 1.3894835710525513  Train Accuracy: 28.0 Valid Accuracy: 36.0 %\n",
      "Iteration: 653  Loss: 1.3907736539840698  Train Accuracy: 26.4 Valid Accuracy: 16.0 %\n",
      "Iteration: 654  Loss: 1.389941692352295  Train Accuracy: 27.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 655  Loss: 1.3908179998397827  Train Accuracy: 25.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 656  Loss: 1.3902455568313599  Train Accuracy: 25.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 657  Loss: 1.3909515142440796  Train Accuracy: 26.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 658  Loss: 1.3920872211456299  Train Accuracy: 25.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 659  Loss: 1.3884047269821167  Train Accuracy: 26.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 660  Loss: 1.3891810178756714  Train Accuracy: 28.2 Valid Accuracy: 16.0 %\n",
      "Iteration: 661  Loss: 1.393106460571289  Train Accuracy: 23.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 662  Loss: 1.3909817934036255  Train Accuracy: 24.2 Valid Accuracy: 32.0 %\n",
      "Iteration: 663  Loss: 1.3914927244186401  Train Accuracy: 23.4 Valid Accuracy: 2.0 %\n",
      "Iteration: 664  Loss: 1.3908177614212036  Train Accuracy: 25.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 665  Loss: 1.3891454935073853  Train Accuracy: 30.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 666  Loss: 1.3898905515670776  Train Accuracy: 28.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 667  Loss: 1.3887555599212646  Train Accuracy: 28.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 668  Loss: 1.3897768259048462  Train Accuracy: 24.8 Valid Accuracy: 12.0 %\n",
      "Iteration: 669  Loss: 1.3892295360565186  Train Accuracy: 27.6 Valid Accuracy: 30.0 %\n",
      "Iteration: 670  Loss: 1.3898893594741821  Train Accuracy: 28.4 Valid Accuracy: 16.0 %\n",
      "Iteration: 671  Loss: 1.3900465965270996  Train Accuracy: 26.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 672  Loss: 1.3919832706451416  Train Accuracy: 26.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 673  Loss: 1.3882489204406738  Train Accuracy: 29.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 674  Loss: 1.3923786878585815  Train Accuracy: 23.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 675  Loss: 1.3885624408721924  Train Accuracy: 26.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 676  Loss: 1.3926180601119995  Train Accuracy: 26.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 677  Loss: 1.391118049621582  Train Accuracy: 26.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 678  Loss: 1.3930377960205078  Train Accuracy: 24.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 679  Loss: 1.3897440433502197  Train Accuracy: 26.4 Valid Accuracy: 22.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 680  Loss: 1.3894230127334595  Train Accuracy: 28.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 681  Loss: 1.3906735181808472  Train Accuracy: 28.2 Valid Accuracy: 30.0 %\n",
      "Iteration: 682  Loss: 1.3873659372329712  Train Accuracy: 31.4 Valid Accuracy: 30.0 %\n",
      "Iteration: 683  Loss: 1.3895968198776245  Train Accuracy: 24.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 684  Loss: 1.3924427032470703  Train Accuracy: 23.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 685  Loss: 1.3916263580322266  Train Accuracy: 25.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 686  Loss: 1.388693928718567  Train Accuracy: 29.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 687  Loss: 1.389968991279602  Train Accuracy: 27.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 688  Loss: 1.3903928995132446  Train Accuracy: 25.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 689  Loss: 1.3885551691055298  Train Accuracy: 30.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 690  Loss: 1.3902568817138672  Train Accuracy: 27.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 691  Loss: 1.3887687921524048  Train Accuracy: 27.4 Valid Accuracy: 18.0 %\n",
      "Iteration: 692  Loss: 1.3914011716842651  Train Accuracy: 25.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 693  Loss: 1.3908277750015259  Train Accuracy: 24.2 Valid Accuracy: 34.0 %\n",
      "Iteration: 694  Loss: 1.3881715536117554  Train Accuracy: 28.8 Valid Accuracy: 12.0 %\n",
      "Iteration: 695  Loss: 1.3926172256469727  Train Accuracy: 24.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 696  Loss: 1.390019178390503  Train Accuracy: 26.4 Valid Accuracy: 30.0 %\n",
      "Iteration: 697  Loss: 1.3881754875183105  Train Accuracy: 28.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 698  Loss: 1.3903388977050781  Train Accuracy: 27.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 699  Loss: 1.3888955116271973  Train Accuracy: 26.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 700  Loss: 1.3916687965393066  Train Accuracy: 25.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 701  Loss: 1.3896028995513916  Train Accuracy: 25.4 Valid Accuracy: 14.0 %\n",
      "Iteration: 702  Loss: 1.3910142183303833  Train Accuracy: 24.8 Valid Accuracy: 32.0 %\n",
      "Iteration: 703  Loss: 1.3939381837844849  Train Accuracy: 23.8 Valid Accuracy: 16.0 %\n",
      "Iteration: 704  Loss: 1.391633152961731  Train Accuracy: 27.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 705  Loss: 1.390575885772705  Train Accuracy: 25.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 706  Loss: 1.3908922672271729  Train Accuracy: 27.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 707  Loss: 1.392746925354004  Train Accuracy: 23.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 708  Loss: 1.3897511959075928  Train Accuracy: 27.6 Valid Accuracy: 34.0 %\n",
      "Iteration: 709  Loss: 1.3921891450881958  Train Accuracy: 26.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 710  Loss: 1.3925909996032715  Train Accuracy: 24.0 Valid Accuracy: 18.0 %\n",
      "epoch= 2\n",
      "Iteration: 711  Loss: 1.3897005319595337  Train Accuracy: 27.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 712  Loss: 1.3909574747085571  Train Accuracy: 24.8 Valid Accuracy: 32.0 %\n",
      "Iteration: 713  Loss: 1.3928149938583374  Train Accuracy: 26.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 714  Loss: 1.389914870262146  Train Accuracy: 26.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 715  Loss: 1.387351632118225  Train Accuracy: 30.0 Valid Accuracy: 14.0 %\n",
      "Iteration: 716  Loss: 1.38931143283844  Train Accuracy: 27.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 717  Loss: 1.3887618780136108  Train Accuracy: 27.2 Valid Accuracy: 14.0 %\n",
      "Iteration: 718  Loss: 1.391899585723877  Train Accuracy: 26.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 719  Loss: 1.389461874961853  Train Accuracy: 25.6 Valid Accuracy: 16.0 %\n",
      "Iteration: 720  Loss: 1.3913841247558594  Train Accuracy: 25.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 721  Loss: 1.389013409614563  Train Accuracy: 28.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 722  Loss: 1.3880946636199951  Train Accuracy: 29.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 723  Loss: 1.3896578550338745  Train Accuracy: 26.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 724  Loss: 1.3896734714508057  Train Accuracy: 27.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 725  Loss: 1.3861119747161865  Train Accuracy: 31.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 726  Loss: 1.3937731981277466  Train Accuracy: 23.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 727  Loss: 1.3914698362350464  Train Accuracy: 26.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 728  Loss: 1.3885835409164429  Train Accuracy: 26.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 729  Loss: 1.3877995014190674  Train Accuracy: 29.8 Valid Accuracy: 34.0 %\n",
      "Iteration: 730  Loss: 1.3911375999450684  Train Accuracy: 24.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 731  Loss: 1.3907225131988525  Train Accuracy: 24.2 Valid Accuracy: 14.0 %\n",
      "Iteration: 732  Loss: 1.3890612125396729  Train Accuracy: 27.8 Valid Accuracy: 16.0 %\n",
      "Iteration: 733  Loss: 1.3914051055908203  Train Accuracy: 25.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 734  Loss: 1.388810634613037  Train Accuracy: 27.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 735  Loss: 1.3920505046844482  Train Accuracy: 24.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 736  Loss: 1.3885849714279175  Train Accuracy: 28.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 737  Loss: 1.391364574432373  Train Accuracy: 25.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 738  Loss: 1.3919275999069214  Train Accuracy: 25.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 739  Loss: 1.3892780542373657  Train Accuracy: 26.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 740  Loss: 1.3893070220947266  Train Accuracy: 27.2 Valid Accuracy: 30.0 %\n",
      "Iteration: 741  Loss: 1.3899147510528564  Train Accuracy: 30.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 742  Loss: 1.3911676406860352  Train Accuracy: 25.2 Valid Accuracy: 34.0 %\n",
      "Iteration: 743  Loss: 1.3878697156906128  Train Accuracy: 28.6 Valid Accuracy: 16.0 %\n",
      "Iteration: 744  Loss: 1.3908432722091675  Train Accuracy: 24.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 745  Loss: 1.386332392692566  Train Accuracy: 30.0 Valid Accuracy: 14.0 %\n",
      "Iteration: 746  Loss: 1.3894883394241333  Train Accuracy: 27.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 747  Loss: 1.389622449874878  Train Accuracy: 26.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 748  Loss: 1.391414761543274  Train Accuracy: 27.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 749  Loss: 1.3920248746871948  Train Accuracy: 25.2 Valid Accuracy: 38.0 %\n",
      "Iteration: 750  Loss: 1.3916645050048828  Train Accuracy: 24.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 751  Loss: 1.3923578262329102  Train Accuracy: 24.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 752  Loss: 1.391154408454895  Train Accuracy: 26.4 Valid Accuracy: 30.0 %\n",
      "Iteration: 753  Loss: 1.3902132511138916  Train Accuracy: 27.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 754  Loss: 1.3919355869293213  Train Accuracy: 24.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 755  Loss: 1.3914756774902344  Train Accuracy: 23.2 Valid Accuracy: 10.0 %\n",
      "Iteration: 756  Loss: 1.391908049583435  Train Accuracy: 24.2 Valid Accuracy: 28.0 %\n",
      "Iteration: 757  Loss: 1.3878960609436035  Train Accuracy: 27.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 758  Loss: 1.3909294605255127  Train Accuracy: 25.2 Valid Accuracy: 14.0 %\n",
      "Iteration: 759  Loss: 1.3875397443771362  Train Accuracy: 27.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 760  Loss: 1.3895879983901978  Train Accuracy: 26.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 761  Loss: 1.390709400177002  Train Accuracy: 25.6 Valid Accuracy: 26.0 %\n",
      "Iteration: 762  Loss: 1.3885738849639893  Train Accuracy: 26.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 763  Loss: 1.389265775680542  Train Accuracy: 26.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 764  Loss: 1.3874799013137817  Train Accuracy: 26.8 Valid Accuracy: 16.0 %\n",
      "Iteration: 765  Loss: 1.3893988132476807  Train Accuracy: 27.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 766  Loss: 1.3884401321411133  Train Accuracy: 26.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 767  Loss: 1.3879611492156982  Train Accuracy: 25.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 768  Loss: 1.3906208276748657  Train Accuracy: 25.6 Valid Accuracy: 32.0 %\n",
      "Iteration: 769  Loss: 1.389939546585083  Train Accuracy: 25.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 770  Loss: 1.3885468244552612  Train Accuracy: 27.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 771  Loss: 1.3881522417068481  Train Accuracy: 28.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 772  Loss: 1.3885959386825562  Train Accuracy: 24.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 773  Loss: 1.3887871503829956  Train Accuracy: 28.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 774  Loss: 1.389445185661316  Train Accuracy: 27.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 775  Loss: 1.3897088766098022  Train Accuracy: 27.4 Valid Accuracy: 8.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 776  Loss: 1.3905383348464966  Train Accuracy: 26.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 777  Loss: 1.3886566162109375  Train Accuracy: 26.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 778  Loss: 1.3911185264587402  Train Accuracy: 25.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 779  Loss: 1.388664960861206  Train Accuracy: 28.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 780  Loss: 1.388736367225647  Train Accuracy: 30.2 Valid Accuracy: 32.0 %\n",
      "Iteration: 781  Loss: 1.3860292434692383  Train Accuracy: 28.8 Valid Accuracy: 20.0 %\n",
      "Iteration: 782  Loss: 1.3894920349121094  Train Accuracy: 26.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 783  Loss: 1.3905692100524902  Train Accuracy: 26.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 784  Loss: 1.3890175819396973  Train Accuracy: 26.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 785  Loss: 1.389319896697998  Train Accuracy: 25.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 786  Loss: 1.389140248298645  Train Accuracy: 24.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 787  Loss: 1.39127779006958  Train Accuracy: 25.0 Valid Accuracy: 14.0 %\n",
      "Iteration: 788  Loss: 1.3925188779830933  Train Accuracy: 24.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 789  Loss: 1.391284465789795  Train Accuracy: 24.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 790  Loss: 1.3882052898406982  Train Accuracy: 27.4 Valid Accuracy: 30.0 %\n",
      "Iteration: 791  Loss: 1.3893649578094482  Train Accuracy: 27.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 792  Loss: 1.390141248703003  Train Accuracy: 25.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 793  Loss: 1.3883309364318848  Train Accuracy: 27.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 794  Loss: 1.3881268501281738  Train Accuracy: 27.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 795  Loss: 1.389675259590149  Train Accuracy: 25.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 796  Loss: 1.3910685777664185  Train Accuracy: 24.8 Valid Accuracy: 32.0 %\n",
      "Iteration: 797  Loss: 1.388365626335144  Train Accuracy: 28.8 Valid Accuracy: 20.0 %\n",
      "Iteration: 798  Loss: 1.3885784149169922  Train Accuracy: 27.8 Valid Accuracy: 20.0 %\n",
      "Iteration: 799  Loss: 1.3876721858978271  Train Accuracy: 28.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 800  Loss: 1.3890869617462158  Train Accuracy: 27.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 801  Loss: 1.3914378881454468  Train Accuracy: 23.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 802  Loss: 1.39048171043396  Train Accuracy: 26.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 803  Loss: 1.3866080045700073  Train Accuracy: 30.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 804  Loss: 1.3867286443710327  Train Accuracy: 30.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 805  Loss: 1.3887120485305786  Train Accuracy: 28.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 806  Loss: 1.388093113899231  Train Accuracy: 30.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 807  Loss: 1.386965036392212  Train Accuracy: 27.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 808  Loss: 1.391910195350647  Train Accuracy: 21.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 809  Loss: 1.3894902467727661  Train Accuracy: 25.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 810  Loss: 1.3894641399383545  Train Accuracy: 27.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 811  Loss: 1.3904112577438354  Train Accuracy: 25.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 812  Loss: 1.3898078203201294  Train Accuracy: 26.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 813  Loss: 1.390849232673645  Train Accuracy: 26.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 814  Loss: 1.3893637657165527  Train Accuracy: 25.2 Valid Accuracy: 12.0 %\n",
      "Iteration: 815  Loss: 1.3893229961395264  Train Accuracy: 26.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 816  Loss: 1.3868732452392578  Train Accuracy: 29.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 817  Loss: 1.385005235671997  Train Accuracy: 30.6 Valid Accuracy: 32.0 %\n",
      "Iteration: 818  Loss: 1.3869398832321167  Train Accuracy: 28.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 819  Loss: 1.3873826265335083  Train Accuracy: 27.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 820  Loss: 1.3890804052352905  Train Accuracy: 27.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 821  Loss: 1.3902168273925781  Train Accuracy: 26.4 Valid Accuracy: 14.0 %\n",
      "Iteration: 822  Loss: 1.3884388208389282  Train Accuracy: 28.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 823  Loss: 1.3878724575042725  Train Accuracy: 29.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 824  Loss: 1.3864924907684326  Train Accuracy: 30.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 825  Loss: 1.388126254081726  Train Accuracy: 28.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 826  Loss: 1.3871922492980957  Train Accuracy: 28.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 827  Loss: 1.3931585550308228  Train Accuracy: 21.6 Valid Accuracy: 32.0 %\n",
      "Iteration: 828  Loss: 1.390538215637207  Train Accuracy: 24.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 829  Loss: 1.3869692087173462  Train Accuracy: 28.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 830  Loss: 1.3905751705169678  Train Accuracy: 26.0 Valid Accuracy: 36.0 %\n",
      "Iteration: 831  Loss: 1.3888027667999268  Train Accuracy: 28.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 832  Loss: 1.3913506269454956  Train Accuracy: 23.8 Valid Accuracy: 12.0 %\n",
      "Iteration: 833  Loss: 1.3900747299194336  Train Accuracy: 25.4 Valid Accuracy: 32.0 %\n",
      "Iteration: 834  Loss: 1.389654278755188  Train Accuracy: 28.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 835  Loss: 1.387471079826355  Train Accuracy: 28.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 836  Loss: 1.393351435661316  Train Accuracy: 24.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 837  Loss: 1.38913094997406  Train Accuracy: 27.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 838  Loss: 1.3882253170013428  Train Accuracy: 28.2 Valid Accuracy: 18.0 %\n",
      "Iteration: 839  Loss: 1.393051028251648  Train Accuracy: 24.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 840  Loss: 1.3871666193008423  Train Accuracy: 28.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 841  Loss: 1.3893362283706665  Train Accuracy: 25.0 Valid Accuracy: 16.0 %\n",
      "Iteration: 842  Loss: 1.3906750679016113  Train Accuracy: 25.2 Valid Accuracy: 16.0 %\n",
      "Iteration: 843  Loss: 1.387666940689087  Train Accuracy: 28.4 Valid Accuracy: 16.0 %\n",
      "Iteration: 844  Loss: 1.3899924755096436  Train Accuracy: 27.0 Valid Accuracy: 12.0 %\n",
      "Iteration: 845  Loss: 1.391310214996338  Train Accuracy: 24.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 846  Loss: 1.3918145895004272  Train Accuracy: 25.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 847  Loss: 1.3924219608306885  Train Accuracy: 25.6 Valid Accuracy: 20.0 %\n",
      "Iteration: 848  Loss: 1.3871649503707886  Train Accuracy: 29.4 Valid Accuracy: 20.0 %\n",
      "Iteration: 849  Loss: 1.3896039724349976  Train Accuracy: 25.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 850  Loss: 1.3894643783569336  Train Accuracy: 25.8 Valid Accuracy: 18.0 %\n",
      "Iteration: 851  Loss: 1.3869343996047974  Train Accuracy: 27.8 Valid Accuracy: 20.0 %\n",
      "Iteration: 852  Loss: 1.3886092901229858  Train Accuracy: 26.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 853  Loss: 1.3887622356414795  Train Accuracy: 25.8 Valid Accuracy: 32.0 %\n",
      "Iteration: 854  Loss: 1.386391282081604  Train Accuracy: 29.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 855  Loss: 1.3876278400421143  Train Accuracy: 27.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 856  Loss: 1.3914064168930054  Train Accuracy: 23.2 Valid Accuracy: 20.0 %\n",
      "Iteration: 857  Loss: 1.38918936252594  Train Accuracy: 25.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 858  Loss: 1.3897215127944946  Train Accuracy: 26.8 Valid Accuracy: 36.0 %\n",
      "Iteration: 859  Loss: 1.3896303176879883  Train Accuracy: 26.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 860  Loss: 1.389042854309082  Train Accuracy: 26.4 Valid Accuracy: 24.0 %\n",
      "Iteration: 861  Loss: 1.3894513845443726  Train Accuracy: 25.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 862  Loss: 1.3894888162612915  Train Accuracy: 24.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 863  Loss: 1.3873140811920166  Train Accuracy: 29.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 864  Loss: 1.3876069784164429  Train Accuracy: 28.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 865  Loss: 1.387308120727539  Train Accuracy: 27.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 866  Loss: 1.3892943859100342  Train Accuracy: 24.8 Valid Accuracy: 26.0 %\n",
      "Iteration: 867  Loss: 1.3883965015411377  Train Accuracy: 25.6 Valid Accuracy: 32.0 %\n",
      "Iteration: 868  Loss: 1.393588662147522  Train Accuracy: 22.6 Valid Accuracy: 22.0 %\n",
      "Iteration: 869  Loss: 1.391098141670227  Train Accuracy: 25.8 Valid Accuracy: 16.0 %\n",
      "Iteration: 870  Loss: 1.3890856504440308  Train Accuracy: 25.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 871  Loss: 1.386498212814331  Train Accuracy: 31.6 Valid Accuracy: 28.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 872  Loss: 1.3892927169799805  Train Accuracy: 26.2 Valid Accuracy: 24.0 %\n",
      "Iteration: 873  Loss: 1.389337182044983  Train Accuracy: 26.6 Valid Accuracy: 24.0 %\n",
      "Iteration: 874  Loss: 1.3895671367645264  Train Accuracy: 24.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 875  Loss: 1.3884907960891724  Train Accuracy: 24.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 876  Loss: 1.3915132284164429  Train Accuracy: 24.2 Valid Accuracy: 32.0 %\n",
      "Iteration: 877  Loss: 1.3880351781845093  Train Accuracy: 28.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 878  Loss: 1.3896689414978027  Train Accuracy: 27.0 Valid Accuracy: 10.0 %\n",
      "Iteration: 879  Loss: 1.3870254755020142  Train Accuracy: 28.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 880  Loss: 1.3864495754241943  Train Accuracy: 29.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 881  Loss: 1.3902647495269775  Train Accuracy: 27.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 882  Loss: 1.3880211114883423  Train Accuracy: 29.4 Valid Accuracy: 22.0 %\n",
      "Iteration: 883  Loss: 1.3885397911071777  Train Accuracy: 27.2 Valid Accuracy: 34.0 %\n",
      "Iteration: 884  Loss: 1.3912487030029297  Train Accuracy: 24.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 885  Loss: 1.3914738893508911  Train Accuracy: 23.2 Valid Accuracy: 28.0 %\n",
      "Iteration: 886  Loss: 1.3888227939605713  Train Accuracy: 28.8 Valid Accuracy: 20.0 %\n",
      "Iteration: 887  Loss: 1.3877933025360107  Train Accuracy: 29.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 888  Loss: 1.390625  Train Accuracy: 24.8 Valid Accuracy: 30.0 %\n",
      "Iteration: 889  Loss: 1.391157627105713  Train Accuracy: 23.2 Valid Accuracy: 26.0 %\n",
      "Iteration: 890  Loss: 1.3904998302459717  Train Accuracy: 26.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 891  Loss: 1.3912137746810913  Train Accuracy: 22.4 Valid Accuracy: 16.0 %\n",
      "Iteration: 892  Loss: 1.388330101966858  Train Accuracy: 27.8 Valid Accuracy: 16.0 %\n",
      "Iteration: 893  Loss: 1.3891056776046753  Train Accuracy: 25.8 Valid Accuracy: 20.0 %\n",
      "Iteration: 894  Loss: 1.3902190923690796  Train Accuracy: 24.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 895  Loss: 1.3860766887664795  Train Accuracy: 29.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 896  Loss: 1.3928769826889038  Train Accuracy: 24.8 Valid Accuracy: 22.0 %\n",
      "Iteration: 897  Loss: 1.3901970386505127  Train Accuracy: 26.6 Valid Accuracy: 18.0 %\n",
      "Iteration: 898  Loss: 1.3898452520370483  Train Accuracy: 26.4 Valid Accuracy: 28.0 %\n",
      "Iteration: 899  Loss: 1.3905630111694336  Train Accuracy: 27.6 Valid Accuracy: 28.0 %\n",
      "Iteration: 900  Loss: 1.3876150846481323  Train Accuracy: 29.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 901  Loss: 1.3888942003250122  Train Accuracy: 26.0 Valid Accuracy: 40.0 %\n",
      "Iteration: 902  Loss: 1.3875796794891357  Train Accuracy: 27.4 Valid Accuracy: 26.0 %\n",
      "Iteration: 903  Loss: 1.389060139656067  Train Accuracy: 24.8 Valid Accuracy: 20.0 %\n",
      "Iteration: 904  Loss: 1.3897209167480469  Train Accuracy: 26.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 905  Loss: 1.3885613679885864  Train Accuracy: 26.6 Valid Accuracy: 30.0 %\n",
      "Iteration: 906  Loss: 1.389775037765503  Train Accuracy: 24.0 Valid Accuracy: 18.0 %\n",
      "Iteration: 907  Loss: 1.387856125831604  Train Accuracy: 27.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 908  Loss: 1.3907846212387085  Train Accuracy: 22.8 Valid Accuracy: 34.0 %\n",
      "Iteration: 909  Loss: 1.3896421194076538  Train Accuracy: 23.6 Valid Accuracy: 34.0 %\n",
      "Iteration: 910  Loss: 1.3889669179916382  Train Accuracy: 27.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 911  Loss: 1.3889931440353394  Train Accuracy: 26.2 Valid Accuracy: 22.0 %\n",
      "Iteration: 912  Loss: 1.3873934745788574  Train Accuracy: 27.4 Valid Accuracy: 32.0 %\n",
      "Iteration: 913  Loss: 1.3883965015411377  Train Accuracy: 27.2 Valid Accuracy: 14.0 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-756a044985bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# Calculating gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "n_iters = 10000\n",
    "num_epochs = int(n_iters / (len(X_train)/batch_size))\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "# batch GD\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01,weight_decay =0,betas=(0.9, 0.999),amsgrad=False)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(),lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.1)\n",
    "\n",
    "# Create RNN\n",
    "input_dim = 22\n",
    "seq_dim = 500\n",
    "\n",
    "train_loss = []\n",
    "iterations = []\n",
    "train_acc = []\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "\n",
    "print(\"num_epochs = \", num_epochs)\n",
    "print(\"n_iters = \", n_iters)\n",
    "print(\"starting training..\")\n",
    "\n",
    "count = 0\n",
    "#num_epochs = 2\n",
    "print(\"starting training..\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch=\",epoch)\n",
    "    # reset hidden states\n",
    "    \n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        train  = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden() \n",
    "                \n",
    "        # Forward propagation\n",
    "        outputs = model(train.float())\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "                    \n",
    "        #print(\"parameters===\",list(model.parameters())[0].data)\n",
    "\n",
    "        count += 1\n",
    "        train_loss.append(loss.data)\n",
    "        iterations.append(count)\n",
    "        if count % 1 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            #indices = np.random.choice(X_train.shape[0], 50, replace=False)\n",
    "            #X_train_tensor = torch.from_numpy(X_train[indices].reshape(-1, seq_dim, input_dim))\n",
    "            #y_pred_valid = model( X_valid_tensor.float())\n",
    "            #val_acc = get_accuracy(y_pred_valid, Y_valid,batch_size=X_valid.shape[0])\n",
    "            \n",
    "            y_pred_train = model( train.float())\n",
    "            train_acc = get_accuracy(y_pred_train,labels,batch_size=labels.shape[0])\n",
    "            \n",
    "            indices = np.random.choice(X_valid.shape[0], 50, replace=False)\n",
    "            \n",
    "            X_valid_tensor = torch.from_numpy(X_valid[indices].reshape(-1, seq_dim, input_dim))\n",
    "            \n",
    "            y_pred_valid = model( X_valid_tensor.float())\n",
    "            val_acc = get_accuracy(y_pred_valid, Y_valid[indices],\n",
    "            batch_size=50)\n",
    "            \n",
    "            #print('Iteration: {}  Loss: {}' .format(count, loss.data))\n",
    "\n",
    "            print('Iteration: {}  Loss: {}  Train Accuracy: {} Valid Accuracy: {} %'.format(count, loss.data,train_acc,\n",
    "                                                                                            val_acc))\n",
    "            #if(train_acc> 35 and val_acc>35):\n",
    "                #return\n",
    "            '''\n",
    "            # Iterate through test dataset\n",
    "            for signals, labels in valid_loader:\n",
    "                signals = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "                #print(signals.shape)\n",
    "                # Forward propagation\n",
    "                outputs_valid = model(signals.float())\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs_valid.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            train_loss.append(loss.data)\n",
    "            iterations.append(count)\n",
    "            train_acc.append(accuracy)\n",
    "            print('Iteration: {}  Loss: {}  Valid Accuracy: {} %'.format(count, loss.data, accuracy))\n",
    "          '''  \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "print(X_train_tensor.shape)\n",
    "y_pred_train = model( X_train_tensor.float())\n",
    "train_acc = get_accuracy(y_pred_train, Y_train,\n",
    "    batch_size=len(Y_train))\n",
    "print('train accuracy:', train_acc)\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "print(X_valid_tensor.shape)\n",
    "y_pred_valid = model( X_valid_tensor.float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid,\n",
    "    batch_size=len(Y_valid))\n",
    "print('validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87250\n",
      "581\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "torch.Size([581, 500, 22])\n",
      "validation accuracy: 22.990246701090076\n"
     ]
    }
   ],
   "source": [
    "#Calculating the validation accruacy in baaches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_valid.shape[0]\n",
    "size_of_batches = int(datset_size/150)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start = 0\n",
    "\n",
    "valid_accuracies = []\n",
    "for i in range(150):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    X_valid_tensor = torch.from_numpy(X_valid[start:end].reshape(-1, seq_dim, input_dim))\n",
    "    print(X_valid_tensor.shape)\n",
    "    y_pred_valid = model( X_valid_tensor.float())\n",
    "    val_acc = get_accuracy(y_pred_valid, Y_valid[start:end],\n",
    "    batch_size=len(Y_valid[start:end]))\n",
    "    start = end\n",
    "    valid_accuracies.append(val_acc)\n",
    "\n",
    "print('validation accuracy:', np.mean(valid_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177125\n",
      "885\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "torch.Size([885, 500, 22])\n",
      "train accuracy: 26.46666666666667\n"
     ]
    }
   ],
   "source": [
    "#Calculating the training accruacy in batches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_train.shape[0]\n",
    "size_of_batches = int(datset_size/200)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start=end = 0\n",
    "\n",
    "train_accuracies = []\n",
    "for i in range(200):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    X_train_tensor = torch.from_numpy(X_train[start:end].reshape(-1, seq_dim, input_dim))\n",
    "    print(X_train_tensor.shape)\n",
    "    y_pred_train = model( X_train_tensor .float())\n",
    "    train_acc = get_accuracy(y_pred_train, Y_train[start:end],\n",
    "    batch_size=len(Y_train[start:end]))\n",
    "    start = end\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "print('train accuracy:', np.mean(train_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(iterations,train_loss)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-82-e672ddfbaeab>, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-82-e672ddfbaeab>\"\u001b[1;36m, line \u001b[1;32m62\u001b[0m\n\u001b[1;33m    if count % 1 == 0:\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "n_iters = 1000\n",
    "num_epochs = int(n_iters / (len(X_train)/batch_size))\n",
    "\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "# batch GD\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1,weight_decay = 0, amsgrad=False)\n",
    "\n",
    "# Create RNN\n",
    "input_dim = 22\n",
    "seq_dim = 1000\n",
    "\n",
    "train_loss = []\n",
    "iterations = []\n",
    "train_acc = []\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "\n",
    "print(\"num_epochs = \", num_epochs)\n",
    "print(\"n_iters = \", n_iters)\n",
    "print(\"starting training..\")\n",
    "\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch=\",epoch)\n",
    "    # reset hidden states\n",
    "    model.hidden = model.init_hidden()\n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        train  = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        #model.hidden = model.init_hidden() \n",
    "                \n",
    "        # Forward propagation\n",
    "        outputs = model(train.float())\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "                    \n",
    "        #print(\"parameters===\",list(model.parameters())[0].data)\n",
    "\n",
    "        count += 1\n",
    "        train_loss.append(loss.data)\n",
    "        iterations.append(count\n",
    "                          \n",
    "        if count % 1 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            \n",
    "            y_pred_valid = model( X_valid_tensor.float())\n",
    "            val_acc = get_accuracy(y_pred_valid, Y_valid,batch_size=X_valid.shape[0])\n",
    "            \n",
    "            y_pred_train = model( X_train_tensor.float())\n",
    "            train_acc = get_accuracy(y_pred_train, Y_train,batch_size=X_train.shape[0])\n",
    "            \n",
    "            print('Iteration: {}  Loss: {}  Train Accuracy: {} Valid Accuracy: {} %'.format(count, loss.data,train_acc,\n",
    "                                                                                            val_acc))\n",
    "            '''\n",
    "            # Iterate through test dataset\n",
    "            for signals, labels in valid_loader:\n",
    "                signals = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "                #print(signals.shape)\n",
    "                # Forward propagation\n",
    "                outputs_valid = model(signals.float())\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs_valid.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            train_loss.append(loss.data)\n",
    "            iterations.append(count)\n",
    "            train_acc.append(accuracy)\n",
    "            print('Iteration: {}  Loss: {}  Valid Accuracy: {} %'.format(count, loss.data, accuracy))\n",
    "            '''\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 500, 22])\n",
      "validation accuracy: 23.51\n"
     ]
    }
   ],
   "source": [
    "X_valid_tensor = torch.from_numpy(X_valid[0:10000].reshape(-1, seq_dim, input_dim))\n",
    "print(X_valid_tensor.shape)\n",
    "y_pred_valid = model( X_valid_tensor.float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid[0:10000],\n",
    "    batch_size=10000)\n",
    "print('validation accuracy:', val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3290\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3291\u001b[1;33m                     \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3292\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-d8f0033a0184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_test_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_test_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m test_acc = get_accuracy(y_pred_test, Y_test,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-baf1dc696013>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mhidden_out\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.from_numpy(X_test.reshape(-1, seq_dim, input_dim))\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=X_test.shape[0])\n",
    "print('test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
