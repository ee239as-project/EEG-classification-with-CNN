{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for issue loading Utils.preprocess_util\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Utils.preprocess_util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 1000, 22)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n",
      "\n",
      "Training data shape: (1417, 22, 1000)\n",
      "Valid data shape: (698, 22, 1000)\n",
      "Training target shape: (1417,)\n",
      "Valid target shape: (698,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        a= x.view(x.size(0), -1)\n",
    "        return a\n",
    "    \n",
    "class threed_to_twod(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        a = x.reshape(x.shape[0],x.shape[3],x.shape[1])\n",
    "        # print (a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0464],\n",
       "          [-0.0575],\n",
       "          [-0.0048],\n",
       "          ...,\n",
       "          [ 0.0374],\n",
       "          [ 0.0094],\n",
       "          [ 0.0280]],\n",
       "\n",
       "         [[-0.0142],\n",
       "          [ 0.0463],\n",
       "          [ 0.0165],\n",
       "          ...,\n",
       "          [-0.0244],\n",
       "          [-0.0565],\n",
       "          [-0.0142]],\n",
       "\n",
       "         [[ 0.0326],\n",
       "          [-0.0348],\n",
       "          [-0.0134],\n",
       "          ...,\n",
       "          [-0.0002],\n",
       "          [-0.0211],\n",
       "          [ 0.0359]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0117],\n",
       "          [-0.0150],\n",
       "          [-0.0066],\n",
       "          ...,\n",
       "          [ 0.0536],\n",
       "          [-0.0428],\n",
       "          [-0.0133]],\n",
       "\n",
       "         [[-0.0254],\n",
       "          [-0.0445],\n",
       "          [ 0.0068],\n",
       "          ...,\n",
       "          [ 0.0520],\n",
       "          [ 0.0047],\n",
       "          [-0.0243]],\n",
       "\n",
       "         [[-0.0497],\n",
       "          [ 0.0265],\n",
       "          [-0.0248],\n",
       "          ...,\n",
       "          [ 0.0247],\n",
       "          [ 0.0495],\n",
       "          [-0.0127]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0307],\n",
       "          [-0.0085],\n",
       "          [-0.0401],\n",
       "          ...,\n",
       "          [-0.0208],\n",
       "          [-0.0468],\n",
       "          [-0.0258]],\n",
       "\n",
       "         [[ 0.0480],\n",
       "          [-0.0527],\n",
       "          [ 0.0061],\n",
       "          ...,\n",
       "          [-0.0430],\n",
       "          [ 0.0315],\n",
       "          [-0.0243]],\n",
       "\n",
       "         [[-0.0578],\n",
       "          [ 0.0364],\n",
       "          [-0.0044],\n",
       "          ...,\n",
       "          [-0.0106],\n",
       "          [-0.0360],\n",
       "          [ 0.0492]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0320],\n",
       "          [ 0.0361],\n",
       "          [ 0.0296],\n",
       "          ...,\n",
       "          [ 0.0374],\n",
       "          [-0.0072],\n",
       "          [-0.0349]],\n",
       "\n",
       "         [[ 0.0345],\n",
       "          [-0.0417],\n",
       "          [-0.0164],\n",
       "          ...,\n",
       "          [ 0.0340],\n",
       "          [-0.0434],\n",
       "          [ 0.0471]],\n",
       "\n",
       "         [[-0.0399],\n",
       "          [-0.0405],\n",
       "          [ 0.0111],\n",
       "          ...,\n",
       "          [ 0.0275],\n",
       "          [-0.0015],\n",
       "          [-0.0525]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0063],\n",
       "          [-0.0432],\n",
       "          [ 0.0321],\n",
       "          ...,\n",
       "          [ 0.0485],\n",
       "          [ 0.0025],\n",
       "          [-0.0161]],\n",
       "\n",
       "         [[-0.0183],\n",
       "          [ 0.0526],\n",
       "          [ 0.0316],\n",
       "          ...,\n",
       "          [ 0.0561],\n",
       "          [ 0.0230],\n",
       "          [-0.0393]],\n",
       "\n",
       "         [[-0.0361],\n",
       "          [ 0.0482],\n",
       "          [-0.0472],\n",
       "          ...,\n",
       "          [ 0.0209],\n",
       "          [ 0.0548],\n",
       "          [ 0.0175]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0271],\n",
       "          [ 0.0485],\n",
       "          [ 0.0313],\n",
       "          ...,\n",
       "          [ 0.0062],\n",
       "          [ 0.0370],\n",
       "          [ 0.0532]],\n",
       "\n",
       "         [[ 0.0087],\n",
       "          [-0.0086],\n",
       "          [-0.0482],\n",
       "          ...,\n",
       "          [ 0.0275],\n",
       "          [ 0.0179],\n",
       "          [-0.0305]],\n",
       "\n",
       "         [[-0.0391],\n",
       "          [-0.0220],\n",
       "          [-0.0549],\n",
       "          ...,\n",
       "          [ 0.0476],\n",
       "          [ 0.0521],\n",
       "          [-0.0420]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0506],\n",
       "          [-0.0145],\n",
       "          [ 0.0566],\n",
       "          ...,\n",
       "          [-0.0477],\n",
       "          [-0.0308],\n",
       "          [ 0.0264]],\n",
       "\n",
       "         [[ 0.0294],\n",
       "          [ 0.0005],\n",
       "          [ 0.0121],\n",
       "          ...,\n",
       "          [ 0.0072],\n",
       "          [-0.0281],\n",
       "          [ 0.0568]],\n",
       "\n",
       "         [[ 0.0081],\n",
       "          [ 0.0544],\n",
       "          [ 0.0459],\n",
       "          ...,\n",
       "          [ 0.0344],\n",
       "          [ 0.0459],\n",
       "          [-0.0332]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0552],\n",
       "          [ 0.0155],\n",
       "          [-0.0114],\n",
       "          ...,\n",
       "          [-0.0117],\n",
       "          [ 0.0533],\n",
       "          [-0.0243]],\n",
       "\n",
       "         [[ 0.0369],\n",
       "          [ 0.0232],\n",
       "          [-0.0108],\n",
       "          ...,\n",
       "          [-0.0529],\n",
       "          [-0.0534],\n",
       "          [-0.0122]],\n",
       "\n",
       "         [[-0.0090],\n",
       "          [ 0.0234],\n",
       "          [ 0.0225],\n",
       "          ...,\n",
       "          [-0.0091],\n",
       "          [-0.0077],\n",
       "          [-0.0060]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0400],\n",
       "          [-0.0290],\n",
       "          [ 0.0289],\n",
       "          ...,\n",
       "          [-0.0075],\n",
       "          [-0.0526],\n",
       "          [-0.0379]],\n",
       "\n",
       "         [[-0.0427],\n",
       "          [-0.0201],\n",
       "          [-0.0118],\n",
       "          ...,\n",
       "          [ 0.0153],\n",
       "          [ 0.0343],\n",
       "          [-0.0343]],\n",
       "\n",
       "         [[-0.0053],\n",
       "          [ 0.0364],\n",
       "          [ 0.0001],\n",
       "          ...,\n",
       "          [ 0.0567],\n",
       "          [-0.0539],\n",
       "          [ 0.0331]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0390],\n",
       "          [ 0.0441],\n",
       "          [-0.0254],\n",
       "          ...,\n",
       "          [ 0.0518],\n",
       "          [ 0.0534],\n",
       "          [ 0.0533]],\n",
       "\n",
       "         [[ 0.0262],\n",
       "          [-0.0525],\n",
       "          [ 0.0248],\n",
       "          ...,\n",
       "          [-0.0259],\n",
       "          [-0.0287],\n",
       "          [-0.0183]],\n",
       "\n",
       "         [[-0.0449],\n",
       "          [ 0.0332],\n",
       "          [-0.0572],\n",
       "          ...,\n",
       "          [ 0.0118],\n",
       "          [ 0.0217],\n",
       "          [ 0.0142]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0231],\n",
       "          [ 0.0411],\n",
       "          [-0.0214],\n",
       "          ...,\n",
       "          [ 0.0163],\n",
       "          [-0.0238],\n",
       "          [ 0.0240]],\n",
       "\n",
       "         [[-0.0388],\n",
       "          [ 0.0381],\n",
       "          [-0.0239],\n",
       "          ...,\n",
       "          [-0.0129],\n",
       "          [-0.0253],\n",
       "          [ 0.0319]],\n",
       "\n",
       "         [[ 0.0020],\n",
       "          [-0.0267],\n",
       "          [ 0.0278],\n",
       "          ...,\n",
       "          [ 0.0173],\n",
       "          [-0.0515],\n",
       "          [ 0.0467]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0201],\n",
       "          [ 0.0216],\n",
       "          [ 0.0448],\n",
       "          ...,\n",
       "          [-0.0488],\n",
       "          [ 0.0081],\n",
       "          [ 0.0420]],\n",
       "\n",
       "         [[ 0.0458],\n",
       "          [-0.0514],\n",
       "          [ 0.0485],\n",
       "          ...,\n",
       "          [-0.0163],\n",
       "          [-0.0157],\n",
       "          [-0.0278]],\n",
       "\n",
       "         [[ 0.0476],\n",
       "          [ 0.0111],\n",
       "          [ 0.0467],\n",
       "          ...,\n",
       "          [ 0.0283],\n",
       "          [-0.0203],\n",
       "          [ 0.0544]]]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('conv_across_time',nn.Conv2d(1,40,kernel_size=(1,51),stride = 1))\n",
    "model.add_module('conv_across_electrodes',nn.Conv2d(40,40,kernel_size=(22,1),stride = 1))\n",
    "model.add_module('BatchNorm2d',nn.BatchNorm2d(40,momentum=0.1))\n",
    "model.add_module('Nonlinearity', nn.ReLU())\n",
    "model.add_module('correct_dimensions',threed_to_twod())\n",
    "model.add_module('AvgPool2d',nn.AvgPool2d(kernel_size=(135,1),stride = (5,1)))\n",
    "model.add_module('drop', nn.Dropout(p=0.5))\n",
    "model.add_module('Flatten',Flatten())    \n",
    "model.add_module('Fc_layer',nn.Linear(164*40,10))\n",
    "torch.nn.init.xavier_uniform_(model.conv_across_time.weight, gain=1)\n",
    "torch.nn.init.xavier_uniform_(model.conv_across_electrodes.weight, gain=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "model.type(dtype)\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 0., 1.,  ..., 2., 1., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N,C,H,W = 18,1,25,1000\n",
    "# x = Variable(torch.tensor(X_train.reshape((18,1, 25, 1000))))\n",
    "x = Variable(torch.tensor(X_train))\n",
    "y = Variable(torch.tensor(Y_train),requires_grad=False)\n",
    "dtype = torch.FloatTensor\n",
    "x.type(dtype)\n",
    "y.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for t in range(3):\n",
    "    y_pred = model( x.float())\n",
    "    loss = loss_fn(y_pred,y.type(torch.LongTensor))\n",
    "    print(loss.data)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "loss = loss_fn(y_pred,y.type(torch.LongTensor))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ouput, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    classes_predicted = torch.max(ouput, 1)[1]\n",
    "    corrects = (np.equal(classes_predicted.tolist(),target.tolist()).astype(int)).sum()\n",
    "    # corrects = (max_values[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()\n",
    "\n",
    "def threeD_to_fourDTensor(X):\n",
    "    return Variable(torch.tensor(X.reshape((X.shape[0],1,X.shape[1],X.shape[2],))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 1400) loss: 2.239372\n",
      "(Epoch 1 / 50) train acc: 8.000000; val_acc: 24.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1b44ad2185c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_train = X_train.shape[0]\n",
    "num_valid = X_valid.shape[0]\n",
    "batch_size = 50\n",
    "num_epochs = 50\n",
    "iterations_per_epoch = max(num_train // batch_size, 1)\n",
    "num_iterations = num_epochs * iterations_per_epoch\n",
    "epoch = 1\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)   \n",
    "for t in range(num_iterations):\n",
    "    batch_mask = np.random.choice(num_train, batch_size)\n",
    "    X_batch = X_train[batch_mask]\n",
    "    y_batch = Y_train[batch_mask]\n",
    "    X_batch_tensor = threeD_to_fourDTensor(X_batch)\n",
    "    y_batch_tensor = Variable(torch.tensor(y_batch))\n",
    "    \n",
    "    y_pred = model( X_batch_tensor.float())\n",
    "    \n",
    "    loss = loss_fn(y_pred,y_batch_tensor.type(torch.LongTensor))\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if(t%10 == 0):\n",
    "        print('(Iteration %d / %d) loss: %f' % (\n",
    "                       t + 1, num_iterations, loss.detach().numpy()))\n",
    "    \n",
    "    epoch_end = (t + 1) % iterations_per_epoch == 0\n",
    "    \n",
    "    if epoch_end:\n",
    "                epoch += 1\n",
    "    \n",
    "    first_it = (t == 0)\n",
    "    last_it = (t == num_iterations - 1)\n",
    "\n",
    "    if first_it or last_it or epoch_end:\n",
    "        X_train_tensor =threeD_to_fourDTensor(X_train[0:50,:,:])\n",
    "        y_pred_train = model( X_train_tensor.float())\n",
    "        train_acc = get_accuracy(y_pred_train, Y_train[0:50],\n",
    "            batch_size=50)\n",
    "        \n",
    "        X_valid_tensor = threeD_to_fourDTensor(X_valid[0:50,:,:])\n",
    "        y_pred_valid = model( X_valid_tensor.float())\n",
    "        val_acc = get_accuracy(y_pred_valid, Y_valid[0:50],\n",
    "            batch_size=50)\n",
    "        print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n",
    "                           epoch, num_epochs, train_acc, val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 24.498567335243553\n"
     ]
    }
   ],
   "source": [
    "X_valid_tensor = threeD_to_fourDTensor(X_valid)\n",
    "y_pred_valid = model( X_valid_tensor.float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid,\n",
    "    batch_size=X_valid.shape[0])\n",
    "print('validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 22.34762979683973\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = threeD_to_fourDTensor(X_test)\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=X_test.shape[0])\n",
    "print('test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
