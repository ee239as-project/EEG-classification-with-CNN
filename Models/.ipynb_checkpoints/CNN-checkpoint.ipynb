{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Utils.preprocess_util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 1000, 22)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n",
      "\n",
      "Training data shape: (1417, 22, 1000)\n",
      "Valid data shape: (698, 22, 1000)\n",
      "Training target shape: (1417,)\n",
      "Valid target shape: (698,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (443, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"../Data/X_test.npy\")[:,0:22,:]\n",
    "y_test = np.load(\"../Data/y_test.npy\")\n",
    "person_train_valid = np.load(\"../Data/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"../Data/X_train_valid.npy\")[:,0:22,:]\n",
    "y_train_valid = np.load(\"../Data/y_train_valid.npy\")\n",
    "person_test = np.load(\"../Data/person_test.npy\")\n",
    "\n",
    "print ('Test data shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(  X_train_valid, y_train_valid, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_modified =[]\n",
    "X_valid_modified =[]\n",
    "X_test_modified =[]\n",
    "\n",
    "for xi in X_train:\n",
    "    X_train_modified.append(exponential_running_standardize(xi.T, eps=1e-4))\n",
    "\n",
    "for xi in X_valid:\n",
    "    X_valid_modified.append(exponential_running_standardize(xi.T, eps=1e-4))\n",
    "    \n",
    "for xi in X_test:\n",
    "    X_test_modified.append(exponential_running_standardize(xi.T, eps=1e-4))\n",
    "    \n",
    "\n",
    "X_train = np.array(X_train_modified)\n",
    "X_valid = np.array(X_valid_modified)\n",
    "X_test = np.array(X_test_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 1000, 22)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n",
      "\n",
      "Training data shape: (1417, 22, 1000)\n",
      "Valid data shape: (698, 22, 1000)\n",
      "Training target shape: (1417,)\n",
      "Valid target shape: (698,)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n",
    "print()\n",
    "\n",
    "X_train = np.transpose(X_train,[0,2,1])\n",
    "X_valid = np.transpose(X_valid,[0,2,1])\n",
    "X_test = np.transpose(X_test,[0,2,1])\n",
    "print ('Training data shape: {}'.format(X_train.shape))\n",
    "print ('Valid data shape: {}'.format(X_valid.shape))\n",
    "print ('Training target shape: {}'.format(y_train.shape))\n",
    "print ('Valid target shape: {}'.format(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = []\n",
    "for y in y_train:\n",
    "    value = np.abs(769-y)\n",
    "    Y_train.append(value)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "Y_valid = []\n",
    "for y in y_valid:\n",
    "    value = np.abs(769-y)\n",
    "    Y_valid.append(value)\n",
    "Y_valid = np.array(Y_valid)\n",
    "\n",
    "Y_test = []\n",
    "for y in y_test:\n",
    "    value = np.abs(769-y)\n",
    "    Y_test.append(value)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        a= x.view(x.size(0), -1)\n",
    "        return a\n",
    "    \n",
    "class threed_to_twod(nn.Module):\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        a = x.reshape(x.shape[0],x.shape[3],x.shape[1])\n",
    "        #print (a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('conv_across_time',nn.Conv2d(1,40,kernel_size=(1,51),stride = 1))\n",
    "model.add_module('conv_across_electrodes',nn.Conv2d(40,40,kernel_size=(22,1),stride = 1))\n",
    "model.add_module('BatchNorm2d',nn.BatchNorm2d(40,momentum=0.1))\n",
    "model.add_module('Nonlinearity', nn.ReLU())\n",
    "model.add_module('correct_dimensions',threed_to_twod())\n",
    "model.add_module('AvgPool2d',nn.AvgPool2d(kernel_size=(135,1),stride = (5,1)))\n",
    "model.add_module('drop', nn.Dropout(p=0.5))\n",
    "model.add_module('Flatten',Flatten())    \n",
    "model.add_module('Fc_layer',nn.Linear(164*40,10))\n",
    "torch.nn.init.xavier_uniform_(model.conv_across_time.weight, gain=1)\n",
    "torch.nn.init.xavier_uniform_(model.conv_across_electrodes.weight, gain=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "model.type(dtype)\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 0., 1.,  ..., 2., 1., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#N,C,H,W = 18,1,25,1000\n",
    "#x = Variable(torch.tensor(X_train.reshape((18,1, 25, 1000))))\n",
    "x = Variable(torch.tensor(X_train))\n",
    "y = Variable(torch.tensor(Y_train),requires_grad = False)\n",
    "dtype = torch.FloatTensor\n",
    "x.type(dtype)\n",
    "y.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for t in range(3):\n",
    "    y_pred = model( x.float())\n",
    "    loss = loss_fn(y_pred,y.type(torch.LongTensor))\n",
    "    print(loss.data)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "loss = loss_fn(y_pred,y.type(torch.LongTensor))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ouput, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    \n",
    "    \n",
    "    classes_predicted = torch.max(ouput, 1)[1]\n",
    "    corrects = (np.equal(classes_predicted.tolist(),target.tolist()).astype(int)).sum()\n",
    "\n",
    "    #corrects = (max_values[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()\n",
    "\n",
    "def threeD_to_fourDTensor(X):\n",
    "    return Variable(torch.tensor(X.reshape((X.shape[0],1,X.shape[1],X.shape[2],))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = X_train.shape[0]\n",
    "num_valid = X_valid.shape[0]\n",
    "batch_size = 50\n",
    "num_epochs = 50\n",
    "iterations_per_epoch = max(num_train // batch_size, 1)\n",
    "num_iterations = num_epochs * iterations_per_epoch\n",
    "epoch = 1\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)   \n",
    "for t in range(num_iterations):\n",
    "    batch_mask = np.random.choice(num_train, batch_size)\n",
    "    X_batch = X_train[batch_mask]\n",
    "    y_batch = Y_train[batch_mask]\n",
    "    X_batch_tensor = threeD_to_fourDTensor(X_batch)\n",
    "    y_batch_tensor = Variable(torch.tensor(y_batch))\n",
    "    \n",
    "    y_pred = model( X_batch_tensor.float())\n",
    "    \n",
    "    loss = loss_fn(y_pred,y_batch_tensor.type(torch.LongTensor))\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if(t%10 == 0):\n",
    "        print('(Iteration %d / %d) loss: %f' % (\n",
    "                       t + 1, num_iterations, loss.detach().numpy()))\n",
    "    \n",
    "    epoch_end = (t + 1) % iterations_per_epoch == 0\n",
    "    \n",
    "    if epoch_end:\n",
    "                epoch += 1\n",
    "    \n",
    "    first_it = (t == 0)\n",
    "    last_it = (t == num_iterations - 1)\n",
    "\n",
    "    if first_it or last_it or epoch_end:\n",
    "        X_train_tensor =threeD_to_fourDTensor(X_train[0:50,:,:])\n",
    "        y_pred_train = model( X_train_tensor.float())\n",
    "        train_acc = get_accuracy(y_pred_train, Y_train[0:50],\n",
    "            batch_size=50)\n",
    "        \n",
    "        X_valid_tensor = threeD_to_fourDTensor(X_valid[0:50,:,:])\n",
    "        y_pred_valid = model( X_valid_tensor.float())\n",
    "        val_acc = get_accuracy(y_pred_valid, Y_valid[0:50],\n",
    "            batch_size=50)\n",
    "        print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n",
    "                           epoch, num_epochs, train_acc, val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_tensor = threeD_to_fourDTensor(X_valid)\n",
    "y_pred_valid = model( X_valid_tensor.float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid,\n",
    "    batch_size=X_valid.shape[0])\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = threeD_to_fourDTensor(X_test)\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=X_test.shape[0])\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
