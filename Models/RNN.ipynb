{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"../Data/X_test.npy\")\n",
    "y_test = np.load(\"../Data/y_test.npy\")\n",
    "person_train_valid = np.load(\"../Data/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"../Data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"../Data/y_train_valid.npy\")\n",
    "person_test = np.load(\"../Data/person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = []\n",
    "for y in y_train_valid:\n",
    "    value = np.abs(769-y)\n",
    "    Y_train.append(value)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "Y_test = []\n",
    "for y in y_test:\n",
    "    value = np.abs(769-y)\n",
    "    Y_test.append(value)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115,)\n",
      "(2115,)\n",
      "(443,)\n",
      "(443,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_valid.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and targets tensor for train set. we create tensor, then we will create variable\n",
    "featuresTrain = torch.from_numpy(X_train_valid)\n",
    "targetsTrain = torch.from_numpy(Y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(X_test)\n",
    "targetsTest = torch.from_numpy(Y_test).type(torch.LongTensor) # data type is long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(X_train_valid) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, \n",
    "                          nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10  Loss: 1.5840939283370972  Accuracy: 30 %\n",
      "Iteration: 20  Loss: 1.3395147323608398  Accuracy: 39 %\n",
      "Iteration: 30  Loss: 1.3117599487304688  Accuracy: 52 %\n",
      "Iteration: 40  Loss: 1.456087589263916  Accuracy: 58 %\n",
      "Iteration: 50  Loss: 1.2119991779327393  Accuracy: 59 %\n",
      "Iteration: 60  Loss: 0.45253363251686096  Accuracy: 61 %\n",
      "Iteration: 70  Loss: 0.8311282992362976  Accuracy: 59 %\n",
      "Iteration: 80  Loss: 0.40881621837615967  Accuracy: 62 %\n",
      "Iteration: 90  Loss: 0.9112553596496582  Accuracy: 58 %\n",
      "Iteration: 100  Loss: 0.4276775121688843  Accuracy: 58 %\n",
      "Iteration: 110  Loss: 0.0912146270275116  Accuracy: 53 %\n",
      "Iteration: 120  Loss: 0.5784710049629211  Accuracy: 55 %\n",
      "Iteration: 130  Loss: 0.5351635813713074  Accuracy: 60 %\n",
      "Iteration: 140  Loss: 0.7218586206436157  Accuracy: 57 %\n",
      "Iteration: 150  Loss: 0.20522741973400116  Accuracy: 58 %\n",
      "Iteration: 160  Loss: 0.3935294449329376  Accuracy: 54 %\n",
      "Iteration: 170  Loss: 0.214603990316391  Accuracy: 58 %\n",
      "Iteration: 180  Loss: 0.30525413155555725  Accuracy: 58 %\n",
      "Iteration: 190  Loss: 0.13162504136562347  Accuracy: 57 %\n",
      "Iteration: 200  Loss: 0.31452134251594543  Accuracy: 55 %\n",
      "Iteration: 210  Loss: 0.08713199943304062  Accuracy: 57 %\n",
      "Iteration: 220  Loss: 0.026631228625774384  Accuracy: 59 %\n",
      "Iteration: 230  Loss: 0.08247353881597519  Accuracy: 56 %\n",
      "Iteration: 240  Loss: 0.04067300260066986  Accuracy: 59 %\n",
      "Iteration: 250  Loss: 0.04391688480973244  Accuracy: 58 %\n",
      "Iteration: 260  Loss: 0.014820676296949387  Accuracy: 60 %\n",
      "Iteration: 270  Loss: 0.01319634635001421  Accuracy: 60 %\n",
      "Iteration: 280  Loss: 0.08621641993522644  Accuracy: 53 %\n",
      "Iteration: 290  Loss: 0.015294828452169895  Accuracy: 59 %\n",
      "Iteration: 300  Loss: 0.031168675050139427  Accuracy: 58 %\n",
      "Iteration: 310  Loss: 0.022427206858992577  Accuracy: 58 %\n",
      "Iteration: 320  Loss: 0.004267849959433079  Accuracy: 58 %\n",
      "Iteration: 330  Loss: 7.89006517152302e-05  Accuracy: 57 %\n",
      "Iteration: 340  Loss: 0.03649679571390152  Accuracy: 56 %\n",
      "Iteration: 350  Loss: 0.12992268800735474  Accuracy: 60 %\n",
      "Iteration: 360  Loss: 0.033441390842199326  Accuracy: 58 %\n",
      "Iteration: 370  Loss: 0.011510605923831463  Accuracy: 59 %\n",
      "Iteration: 380  Loss: 0.10152003914117813  Accuracy: 59 %\n",
      "Iteration: 390  Loss: 0.0019202805124223232  Accuracy: 59 %\n",
      "Iteration: 400  Loss: 0.007904591970145702  Accuracy: 60 %\n",
      "Iteration: 410  Loss: 0.008945412933826447  Accuracy: 59 %\n",
      "Iteration: 420  Loss: 0.006087231449782848  Accuracy: 57 %\n",
      "Iteration: 430  Loss: 0.000962376594543457  Accuracy: 58 %\n",
      "Iteration: 440  Loss: 1.296997106692288e-05  Accuracy: 58 %\n",
      "Iteration: 450  Loss: 0.0024597598239779472  Accuracy: 57 %\n",
      "Iteration: 460  Loss: 0.009387440979480743  Accuracy: 58 %\n",
      "Iteration: 470  Loss: 0.04580695927143097  Accuracy: 59 %\n",
      "Iteration: 480  Loss: 0.12099073082208633  Accuracy: 57 %\n",
      "Iteration: 490  Loss: 0.044886473566293716  Accuracy: 56 %\n",
      "Iteration: 500  Loss: 0.004185285419225693  Accuracy: 55 %\n",
      "Iteration: 510  Loss: 0.0019103670492768288  Accuracy: 55 %\n",
      "Iteration: 520  Loss: 0.00013322829909157008  Accuracy: 56 %\n",
      "Iteration: 530  Loss: 0.0020089007448405027  Accuracy: 56 %\n",
      "Iteration: 540  Loss: 0.02006571739912033  Accuracy: 56 %\n",
      "Iteration: 550  Loss: 0.005165799520909786  Accuracy: 56 %\n",
      "Iteration: 560  Loss: 0.046732380986213684  Accuracy: 55 %\n",
      "Iteration: 570  Loss: 0.003236031625419855  Accuracy: 58 %\n",
      "Iteration: 580  Loss: 0.04930609092116356  Accuracy: 57 %\n",
      "Iteration: 590  Loss: 0.007232542149722576  Accuracy: 55 %\n",
      "Iteration: 600  Loss: 0.020464114844799042  Accuracy: 57 %\n",
      "Iteration: 610  Loss: 0.009471104480326176  Accuracy: 57 %\n",
      "Iteration: 620  Loss: 0.06118447333574295  Accuracy: 55 %\n",
      "Iteration: 630  Loss: 0.0057139634154737  Accuracy: 56 %\n",
      "Iteration: 640  Loss: 0.008149228058755398  Accuracy: 57 %\n",
      "Iteration: 650  Loss: 0.04355243220925331  Accuracy: 58 %\n",
      "Iteration: 660  Loss: 2.2252401322475635e-05  Accuracy: 55 %\n",
      "Iteration: 670  Loss: 0.006804728414863348  Accuracy: 56 %\n",
      "Iteration: 680  Loss: 0.004379501566290855  Accuracy: 53 %\n",
      "Iteration: 690  Loss: 0.0099358344450593  Accuracy: 55 %\n",
      "Iteration: 700  Loss: 0.033138684928417206  Accuracy: 56 %\n",
      "Iteration: 710  Loss: 0.0007353973342105746  Accuracy: 55 %\n",
      "Iteration: 720  Loss: 0.006921026855707169  Accuracy: 59 %\n",
      "Iteration: 730  Loss: 0.040878672152757645  Accuracy: 57 %\n",
      "Iteration: 740  Loss: 0.05921510234475136  Accuracy: 57 %\n",
      "Iteration: 750  Loss: 0.28298357129096985  Accuracy: 59 %\n",
      "Iteration: 760  Loss: 0.01779925264418125  Accuracy: 56 %\n",
      "Iteration: 770  Loss: 0.00022033056302461773  Accuracy: 56 %\n",
      "Iteration: 780  Loss: 0.11577833443880081  Accuracy: 58 %\n",
      "Iteration: 790  Loss: 0.07577870786190033  Accuracy: 55 %\n",
      "Iteration: 800  Loss: 0.0630313903093338  Accuracy: 55 %\n",
      "Iteration: 810  Loss: 0.03464300185441971  Accuracy: 56 %\n",
      "Iteration: 820  Loss: 0.0027174712158739567  Accuracy: 57 %\n",
      "Iteration: 830  Loss: 0.011404271237552166  Accuracy: 55 %\n",
      "Iteration: 840  Loss: 0.0053876545280218124  Accuracy: 56 %\n",
      "Iteration: 850  Loss: 0.018837854266166687  Accuracy: 57 %\n",
      "Iteration: 860  Loss: 0.010876745916903019  Accuracy: 57 %\n",
      "Iteration: 870  Loss: 0.003805889980867505  Accuracy: 59 %\n",
      "Iteration: 880  Loss: 2.7974447220913135e-06  Accuracy: 58 %\n",
      "Iteration: 890  Loss: 0.006073575001209974  Accuracy: 56 %\n",
      "Iteration: 900  Loss: 0.004355521406978369  Accuracy: 56 %\n",
      "Iteration: 910  Loss: 0.0007213592762127519  Accuracy: 57 %\n",
      "Iteration: 920  Loss: 0.06526346504688263  Accuracy: 58 %\n",
      "Iteration: 930  Loss: 0.0030853652860969305  Accuracy: 54 %\n",
      "Iteration: 940  Loss: 0.0014846897684037685  Accuracy: 55 %\n",
      "Iteration: 950  Loss: 0.00039128304342739284  Accuracy: 58 %\n",
      "Iteration: 960  Loss: 0.008648528717458248  Accuracy: 57 %\n",
      "Iteration: 970  Loss: 0.0013195514911785722  Accuracy: 58 %\n",
      "Iteration: 980  Loss: 0.005498175509274006  Accuracy: 56 %\n",
      "Iteration: 990  Loss: 0.1297050267457962  Accuracy: 57 %\n",
      "Iteration: 1000  Loss: 0.01675177551805973  Accuracy: 57 %\n",
      "Iteration: 1010  Loss: 0.02162969671189785  Accuracy: 58 %\n",
      "Iteration: 1020  Loss: 0.00806177593767643  Accuracy: 59 %\n",
      "Iteration: 1030  Loss: 0.06535088270902634  Accuracy: 59 %\n",
      "Iteration: 1040  Loss: 0.0005870485329069197  Accuracy: 60 %\n",
      "Iteration: 1050  Loss: 0.023167075589299202  Accuracy: 58 %\n",
      "Iteration: 1060  Loss: 0.009131688624620438  Accuracy: 55 %\n",
      "Iteration: 1070  Loss: 0.0005808401037938893  Accuracy: 55 %\n",
      "Iteration: 1080  Loss: 0.023511698469519615  Accuracy: 55 %\n",
      "Iteration: 1090  Loss: 0.0029424834065139294  Accuracy: 58 %\n",
      "Iteration: 1100  Loss: 0.08358090370893478  Accuracy: 57 %\n",
      "Iteration: 1110  Loss: 0.018448520451784134  Accuracy: 57 %\n",
      "Iteration: 1120  Loss: 0.0846690908074379  Accuracy: 56 %\n",
      "Iteration: 1130  Loss: 0.005186810623854399  Accuracy: 55 %\n",
      "Iteration: 1140  Loss: 0.006800460629165173  Accuracy: 59 %\n",
      "Iteration: 1150  Loss: 0.01002679392695427  Accuracy: 59 %\n",
      "Iteration: 1160  Loss: 0.00023072719341143966  Accuracy: 57 %\n",
      "Iteration: 1170  Loss: 0.00830560177564621  Accuracy: 56 %\n",
      "Iteration: 1180  Loss: 0.0005206680507399142  Accuracy: 59 %\n",
      "Iteration: 1190  Loss: 0.03178892657160759  Accuracy: 57 %\n",
      "Iteration: 1200  Loss: 0.0034228134900331497  Accuracy: 56 %\n",
      "Iteration: 1210  Loss: 2.346038854739163e-05  Accuracy: 59 %\n",
      "Iteration: 1220  Loss: 0.0025643729604780674  Accuracy: 55 %\n",
      "Iteration: 1230  Loss: 0.015142402611672878  Accuracy: 57 %\n",
      "Iteration: 1240  Loss: 0.03465895727276802  Accuracy: 56 %\n",
      "Iteration: 1250  Loss: 0.08199949562549591  Accuracy: 56 %\n",
      "Iteration: 1260  Loss: 0.018136486411094666  Accuracy: 55 %\n",
      "Iteration: 1270  Loss: 0.00044213293585926294  Accuracy: 55 %\n",
      "Iteration: 1280  Loss: 0.0028869437519460917  Accuracy: 55 %\n",
      "Iteration: 1290  Loss: 0.01044901367276907  Accuracy: 56 %\n",
      "Iteration: 1300  Loss: 0.03226904943585396  Accuracy: 56 %\n",
      "Iteration: 1310  Loss: 0.0027920149732381105  Accuracy: 58 %\n",
      "Iteration: 1320  Loss: 1.3415018656814937e-05  Accuracy: 57 %\n",
      "Iteration: 1330  Loss: 0.0009399843402206898  Accuracy: 58 %\n",
      "Iteration: 1340  Loss: 0.0017937517259269953  Accuracy: 57 %\n",
      "Iteration: 1350  Loss: 0.0010294914245605469  Accuracy: 58 %\n",
      "Iteration: 1360  Loss: 0.0003422164882067591  Accuracy: 55 %\n",
      "Iteration: 1370  Loss: 0.0011566210305318236  Accuracy: 56 %\n",
      "Iteration: 1380  Loss: 8.74424003995955e-05  Accuracy: 56 %\n",
      "Iteration: 1390  Loss: 4.0531158447265625e-05  Accuracy: 56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1400  Loss: 3.369331534486264e-05  Accuracy: 55 %\n",
      "Iteration: 1410  Loss: 0.00014613628445658833  Accuracy: 55 %\n",
      "Iteration: 1420  Loss: 0.00010948658018605784  Accuracy: 55 %\n",
      "Iteration: 1430  Loss: 3.814697322468419e-07  Accuracy: 55 %\n",
      "Iteration: 1440  Loss: 5.188941941014491e-05  Accuracy: 55 %\n",
      "Iteration: 1450  Loss: 0.0001528930733911693  Accuracy: 55 %\n",
      "Iteration: 1460  Loss: 6.967544322833419e-05  Accuracy: 55 %\n",
      "Iteration: 1470  Loss: 4.413604619912803e-05  Accuracy: 55 %\n",
      "Iteration: 1480  Loss: 8.425712439930066e-05  Accuracy: 55 %\n",
      "Iteration: 1490  Loss: 3.2482148526469246e-05  Accuracy: 55 %\n",
      "Iteration: 1500  Loss: 1.2245178368175402e-05  Accuracy: 55 %\n",
      "Iteration: 1510  Loss: 1.202583280246472e-05  Accuracy: 55 %\n",
      "Iteration: 1520  Loss: 5.824089021189138e-05  Accuracy: 55 %\n",
      "Iteration: 1530  Loss: 4.218578396830708e-05  Accuracy: 55 %\n",
      "Iteration: 1540  Loss: 1.2715658215256553e-07  Accuracy: 55 %\n",
      "Iteration: 1550  Loss: 2.192497231590096e-05  Accuracy: 55 %\n",
      "Iteration: 1560  Loss: 6.118774763308465e-05  Accuracy: 55 %\n",
      "Iteration: 1570  Loss: 3.1995772587833926e-05  Accuracy: 55 %\n",
      "Iteration: 1580  Loss: 2.38895408983808e-05  Accuracy: 55 %\n",
      "Iteration: 1590  Loss: 4.335403355071321e-05  Accuracy: 55 %\n",
      "Iteration: 1600  Loss: 1.772880568751134e-05  Accuracy: 55 %\n",
      "Iteration: 1610  Loss: 6.8759918576688506e-06  Accuracy: 55 %\n",
      "Iteration: 1620  Loss: 6.742477580701234e-06  Accuracy: 55 %\n",
      "Iteration: 1630  Loss: 3.510475289658643e-05  Accuracy: 55 %\n",
      "Iteration: 1640  Loss: 2.4290084184031002e-05  Accuracy: 55 %\n",
      "Iteration: 1650  Loss: 6.357829107628277e-08  Accuracy: 55 %\n",
      "Iteration: 1660  Loss: 1.3208389646024443e-05  Accuracy: 55 %\n",
      "Iteration: 1670  Loss: 3.61442580469884e-05  Accuracy: 55 %\n",
      "Iteration: 1680  Loss: 2.022743137786165e-05  Accuracy: 55 %\n",
      "Iteration: 1690  Loss: 1.5563964552711695e-05  Accuracy: 55 %\n",
      "Iteration: 1700  Loss: 2.7933121600653976e-05  Accuracy: 55 %\n",
      "Iteration: 1710  Loss: 1.1625289516814519e-05  Accuracy: 55 %\n",
      "Iteration: 1720  Loss: 4.673004241340095e-06  Accuracy: 55 %\n",
      "Iteration: 1730  Loss: 4.4918060666532256e-06  Accuracy: 55 %\n",
      "Iteration: 1740  Loss: 2.4309158106916584e-05  Accuracy: 55 %\n",
      "Iteration: 1750  Loss: 1.61647803906817e-05  Accuracy: 55 %\n",
      "Iteration: 1760  Loss: 0.0  Accuracy: 55 %\n",
      "Iteration: 1770  Loss: 9.021759069582913e-06  Accuracy: 55 %\n",
      "Iteration: 1780  Loss: 2.444267192913685e-05  Accuracy: 55 %\n",
      "Iteration: 1790  Loss: 1.4486312466033269e-05  Accuracy: 55 %\n",
      "Iteration: 1800  Loss: 1.1186599294887856e-05  Accuracy: 55 %\n",
      "Iteration: 1810  Loss: 1.9931792849092744e-05  Accuracy: 55 %\n",
      "Iteration: 1820  Loss: 8.36372419144027e-06  Accuracy: 55 %\n",
      "Iteration: 1830  Loss: 3.43322744811303e-06  Accuracy: 55 %\n",
      "Iteration: 1840  Loss: 3.280639703007182e-06  Accuracy: 55 %\n",
      "Iteration: 1850  Loss: 1.812934897316154e-05  Accuracy: 55 %\n",
      "Iteration: 1860  Loss: 1.1682510375976562e-05  Accuracy: 55 %\n",
      "Iteration: 1870  Loss: 0.0  Accuracy: 55 %\n",
      "Iteration: 1880  Loss: 6.666183253400959e-06  Accuracy: 55 %\n",
      "Iteration: 1890  Loss: 1.7833710444392636e-05  Accuracy: 55 %\n",
      "Iteration: 1900  Loss: 1.107215848605847e-05  Accuracy: 55 %\n",
      "Iteration: 1910  Loss: 8.516311936546117e-06  Accuracy: 55 %\n",
      "Iteration: 1920  Loss: 1.5144348253670614e-05  Accuracy: 55 %\n",
      "Iteration: 1930  Loss: 6.361007763189264e-06  Accuracy: 55 %\n",
      "Iteration: 1940  Loss: 2.6798247745318804e-06  Accuracy: 55 %\n",
      "Iteration: 1950  Loss: 2.517700295356917e-06  Accuracy: 55 %\n",
      "Iteration: 1960  Loss: 1.4152527000987902e-05  Accuracy: 55 %\n",
      "Iteration: 1970  Loss: 8.926391274144407e-06  Accuracy: 55 %\n",
      "Iteration: 1980  Loss: 0.0  Accuracy: 55 %\n",
      "Iteration: 1990  Loss: 5.207061803957913e-06  Accuracy: 55 %\n",
      "Iteration: 2000  Loss: 1.357078508590348e-05  Accuracy: 55 %\n",
      "Iteration: 2010  Loss: 8.80241350387223e-06  Accuracy: 55 %\n",
      "Iteration: 2020  Loss: 6.656646746705519e-06  Accuracy: 55 %\n",
      "Iteration: 2030  Loss: 1.1997222827631049e-05  Accuracy: 55 %\n",
      "Iteration: 2040  Loss: 5.0163271225756034e-06  Accuracy: 55 %\n",
      "Iteration: 2050  Loss: 2.1457672119140625e-06  Accuracy: 55 %\n",
      "Iteration: 2060  Loss: 1.9741057712963084e-06  Accuracy: 55 %\n",
      "Iteration: 2070  Loss: 1.1434554835432209e-05  Accuracy: 55 %\n",
      "Iteration: 2080  Loss: 6.9522857302217744e-06  Accuracy: 55 %\n",
      "Iteration: 2090  Loss: 0.0  Accuracy: 55 %\n",
      "Iteration: 2100  Loss: 4.167556653555948e-06  Accuracy: 55 %\n",
      "Iteration: 2110  Loss: 1.0719299098127522e-05  Accuracy: 55 %\n",
      "Iteration: 2120  Loss: 7.23838820704259e-06  Accuracy: 55 %\n",
      "Iteration: 2130  Loss: 5.302429144649068e-06  Accuracy: 55 %\n",
      "Iteration: 2140  Loss: 9.746551768330391e-06  Accuracy: 55 %\n",
      "Iteration: 2150  Loss: 4.0340423765883315e-06  Accuracy: 55 %\n",
      "Iteration: 2160  Loss: 1.783370976227161e-06  Accuracy: 55 %\n",
      "Iteration: 2170  Loss: 1.640319851503591e-06  Accuracy: 55 %\n",
      "Iteration: 2180  Loss: 9.412765393790323e-06  Accuracy: 55 %\n",
      "Iteration: 2190  Loss: 5.655288532580016e-06  Accuracy: 55 %\n",
      "Iteration: 2200  Loss: 0.0  Accuracy: 55 %\n",
      "Iteration: 2210  Loss: 3.3855437777674524e-06  Accuracy: 55 %\n",
      "Iteration: 2220  Loss: 8.640289706818294e-06  Accuracy: 55 %\n",
      "Iteration: 2230  Loss: 6.046295311534777e-06  Accuracy: 55 %\n",
      "Iteration: 2240  Loss: 4.329681360104587e-06  Accuracy: 55 %\n",
      "Iteration: 2250  Loss: 8.134841664286796e-06  Accuracy: 55 %\n",
      "Iteration: 2260  Loss: 3.356933575560106e-06  Accuracy: 55 %\n",
      "Iteration: 2270  Loss: 1.516342194918252e-06  Accuracy: 55 %\n",
      "Iteration: 2280  Loss: 1.325607286162267e-06  Accuracy: 55 %\n",
      "Iteration: 2290  Loss: 7.877350071794353e-06  Accuracy: 55 %\n",
      "Iteration: 2300  Loss: 4.692077709478326e-06  Accuracy: 55 %\n",
      "Iteration: 2310  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 2320  Loss: 2.8133392788731726e-06  Accuracy: 56 %\n",
      "Iteration: 2330  Loss: 7.123946943465853e-06  Accuracy: 56 %\n",
      "Iteration: 2340  Loss: 5.14984139954322e-06  Accuracy: 56 %\n",
      "Iteration: 2350  Loss: 3.6334990909381304e-06  Accuracy: 56 %\n",
      "Iteration: 2360  Loss: 6.809234491811367e-06  Accuracy: 56 %\n",
      "Iteration: 2370  Loss: 2.8133392788731726e-06  Accuracy: 56 %\n",
      "Iteration: 2380  Loss: 1.2779236158166896e-06  Accuracy: 56 %\n",
      "Iteration: 2390  Loss: 1.1062621751989354e-06  Accuracy: 56 %\n",
      "Iteration: 2400  Loss: 6.704330644424772e-06  Accuracy: 56 %\n",
      "Iteration: 2410  Loss: 3.929138074454386e-06  Accuracy: 56 %\n",
      "Iteration: 2420  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 2430  Loss: 2.384185791015625e-06  Accuracy: 56 %\n",
      "Iteration: 2440  Loss: 5.9223175412626006e-06  Accuracy: 56 %\n",
      "Iteration: 2450  Loss: 4.415512194100302e-06  Accuracy: 56 %\n",
      "Iteration: 2460  Loss: 3.089904794251197e-06  Accuracy: 56 %\n",
      "Iteration: 2470  Loss: 5.807876732433215e-06  Accuracy: 56 %\n",
      "Iteration: 2480  Loss: 2.384185791015625e-06  Accuracy: 56 %\n",
      "Iteration: 2490  Loss: 1.0871887070607045e-06  Accuracy: 56 %\n",
      "Iteration: 2500  Loss: 9.632110504753655e-07  Accuracy: 56 %\n",
      "Iteration: 2510  Loss: 5.769729796156753e-06  Accuracy: 56 %\n",
      "Iteration: 2520  Loss: 3.337860107421875e-06  Accuracy: 56 %\n",
      "Iteration: 2530  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 2540  Loss: 2.040863137153792e-06  Accuracy: 56 %\n",
      "Iteration: 2550  Loss: 5.0067901611328125e-06  Accuracy: 56 %\n",
      "Iteration: 2560  Loss: 3.843307695206022e-06  Accuracy: 56 %\n",
      "Iteration: 2570  Loss: 2.6226043701171875e-06  Accuracy: 56 %\n",
      "Iteration: 2580  Loss: 5.0067901611328125e-06  Accuracy: 56 %\n",
      "Iteration: 2590  Loss: 2.040863137153792e-06  Accuracy: 56 %\n",
      "Iteration: 2600  Loss: 1.0013579867518274e-06  Accuracy: 56 %\n",
      "Iteration: 2610  Loss: 8.1062319168268e-07  Accuracy: 56 %\n",
      "Iteration: 2620  Loss: 4.940032795275329e-06  Accuracy: 56 %\n",
      "Iteration: 2630  Loss: 2.86102294921875e-06  Accuracy: 56 %\n",
      "Iteration: 2640  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 2650  Loss: 1.7547607740198146e-06  Accuracy: 56 %\n",
      "Iteration: 2660  Loss: 4.262923994247103e-06  Accuracy: 56 %\n",
      "Iteration: 2670  Loss: 3.3473968414909905e-06  Accuracy: 56 %\n",
      "Iteration: 2680  Loss: 2.231597818536102e-06  Accuracy: 56 %\n",
      "Iteration: 2690  Loss: 4.367828296381049e-06  Accuracy: 56 %\n",
      "Iteration: 2700  Loss: 1.7738342421580455e-06  Accuracy: 56 %\n",
      "Iteration: 2710  Loss: 8.964538551481382e-07  Accuracy: 56 %\n",
      "Iteration: 2720  Loss: 7.05719003235572e-07  Accuracy: 56 %\n",
      "Iteration: 2730  Loss: 4.320144853409147e-06  Accuracy: 56 %\n",
      "Iteration: 2740  Loss: 2.4890898657758953e-06  Accuracy: 56 %\n",
      "Iteration: 2750  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 2760  Loss: 1.5068054608491366e-06  Accuracy: 56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2770  Loss: 3.643035825007246e-06  Accuracy: 56 %\n",
      "Iteration: 2780  Loss: 2.9468535558407893e-06  Accuracy: 56 %\n",
      "Iteration: 2790  Loss: 1.9359588350198464e-06  Accuracy: 56 %\n",
      "Iteration: 2800  Loss: 3.824234227067791e-06  Accuracy: 56 %\n",
      "Iteration: 2810  Loss: 1.535415663056483e-06  Accuracy: 56 %\n",
      "Iteration: 2820  Loss: 7.438659395120339e-07  Accuracy: 56 %\n",
      "Iteration: 2830  Loss: 6.294250738392293e-07  Accuracy: 56 %\n",
      "Iteration: 2840  Loss: 3.776550329348538e-06  Accuracy: 56 %\n",
      "Iteration: 2850  Loss: 2.174377414121409e-06  Accuracy: 56 %\n",
      "Iteration: 2860  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 2870  Loss: 1.325607286162267e-06  Accuracy: 56 %\n",
      "Iteration: 2880  Loss: 3.1375884645967744e-06  Accuracy: 56 %\n",
      "Iteration: 2890  Loss: 2.6226043701171875e-06  Accuracy: 56 %\n",
      "Iteration: 2900  Loss: 1.6880035218491685e-06  Accuracy: 56 %\n",
      "Iteration: 2910  Loss: 3.3664703096292214e-06  Accuracy: 56 %\n",
      "Iteration: 2920  Loss: 1.306533818024036e-06  Accuracy: 56 %\n",
      "Iteration: 2930  Loss: 6.866455350973411e-07  Accuracy: 56 %\n",
      "Iteration: 2940  Loss: 5.531310875994677e-07  Accuracy: 56 %\n",
      "Iteration: 2950  Loss: 3.356933575560106e-06  Accuracy: 56 %\n",
      "Iteration: 2960  Loss: 1.888275164674269e-06  Accuracy: 56 %\n",
      "Iteration: 2970  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 2980  Loss: 1.163482693300466e-06  Accuracy: 56 %\n",
      "Iteration: 2990  Loss: 2.727508444877458e-06  Accuracy: 56 %\n",
      "Iteration: 3000  Loss: 2.3365021206700476e-06  Accuracy: 56 %\n",
      "Iteration: 3010  Loss: 1.5258789289873675e-06  Accuracy: 56 %\n",
      "Iteration: 3020  Loss: 3.0231476557673886e-06  Accuracy: 56 %\n",
      "Iteration: 3030  Loss: 1.163482693300466e-06  Accuracy: 56 %\n",
      "Iteration: 3040  Loss: 6.389618079083448e-07  Accuracy: 56 %\n",
      "Iteration: 3050  Loss: 4.76837158203125e-07  Accuracy: 56 %\n",
      "Iteration: 3060  Loss: 2.9754637580481358e-06  Accuracy: 56 %\n",
      "Iteration: 3070  Loss: 1.640319851503591e-06  Accuracy: 56 %\n",
      "Iteration: 3080  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 3090  Loss: 1.0108947208209429e-06  Accuracy: 56 %\n",
      "Iteration: 3100  Loss: 2.4127959932229714e-06  Accuracy: 56 %\n",
      "Iteration: 3110  Loss: 2.098083541568485e-06  Accuracy: 56 %\n",
      "Iteration: 3120  Loss: 1.287460349885805e-06  Accuracy: 56 %\n",
      "Iteration: 3130  Loss: 2.7179717108083423e-06  Accuracy: 56 %\n",
      "Iteration: 3140  Loss: 1.058578504853358e-06  Accuracy: 56 %\n",
      "Iteration: 3150  Loss: 5.722046125811175e-07  Accuracy: 56 %\n",
      "Iteration: 3160  Loss: 4.1007996287589776e-07  Accuracy: 56 %\n",
      "Iteration: 3170  Loss: 2.651214572324534e-06  Accuracy: 56 %\n",
      "Iteration: 3180  Loss: 1.4591216768167214e-06  Accuracy: 56 %\n",
      "Iteration: 3190  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 3200  Loss: 9.155273232863692e-07  Accuracy: 56 %\n",
      "Iteration: 3210  Loss: 2.1076202756376006e-06  Accuracy: 56 %\n",
      "Iteration: 3220  Loss: 1.888275164674269e-06  Accuracy: 56 %\n",
      "Iteration: 3230  Loss: 1.1539459592313506e-06  Accuracy: 56 %\n",
      "Iteration: 3240  Loss: 2.441406195430318e-06  Accuracy: 56 %\n",
      "Iteration: 3250  Loss: 9.059905892172537e-07  Accuracy: 56 %\n",
      "Iteration: 3260  Loss: 5.245208853921213e-07  Accuracy: 56 %\n",
      "Iteration: 3270  Loss: 3.9100646631595737e-07  Accuracy: 56 %\n",
      "Iteration: 3280  Loss: 2.3555755888082786e-06  Accuracy: 56 %\n",
      "Iteration: 3290  Loss: 1.325607286162267e-06  Accuracy: 56 %\n",
      "Iteration: 3300  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 3310  Loss: 8.392333938900265e-07  Accuracy: 56 %\n",
      "Iteration: 3320  Loss: 1.8787384306051536e-06  Accuracy: 56 %\n",
      "Iteration: 3330  Loss: 1.678466787780053e-06  Accuracy: 56 %\n",
      "Iteration: 3340  Loss: 1.0490417707842425e-06  Accuracy: 56 %\n",
      "Iteration: 3350  Loss: 2.212524350397871e-06  Accuracy: 56 %\n",
      "Iteration: 3360  Loss: 8.201599257517955e-07  Accuracy: 56 %\n",
      "Iteration: 3370  Loss: 4.577636616431846e-07  Accuracy: 56 %\n",
      "Iteration: 3380  Loss: 3.337860050578456e-07  Accuracy: 56 %\n",
      "Iteration: 3390  Loss: 2.117157009706716e-06  Accuracy: 56 %\n",
      "Iteration: 3400  Loss: 1.1539459592313506e-06  Accuracy: 56 %\n",
      "Iteration: 3410  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 3420  Loss: 7.438659395120339e-07  Accuracy: 56 %\n",
      "Iteration: 3430  Loss: 1.6689300537109375e-06  Accuracy: 56 %\n",
      "Iteration: 3440  Loss: 1.516342194918252e-06  Accuracy: 56 %\n",
      "Iteration: 3450  Loss: 8.964538551481382e-07  Accuracy: 56 %\n",
      "Iteration: 3460  Loss: 1.945495569088962e-06  Accuracy: 56 %\n",
      "Iteration: 3470  Loss: 7.438659395120339e-07  Accuracy: 56 %\n",
      "Iteration: 3480  Loss: 4.1961669694501325e-07  Accuracy: 56 %\n",
      "Iteration: 3490  Loss: 3.0517577442878974e-07  Accuracy: 56 %\n",
      "Iteration: 3500  Loss: 1.9359588350198464e-06  Accuracy: 56 %\n",
      "Iteration: 3510  Loss: 1.058578504853358e-06  Accuracy: 56 %\n",
      "Iteration: 3520  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 3530  Loss: 6.389618079083448e-07  Accuracy: 56 %\n",
      "Iteration: 3540  Loss: 1.4591216768167214e-06  Accuracy: 56 %\n",
      "Iteration: 3550  Loss: 1.392364538332913e-06  Accuracy: 56 %\n",
      "Iteration: 3560  Loss: 8.48770127959142e-07  Accuracy: 56 %\n",
      "Iteration: 3570  Loss: 1.7738342421580455e-06  Accuracy: 56 %\n",
      "Iteration: 3580  Loss: 6.771087441848067e-07  Accuracy: 56 %\n",
      "Iteration: 3590  Loss: 3.814697322468419e-07  Accuracy: 56 %\n",
      "Iteration: 3600  Loss: 2.47955313170678e-07  Accuracy: 56 %\n",
      "Iteration: 3610  Loss: 1.745224039950699e-06  Accuracy: 56 %\n",
      "Iteration: 3620  Loss: 9.441375823371345e-07  Accuracy: 56 %\n",
      "Iteration: 3630  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 3640  Loss: 6.00814814788464e-07  Accuracy: 56 %\n",
      "Iteration: 3650  Loss: 1.3160705520931515e-06  Accuracy: 56 %\n",
      "Iteration: 3660  Loss: 1.2588501476784586e-06  Accuracy: 56 %\n",
      "Iteration: 3670  Loss: 7.343292054429185e-07  Accuracy: 56 %\n",
      "Iteration: 3680  Loss: 1.5830993334020604e-06  Accuracy: 56 %\n",
      "Iteration: 3690  Loss: 6.103515488575795e-07  Accuracy: 56 %\n",
      "Iteration: 3700  Loss: 3.52859501617786e-07  Accuracy: 56 %\n",
      "Iteration: 3710  Loss: 2.384185791015625e-07  Accuracy: 56 %\n",
      "Iteration: 3720  Loss: 1.6021728015402914e-06  Accuracy: 56 %\n",
      "Iteration: 3730  Loss: 8.392333938900265e-07  Accuracy: 56 %\n",
      "Iteration: 3740  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 3750  Loss: 5.435943535303522e-07  Accuracy: 56 %\n",
      "Iteration: 3760  Loss: 1.1920928955078125e-06  Accuracy: 56 %\n",
      "Iteration: 3770  Loss: 1.144409225162235e-06  Accuracy: 56 %\n",
      "Iteration: 3780  Loss: 6.484985419774603e-07  Accuracy: 56 %\n",
      "Iteration: 3790  Loss: 1.4209747405402595e-06  Accuracy: 56 %\n",
      "Iteration: 3800  Loss: 5.340576194612368e-07  Accuracy: 56 %\n",
      "Iteration: 3810  Loss: 3.4332276754867053e-07  Accuracy: 56 %\n",
      "Iteration: 3820  Loss: 2.0027160019253643e-07  Accuracy: 56 %\n",
      "Iteration: 3830  Loss: 1.430511474609375e-06  Accuracy: 56 %\n",
      "Iteration: 3840  Loss: 7.629394644936838e-07  Accuracy: 56 %\n",
      "Iteration: 3850  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 3860  Loss: 4.95910626341356e-07  Accuracy: 56 %\n",
      "Iteration: 3870  Loss: 1.0490417707842425e-06  Accuracy: 56 %\n",
      "Iteration: 3880  Loss: 1.039505036715127e-06  Accuracy: 56 %\n",
      "Iteration: 3890  Loss: 5.722046125811175e-07  Accuracy: 56 %\n",
      "Iteration: 3900  Loss: 1.306533818024036e-06  Accuracy: 56 %\n",
      "Iteration: 3910  Loss: 4.673004241340095e-07  Accuracy: 56 %\n",
      "Iteration: 3920  Loss: 3.337860050578456e-07  Accuracy: 56 %\n",
      "Iteration: 3930  Loss: 1.6212463549436507e-07  Accuracy: 56 %\n",
      "Iteration: 3940  Loss: 1.2779236158166896e-06  Accuracy: 56 %\n",
      "Iteration: 3950  Loss: 6.866455350973411e-07  Accuracy: 56 %\n",
      "Iteration: 3960  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 3970  Loss: 4.577636616431846e-07  Accuracy: 56 %\n",
      "Iteration: 3980  Loss: 9.250641141989036e-07  Accuracy: 56 %\n",
      "Iteration: 3990  Loss: 9.250641141989036e-07  Accuracy: 56 %\n",
      "Iteration: 4000  Loss: 5.149841513230058e-07  Accuracy: 56 %\n",
      "Iteration: 4010  Loss: 1.2111663636460435e-06  Accuracy: 56 %\n",
      "Iteration: 4020  Loss: 4.1961669694501325e-07  Accuracy: 56 %\n",
      "Iteration: 4030  Loss: 2.7656554379973386e-07  Accuracy: 56 %\n",
      "Iteration: 4040  Loss: 1.6212463549436507e-07  Accuracy: 56 %\n",
      "Iteration: 4050  Loss: 1.1730194273695815e-06  Accuracy: 56 %\n",
      "Iteration: 4060  Loss: 5.912780807193485e-07  Accuracy: 56 %\n",
      "Iteration: 4070  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 4080  Loss: 4.0054320038507285e-07  Accuracy: 56 %\n",
      "Iteration: 4090  Loss: 8.583068620282575e-07  Accuracy: 56 %\n",
      "Iteration: 4100  Loss: 8.583068620282575e-07  Accuracy: 56 %\n",
      "Iteration: 4110  Loss: 4.482269275740691e-07  Accuracy: 56 %\n",
      "Iteration: 4120  Loss: 1.09672544112982e-06  Accuracy: 56 %\n",
      "Iteration: 4130  Loss: 4.0054320038507285e-07  Accuracy: 56 %\n",
      "Iteration: 4140  Loss: 2.288818308215923e-07  Accuracy: 56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4150  Loss: 1.335144048653092e-07  Accuracy: 56 %\n",
      "Iteration: 4160  Loss: 1.0490417707842425e-06  Accuracy: 56 %\n",
      "Iteration: 4170  Loss: 5.435943535303522e-07  Accuracy: 56 %\n",
      "Iteration: 4180  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 4190  Loss: 3.4332276754867053e-07  Accuracy: 56 %\n",
      "Iteration: 4200  Loss: 7.724761985627993e-07  Accuracy: 56 %\n",
      "Iteration: 4210  Loss: 7.820129326319147e-07  Accuracy: 56 %\n",
      "Iteration: 4220  Loss: 4.3869019350495364e-07  Accuracy: 56 %\n",
      "Iteration: 4230  Loss: 1.0013579867518274e-06  Accuracy: 56 %\n",
      "Iteration: 4240  Loss: 3.7193296975601697e-07  Accuracy: 56 %\n",
      "Iteration: 4250  Loss: 2.288818308215923e-07  Accuracy: 56 %\n",
      "Iteration: 4260  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 4270  Loss: 9.441375823371345e-07  Accuracy: 56 %\n",
      "Iteration: 4280  Loss: 5.149841513230058e-07  Accuracy: 56 %\n",
      "Iteration: 4290  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 4300  Loss: 3.1471253691961465e-07  Accuracy: 56 %\n",
      "Iteration: 4310  Loss: 6.961822691664565e-07  Accuracy: 56 %\n",
      "Iteration: 4320  Loss: 7.24792471373803e-07  Accuracy: 56 %\n",
      "Iteration: 4330  Loss: 3.9100646631595737e-07  Accuracy: 56 %\n",
      "Iteration: 4340  Loss: 9.34600848268019e-07  Accuracy: 56 %\n",
      "Iteration: 4350  Loss: 3.52859501617786e-07  Accuracy: 56 %\n",
      "Iteration: 4360  Loss: 2.0980834847250662e-07  Accuracy: 56 %\n",
      "Iteration: 4370  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 4380  Loss: 8.773803870099073e-07  Accuracy: 56 %\n",
      "Iteration: 4390  Loss: 4.577636616431846e-07  Accuracy: 56 %\n",
      "Iteration: 4400  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 4410  Loss: 2.8610230629055877e-07  Accuracy: 56 %\n",
      "Iteration: 4420  Loss: 6.294250738392293e-07  Accuracy: 56 %\n",
      "Iteration: 4430  Loss: 6.580352760465757e-07  Accuracy: 56 %\n",
      "Iteration: 4440  Loss: 3.2424927098873013e-07  Accuracy: 56 %\n",
      "Iteration: 4450  Loss: 8.678436529407918e-07  Accuracy: 56 %\n",
      "Iteration: 4460  Loss: 3.337860050578456e-07  Accuracy: 56 %\n",
      "Iteration: 4470  Loss: 1.6212463549436507e-07  Accuracy: 56 %\n",
      "Iteration: 4480  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 4490  Loss: 7.915496667010302e-07  Accuracy: 56 %\n",
      "Iteration: 4500  Loss: 4.1961669694501325e-07  Accuracy: 56 %\n",
      "Iteration: 4510  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 4520  Loss: 2.7656554379973386e-07  Accuracy: 56 %\n",
      "Iteration: 4530  Loss: 5.626678216685832e-07  Accuracy: 56 %\n",
      "Iteration: 4540  Loss: 6.00814814788464e-07  Accuracy: 56 %\n",
      "Iteration: 4550  Loss: 2.7656554379973386e-07  Accuracy: 56 %\n",
      "Iteration: 4560  Loss: 8.010864007701457e-07  Accuracy: 56 %\n",
      "Iteration: 4570  Loss: 2.9563904035967425e-07  Accuracy: 56 %\n",
      "Iteration: 4580  Loss: 1.7166138377433526e-07  Accuracy: 56 %\n",
      "Iteration: 4590  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 4600  Loss: 7.534027304245683e-07  Accuracy: 56 %\n",
      "Iteration: 4610  Loss: 3.7193296975601697e-07  Accuracy: 56 %\n",
      "Iteration: 4620  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 4630  Loss: 2.47955313170678e-07  Accuracy: 56 %\n",
      "Iteration: 4640  Loss: 5.149841513230058e-07  Accuracy: 56 %\n",
      "Iteration: 4650  Loss: 5.531310875994677e-07  Accuracy: 56 %\n",
      "Iteration: 4660  Loss: 2.47955313170678e-07  Accuracy: 56 %\n",
      "Iteration: 4670  Loss: 7.629394644936838e-07  Accuracy: 56 %\n",
      "Iteration: 4680  Loss: 2.574920756615029e-07  Accuracy: 56 %\n",
      "Iteration: 4690  Loss: 1.335144048653092e-07  Accuracy: 56 %\n",
      "Iteration: 4700  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 4710  Loss: 6.771087441848067e-07  Accuracy: 56 %\n",
      "Iteration: 4720  Loss: 3.337860050578456e-07  Accuracy: 56 %\n",
      "Iteration: 4730  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 4740  Loss: 2.0980834847250662e-07  Accuracy: 56 %\n",
      "Iteration: 4750  Loss: 4.577636616431846e-07  Accuracy: 56 %\n",
      "Iteration: 4760  Loss: 5.149841513230058e-07  Accuracy: 56 %\n",
      "Iteration: 4770  Loss: 2.288818308215923e-07  Accuracy: 56 %\n",
      "Iteration: 4780  Loss: 6.675720101156912e-07  Accuracy: 56 %\n",
      "Iteration: 4790  Loss: 2.384185791015625e-07  Accuracy: 56 %\n",
      "Iteration: 4800  Loss: 1.335144048653092e-07  Accuracy: 56 %\n",
      "Iteration: 4810  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 4820  Loss: 6.103515488575795e-07  Accuracy: 56 %\n",
      "Iteration: 4830  Loss: 3.337860050578456e-07  Accuracy: 56 %\n",
      "Iteration: 4840  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 4850  Loss: 2.0980834847250662e-07  Accuracy: 56 %\n",
      "Iteration: 4860  Loss: 4.2915343101412873e-07  Accuracy: 56 %\n",
      "Iteration: 4870  Loss: 4.482269275740691e-07  Accuracy: 56 %\n",
      "Iteration: 4880  Loss: 2.1934509675247682e-07  Accuracy: 56 %\n",
      "Iteration: 4890  Loss: 5.912780807193485e-07  Accuracy: 56 %\n",
      "Iteration: 4900  Loss: 1.9073486612342094e-07  Accuracy: 56 %\n",
      "Iteration: 4910  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 4920  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 4930  Loss: 5.626678216685832e-07  Accuracy: 56 %\n",
      "Iteration: 4940  Loss: 2.9563904035967425e-07  Accuracy: 56 %\n",
      "Iteration: 4950  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 4960  Loss: 2.0027160019253643e-07  Accuracy: 56 %\n",
      "Iteration: 4970  Loss: 3.7193296975601697e-07  Accuracy: 56 %\n",
      "Iteration: 4980  Loss: 4.0054320038507285e-07  Accuracy: 56 %\n",
      "Iteration: 4990  Loss: 2.1934509675247682e-07  Accuracy: 56 %\n",
      "Iteration: 5000  Loss: 5.245208853921213e-07  Accuracy: 56 %\n",
      "Iteration: 5010  Loss: 1.6212463549436507e-07  Accuracy: 56 %\n",
      "Iteration: 5020  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 5030  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 5040  Loss: 5.340576194612368e-07  Accuracy: 56 %\n",
      "Iteration: 5050  Loss: 2.47955313170678e-07  Accuracy: 56 %\n",
      "Iteration: 5060  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 5070  Loss: 1.7166138377433526e-07  Accuracy: 56 %\n",
      "Iteration: 5080  Loss: 3.337860050578456e-07  Accuracy: 56 %\n",
      "Iteration: 5090  Loss: 3.7193296975601697e-07  Accuracy: 56 %\n",
      "Iteration: 5100  Loss: 1.7166138377433526e-07  Accuracy: 56 %\n",
      "Iteration: 5110  Loss: 4.95910626341356e-07  Accuracy: 56 %\n",
      "Iteration: 5120  Loss: 1.4305115314527939e-07  Accuracy: 56 %\n",
      "Iteration: 5130  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 5140  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 5150  Loss: 4.76837158203125e-07  Accuracy: 56 %\n",
      "Iteration: 5160  Loss: 2.1934509675247682e-07  Accuracy: 56 %\n",
      "Iteration: 5170  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 5180  Loss: 1.8119811784345075e-07  Accuracy: 56 %\n",
      "Iteration: 5190  Loss: 3.0517577442878974e-07  Accuracy: 56 %\n",
      "Iteration: 5200  Loss: 3.2424927098873013e-07  Accuracy: 56 %\n",
      "Iteration: 5210  Loss: 1.5258788721439487e-07  Accuracy: 56 %\n",
      "Iteration: 5220  Loss: 4.673004241340095e-07  Accuracy: 56 %\n",
      "Iteration: 5230  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 5240  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 5250  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 5260  Loss: 4.3869019350495364e-07  Accuracy: 56 %\n",
      "Iteration: 5270  Loss: 2.0980834847250662e-07  Accuracy: 56 %\n",
      "Iteration: 5280  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 5290  Loss: 1.5258788721439487e-07  Accuracy: 56 %\n",
      "Iteration: 5300  Loss: 2.7656554379973386e-07  Accuracy: 56 %\n",
      "Iteration: 5310  Loss: 3.0517577442878974e-07  Accuracy: 56 %\n",
      "Iteration: 5320  Loss: 1.5258788721439487e-07  Accuracy: 56 %\n",
      "Iteration: 5330  Loss: 4.3869019350495364e-07  Accuracy: 56 %\n",
      "Iteration: 5340  Loss: 1.335144048653092e-07  Accuracy: 56 %\n",
      "Iteration: 5350  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 5360  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 5370  Loss: 4.0054320038507285e-07  Accuracy: 56 %\n",
      "Iteration: 5380  Loss: 1.8119811784345075e-07  Accuracy: 56 %\n",
      "Iteration: 5390  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 5400  Loss: 1.335144048653092e-07  Accuracy: 56 %\n",
      "Iteration: 5410  Loss: 2.384185791015625e-07  Accuracy: 56 %\n",
      "Iteration: 5420  Loss: 2.7656554379973386e-07  Accuracy: 56 %\n",
      "Iteration: 5430  Loss: 1.335144048653092e-07  Accuracy: 56 %\n",
      "Iteration: 5440  Loss: 3.623962356869015e-07  Accuracy: 56 %\n",
      "Iteration: 5450  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 5460  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 5470  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 5480  Loss: 3.7193296975601697e-07  Accuracy: 56 %\n",
      "Iteration: 5490  Loss: 1.7166138377433526e-07  Accuracy: 56 %\n",
      "Iteration: 5500  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 5510  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 5520  Loss: 2.1934509675247682e-07  Accuracy: 56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5530  Loss: 2.574920756615029e-07  Accuracy: 56 %\n",
      "Iteration: 5540  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 5550  Loss: 3.337860050578456e-07  Accuracy: 56 %\n",
      "Iteration: 5560  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 5570  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 5580  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 5590  Loss: 3.2424927098873013e-07  Accuracy: 56 %\n",
      "Iteration: 5600  Loss: 1.5258788721439487e-07  Accuracy: 56 %\n",
      "Iteration: 5610  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 5620  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 5630  Loss: 2.1934509675247682e-07  Accuracy: 56 %\n",
      "Iteration: 5640  Loss: 2.47955313170678e-07  Accuracy: 56 %\n",
      "Iteration: 5650  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 5660  Loss: 3.1471253691961465e-07  Accuracy: 56 %\n",
      "Iteration: 5670  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 5680  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 5690  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 5700  Loss: 2.7656554379973386e-07  Accuracy: 56 %\n",
      "Iteration: 5710  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 5720  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 5730  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 5740  Loss: 1.9073486612342094e-07  Accuracy: 56 %\n",
      "Iteration: 5750  Loss: 2.1934509675247682e-07  Accuracy: 56 %\n",
      "Iteration: 5760  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 5770  Loss: 3.2424927098873013e-07  Accuracy: 56 %\n",
      "Iteration: 5780  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 5790  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 5800  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 5810  Loss: 2.670288097306184e-07  Accuracy: 56 %\n",
      "Iteration: 5820  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 5830  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 5840  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 5850  Loss: 1.9073486612342094e-07  Accuracy: 56 %\n",
      "Iteration: 5860  Loss: 2.0980834847250662e-07  Accuracy: 56 %\n",
      "Iteration: 5870  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 5880  Loss: 2.9563904035967425e-07  Accuracy: 56 %\n",
      "Iteration: 5890  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 5900  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 5910  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 5920  Loss: 2.574920756615029e-07  Accuracy: 56 %\n",
      "Iteration: 5930  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 5940  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 5950  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 5960  Loss: 1.8119811784345075e-07  Accuracy: 56 %\n",
      "Iteration: 5970  Loss: 1.8119811784345075e-07  Accuracy: 56 %\n",
      "Iteration: 5980  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 5990  Loss: 2.670288097306184e-07  Accuracy: 56 %\n",
      "Iteration: 6000  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 6010  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 6020  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 6030  Loss: 2.1934509675247682e-07  Accuracy: 56 %\n",
      "Iteration: 6040  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 6050  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6060  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 6070  Loss: 1.6212463549436507e-07  Accuracy: 56 %\n",
      "Iteration: 6080  Loss: 1.5258788721439487e-07  Accuracy: 56 %\n",
      "Iteration: 6090  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 6100  Loss: 2.0027160019253643e-07  Accuracy: 56 %\n",
      "Iteration: 6110  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 6120  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6130  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 6140  Loss: 2.1934509675247682e-07  Accuracy: 56 %\n",
      "Iteration: 6150  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 6160  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6170  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6180  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 6190  Loss: 1.5258788721439487e-07  Accuracy: 56 %\n",
      "Iteration: 6200  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 6210  Loss: 2.0027160019253643e-07  Accuracy: 56 %\n",
      "Iteration: 6220  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 6230  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6240  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6250  Loss: 2.0027160019253643e-07  Accuracy: 56 %\n",
      "Iteration: 6260  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 6270  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6280  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6290  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 6300  Loss: 1.5258788721439487e-07  Accuracy: 56 %\n",
      "Iteration: 6310  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 6320  Loss: 1.9073486612342094e-07  Accuracy: 56 %\n",
      "Iteration: 6330  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 6340  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6350  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6360  Loss: 1.7166138377433526e-07  Accuracy: 56 %\n",
      "Iteration: 6370  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 6380  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6390  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6400  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 6410  Loss: 1.4305115314527939e-07  Accuracy: 56 %\n",
      "Iteration: 6420  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6430  Loss: 1.7166138377433526e-07  Accuracy: 56 %\n",
      "Iteration: 6440  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6450  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6460  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6470  Loss: 1.4305115314527939e-07  Accuracy: 56 %\n",
      "Iteration: 6480  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 6490  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6500  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6510  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 6520  Loss: 1.335144048653092e-07  Accuracy: 56 %\n",
      "Iteration: 6530  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6540  Loss: 1.7166138377433526e-07  Accuracy: 56 %\n",
      "Iteration: 6550  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6560  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6570  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6580  Loss: 1.4305115314527939e-07  Accuracy: 56 %\n",
      "Iteration: 6590  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 6600  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6610  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6620  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 6630  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 6640  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6650  Loss: 1.7166138377433526e-07  Accuracy: 56 %\n",
      "Iteration: 6660  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6670  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6680  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6690  Loss: 1.335144048653092e-07  Accuracy: 56 %\n",
      "Iteration: 6700  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 6710  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6720  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6730  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 6740  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 6750  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6760  Loss: 1.5258788721439487e-07  Accuracy: 56 %\n",
      "Iteration: 6770  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6780  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6790  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6800  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 6810  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6820  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6830  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6840  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 6850  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 6860  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6870  Loss: 1.4305115314527939e-07  Accuracy: 56 %\n",
      "Iteration: 6880  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6890  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6900  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6910  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 6920  Loss: 3.814697180359872e-08  Accuracy: 56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6930  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 6940  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 6950  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 6960  Loss: 8.583069188716763e-08  Accuracy: 56 %\n",
      "Iteration: 6970  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 6980  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 6990  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7000  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7010  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7020  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 7030  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 7040  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7050  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 7060  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 7070  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7080  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7090  Loss: 1.23977656585339e-07  Accuracy: 56 %\n",
      "Iteration: 7100  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7110  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7120  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7130  Loss: 1.1444091541079615e-07  Accuracy: 56 %\n",
      "Iteration: 7140  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 7150  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7160  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 7170  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 7180  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7190  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7200  Loss: 1.0490417423625331e-07  Accuracy: 56 %\n",
      "Iteration: 7210  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7220  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7230  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7240  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 7250  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 7260  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7270  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7280  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 7290  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7300  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7310  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 7320  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7330  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7340  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7350  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7360  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 7370  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7380  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7390  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 7400  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 7410  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7420  Loss: 9.536743306171047e-08  Accuracy: 56 %\n",
      "Iteration: 7430  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7440  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7450  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7460  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7470  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 7480  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7490  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7500  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 7510  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 7520  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7530  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7540  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7550  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7560  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7570  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7580  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 7590  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7600  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7610  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 7620  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 7630  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7640  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7650  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7660  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7670  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7680  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 7690  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 7700  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7710  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7720  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 7730  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 7740  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7750  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7760  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7770  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7780  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7790  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 7800  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 7810  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7820  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7830  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 7840  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 7850  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7860  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7870  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7880  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7890  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7900  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 7910  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 7920  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7930  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7940  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 7950  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 7960  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 7970  Loss: 7.629394360719743e-08  Accuracy: 56 %\n",
      "Iteration: 7980  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 7990  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 8000  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8010  Loss: 6.67572024326546e-08  Accuracy: 56 %\n",
      "Iteration: 8020  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8030  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8040  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8050  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8060  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 8070  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8080  Loss: 5.7220457705398076e-08  Accuracy: 56 %\n",
      "Iteration: 8090  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 8100  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 8110  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8120  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8130  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8140  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8150  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8160  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 8170  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 8180  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8190  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8200  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8210  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8220  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8230  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8240  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8250  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8260  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8270  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 8280  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8290  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8300  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8310  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8320  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8330  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8340  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8350  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8360  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8370  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8380  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 8390  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8400  Loss: 0.0  Accuracy: 56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8410  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8420  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8430  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8440  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8450  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 8460  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8470  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8480  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8490  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 8500  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8510  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8520  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8530  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8540  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8550  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8560  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8570  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8580  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8590  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8600  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 8610  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8620  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8630  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8640  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8650  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8660  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8670  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8680  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 8690  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8700  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8710  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 8720  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8730  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8740  Loss: 4.7683716530855236e-08  Accuracy: 56 %\n",
      "Iteration: 8750  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8760  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8770  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8780  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8790  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 8800  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8810  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8820  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 8830  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8840  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8850  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8860  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8870  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8880  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8890  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8900  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 8910  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8920  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8930  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 8940  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 8950  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8960  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 8970  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8980  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 8990  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9000  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9010  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9020  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9030  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9040  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9050  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9060  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9070  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9080  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9090  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9100  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9110  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9120  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9130  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9140  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9150  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9160  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9170  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9180  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9190  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9200  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9210  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9220  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9230  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9240  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9250  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9260  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9270  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9280  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9290  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9300  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9310  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9320  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9330  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9340  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9350  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9360  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9370  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9380  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9390  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9400  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9410  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9420  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9430  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9440  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9450  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9460  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9470  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9480  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9490  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9500  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9510  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9520  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9530  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9540  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9550  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9560  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9570  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9580  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9590  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9600  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9610  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9620  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9630  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9640  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9650  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9660  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9670  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9680  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9690  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9700  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9710  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9720  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9730  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9740  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9750  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9760  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9770  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9780  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9790  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9800  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9810  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9820  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9830  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9840  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9850  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9860  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9870  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9880  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 9890  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9900  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9910  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9920  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9930  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 9940  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9950  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 9960  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9970  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9980  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 9990  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 10000  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10010  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10020  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10030  Loss: 9.53674295089968e-09  Accuracy: 56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10040  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 10050  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10060  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 10070  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10080  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10090  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10100  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 10110  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10120  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10130  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10140  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 10150  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 10160  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10170  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 10180  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10190  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10200  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10210  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 10220  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10230  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10240  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 10250  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 10260  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10270  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10280  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 10290  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10300  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10310  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10320  Loss: 2.8610228852699038e-08  Accuracy: 56 %\n",
      "Iteration: 10330  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10340  Loss: 0.0  Accuracy: 56 %\n",
      "Iteration: 10350  Loss: 1.907348590179936e-08  Accuracy: 56 %\n",
      "Iteration: 10360  Loss: 9.53674295089968e-09  Accuracy: 56 %\n",
      "Iteration: 10370  Loss: 3.814697180359872e-08  Accuracy: 56 %\n",
      "Iteration: 10380  Loss: 0.0  Accuracy: 56 %\n"
     ]
    }
   ],
   "source": [
    "# Create RNN\n",
    "dtype = torch.FloatTensor\n",
    "input_dim = 1000    # input dimension\n",
    "hidden_dim = 200  # hidden layer dimension\n",
    "layer_dim = 6     # number of hidden layers\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.05\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "seq_dim = 25  \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        train  = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "            \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train.float())\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 10 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for signals, labels in test_loader:\n",
    "                signals = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(signals.float())\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if count % 1 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
