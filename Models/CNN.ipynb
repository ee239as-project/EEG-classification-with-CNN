{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Utils.preprocess_util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-61e5eea7dd03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_preprocess_eeg_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Desktop\\UCLA\\deep learning\\final_project\\project_data\\project\\Utils\\preprocess_util.py\u001b[0m in \u001b[0;36mload_preprocess_eeg_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mX_train_modified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexponential_running_standardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mX_valid_modified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexponential_running_standardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\UCLA\\deep learning\\final_project\\project_data\\project\\Utils\\preprocess_util.py\u001b[0m in \u001b[0;36mexponential_running_standardize\u001b[1;34m(data, factor_new, eps)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mmeaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mewm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfactor_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mdemeaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmeaned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0msquared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdemeaned\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdemeaned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0msquare_ewmed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mewm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfactor_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\pandas\\core\\window.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2323\u001b[0m         \"\"\"\n\u001b[0;32m   2324\u001b[0m         \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_window_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2325\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ewma'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2327\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ewm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\pandas\\core\\window.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m   2309\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2311\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2313\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ewm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\pandas\\core\\window.py\u001b[0m in \u001b[0;36m_wrap_results\u001b[1;34m(self, results, blocks, obj)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_center_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                        copy=copy, sort=sort)\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    424\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m    425\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                 copy=self.copy)\n\u001b[0m\u001b[0;32m    427\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   2050\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2052\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2053\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2054\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (443, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"X_test.npy\")[:,0:22,:]\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")[:,0:22,:]\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "print ('Test data shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(  X_train_valid, y_train_valid, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_modified =[]\n",
    "X_valid_modified =[]\n",
    "X_test_modified =[]\n",
    "\n",
    "for xi in X_train:\n",
    "    X_train_modified.append(exponential_running_standardize(xi.T, eps=1e-4))\n",
    "\n",
    "for xi in X_valid:\n",
    "    X_valid_modified.append(exponential_running_standardize(xi.T, eps=1e-4))\n",
    "    \n",
    "for xi in X_test:\n",
    "    X_test_modified.append(exponential_running_standardize(xi.T, eps=1e-4))\n",
    "    \n",
    "\n",
    "X_train = np.array(X_train_modified)\n",
    "X_valid = np.array(X_valid_modified)\n",
    "X_test = np.array(X_test_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 1000, 22)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n",
      "\n",
      "Training data shape: (1417, 22, 1000)\n",
      "Valid data shape: (698, 22, 1000)\n",
      "Training target shape: (1417,)\n",
      "Valid target shape: (698,)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n",
    "print()\n",
    "\n",
    "X_train = np.transpose(X_train,[0,2,1])\n",
    "X_valid = np.transpose(X_valid,[0,2,1])\n",
    "X_test = np.transpose(X_test,[0,2,1])\n",
    "print ('Training data shape: {}'.format(X_train.shape))\n",
    "print ('Valid data shape: {}'.format(X_valid.shape))\n",
    "print ('Training target shape: {}'.format(y_train.shape))\n",
    "print ('Valid target shape: {}'.format(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = []\n",
    "for y in y_train:\n",
    "    value = np.abs(769-y)\n",
    "    Y_train.append(value)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "Y_valid = []\n",
    "for y in y_valid:\n",
    "    value = np.abs(769-y)\n",
    "    Y_valid.append(value)\n",
    "Y_valid = np.array(Y_valid)\n",
    "\n",
    "Y_test = []\n",
    "for y in y_test:\n",
    "    value = np.abs(769-y)\n",
    "    Y_test.append(value)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        a= x.view(x.size(0), -1)\n",
    "        return a\n",
    "    \n",
    "class threed_to_twod(nn.Module):\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        a = x.reshape(x.shape[0],x.shape[3],x.shape[1])\n",
    "        #print (a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-4.1479e-02],\n",
       "          [ 5.4421e-02],\n",
       "          [-2.1440e-02],\n",
       "          ...,\n",
       "          [ 5.1092e-02],\n",
       "          [ 2.2232e-02],\n",
       "          [-2.7714e-02]],\n",
       "\n",
       "         [[ 2.9388e-02],\n",
       "          [-6.6978e-03],\n",
       "          [ 5.4651e-02],\n",
       "          ...,\n",
       "          [-4.7515e-02],\n",
       "          [-2.3194e-02],\n",
       "          [-1.8357e-03]],\n",
       "\n",
       "         [[-2.7672e-03],\n",
       "          [-5.1530e-02],\n",
       "          [ 8.8983e-03],\n",
       "          ...,\n",
       "          [ 3.6804e-02],\n",
       "          [-3.0935e-02],\n",
       "          [ 4.8897e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6492e-02],\n",
       "          [-5.7524e-02],\n",
       "          [ 8.3678e-03],\n",
       "          ...,\n",
       "          [ 2.7051e-02],\n",
       "          [ 3.9018e-02],\n",
       "          [-2.9784e-02]],\n",
       "\n",
       "         [[ 1.5167e-02],\n",
       "          [ 5.1967e-02],\n",
       "          [-3.4041e-02],\n",
       "          ...,\n",
       "          [ 1.2670e-02],\n",
       "          [-5.1042e-02],\n",
       "          [ 5.3674e-02]],\n",
       "\n",
       "         [[-5.3158e-03],\n",
       "          [ 1.5690e-02],\n",
       "          [-5.1425e-02],\n",
       "          ...,\n",
       "          [ 4.0878e-02],\n",
       "          [-4.7672e-03],\n",
       "          [ 1.1077e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.2892e-02],\n",
       "          [ 4.8079e-02],\n",
       "          [ 2.9317e-02],\n",
       "          ...,\n",
       "          [-1.0470e-02],\n",
       "          [ 1.1823e-02],\n",
       "          [-1.8877e-02]],\n",
       "\n",
       "         [[ 5.5949e-02],\n",
       "          [ 3.5625e-02],\n",
       "          [-4.1454e-02],\n",
       "          ...,\n",
       "          [-2.7222e-02],\n",
       "          [ 5.2003e-02],\n",
       "          [-3.6949e-02]],\n",
       "\n",
       "         [[ 7.2413e-03],\n",
       "          [ 3.6183e-03],\n",
       "          [-4.0072e-02],\n",
       "          ...,\n",
       "          [-2.5339e-02],\n",
       "          [-7.9322e-03],\n",
       "          [ 3.9468e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.4929e-02],\n",
       "          [ 5.2485e-02],\n",
       "          [-5.2287e-02],\n",
       "          ...,\n",
       "          [ 3.9268e-02],\n",
       "          [ 3.7044e-02],\n",
       "          [-1.3355e-02]],\n",
       "\n",
       "         [[-2.7680e-02],\n",
       "          [-1.8308e-02],\n",
       "          [-2.8465e-02],\n",
       "          ...,\n",
       "          [-3.8376e-02],\n",
       "          [ 4.1984e-02],\n",
       "          [ 5.8238e-02]],\n",
       "\n",
       "         [[-4.8698e-02],\n",
       "          [ 1.9392e-02],\n",
       "          [ 4.3838e-02],\n",
       "          ...,\n",
       "          [ 9.6605e-03],\n",
       "          [-6.3085e-03],\n",
       "          [ 2.8231e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.0868e-02],\n",
       "          [ 4.0960e-02],\n",
       "          [ 1.9405e-02],\n",
       "          ...,\n",
       "          [-2.8435e-02],\n",
       "          [ 3.0651e-02],\n",
       "          [-5.7921e-02]],\n",
       "\n",
       "         [[ 4.4396e-02],\n",
       "          [-5.2878e-03],\n",
       "          [ 1.8017e-02],\n",
       "          ...,\n",
       "          [ 3.4340e-02],\n",
       "          [ 1.4265e-02],\n",
       "          [ 2.8062e-02]],\n",
       "\n",
       "         [[-5.3065e-02],\n",
       "          [-3.7874e-02],\n",
       "          [ 9.8128e-05],\n",
       "          ...,\n",
       "          [-5.5246e-02],\n",
       "          [ 5.4664e-02],\n",
       "          [ 6.5997e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.4067e-03],\n",
       "          [-4.5085e-02],\n",
       "          [-1.3161e-02],\n",
       "          ...,\n",
       "          [-4.6452e-02],\n",
       "          [ 3.9426e-02],\n",
       "          [ 2.3484e-02]],\n",
       "\n",
       "         [[-5.5508e-02],\n",
       "          [ 3.5508e-02],\n",
       "          [-1.8352e-02],\n",
       "          ...,\n",
       "          [ 2.6130e-03],\n",
       "          [-3.3031e-02],\n",
       "          [-5.4234e-02]],\n",
       "\n",
       "         [[-2.6314e-02],\n",
       "          [-1.7832e-02],\n",
       "          [ 3.5249e-02],\n",
       "          ...,\n",
       "          [ 3.6575e-02],\n",
       "          [ 5.0138e-02],\n",
       "          [-4.8466e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 5.2623e-02],\n",
       "          [-2.3146e-02],\n",
       "          [ 1.2981e-02],\n",
       "          ...,\n",
       "          [-9.8946e-04],\n",
       "          [ 4.7509e-02],\n",
       "          [-1.2684e-02]],\n",
       "\n",
       "         [[-4.6046e-02],\n",
       "          [-5.5529e-02],\n",
       "          [-4.9861e-02],\n",
       "          ...,\n",
       "          [ 4.8379e-02],\n",
       "          [ 2.2358e-02],\n",
       "          [-3.8136e-02]],\n",
       "\n",
       "         [[-4.8003e-02],\n",
       "          [-3.6949e-02],\n",
       "          [-3.5124e-02],\n",
       "          ...,\n",
       "          [ 4.7934e-02],\n",
       "          [-1.4748e-02],\n",
       "          [-3.0353e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.3132e-02],\n",
       "          [ 7.3492e-03],\n",
       "          [-5.6424e-02],\n",
       "          ...,\n",
       "          [ 1.8344e-02],\n",
       "          [ 3.2071e-04],\n",
       "          [-1.6397e-02]],\n",
       "\n",
       "         [[ 3.6766e-02],\n",
       "          [ 2.6998e-02],\n",
       "          [-4.6524e-02],\n",
       "          ...,\n",
       "          [-4.7700e-02],\n",
       "          [ 1.6359e-02],\n",
       "          [-1.9913e-02]],\n",
       "\n",
       "         [[-8.4215e-03],\n",
       "          [-3.7354e-02],\n",
       "          [ 2.0493e-02],\n",
       "          ...,\n",
       "          [-1.7151e-02],\n",
       "          [-3.8751e-02],\n",
       "          [-1.6926e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 4.5574e-04],\n",
       "          [-2.1669e-02],\n",
       "          [ 2.2794e-02],\n",
       "          ...,\n",
       "          [-2.3679e-02],\n",
       "          [ 1.5390e-02],\n",
       "          [ 3.4867e-02]],\n",
       "\n",
       "         [[-4.6887e-02],\n",
       "          [ 1.2304e-02],\n",
       "          [ 5.2298e-02],\n",
       "          ...,\n",
       "          [-1.5985e-03],\n",
       "          [-5.4094e-02],\n",
       "          [ 5.0554e-02]],\n",
       "\n",
       "         [[-5.7994e-02],\n",
       "          [ 4.3828e-02],\n",
       "          [-3.0135e-02],\n",
       "          ...,\n",
       "          [ 9.6285e-04],\n",
       "          [-6.7265e-03],\n",
       "          [-2.1295e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.0232e-02],\n",
       "          [-1.6100e-02],\n",
       "          [ 3.5221e-02],\n",
       "          ...,\n",
       "          [-4.7307e-02],\n",
       "          [-4.2871e-02],\n",
       "          [-5.0468e-02]],\n",
       "\n",
       "         [[ 5.2862e-02],\n",
       "          [-5.5607e-02],\n",
       "          [-4.5201e-02],\n",
       "          ...,\n",
       "          [-5.3428e-02],\n",
       "          [ 2.5440e-02],\n",
       "          [-4.1910e-03]],\n",
       "\n",
       "         [[ 4.5933e-02],\n",
       "          [ 4.6567e-02],\n",
       "          [-4.5979e-02],\n",
       "          ...,\n",
       "          [ 4.8353e-02],\n",
       "          [-9.1009e-03],\n",
       "          [-3.0408e-02]]],\n",
       "\n",
       "\n",
       "        [[[-5.5523e-02],\n",
       "          [ 1.9161e-02],\n",
       "          [ 5.7802e-03],\n",
       "          ...,\n",
       "          [ 3.2518e-02],\n",
       "          [-5.5855e-02],\n",
       "          [ 3.4661e-02]],\n",
       "\n",
       "         [[ 1.3171e-03],\n",
       "          [ 2.4278e-02],\n",
       "          [ 5.1748e-02],\n",
       "          ...,\n",
       "          [-4.2325e-02],\n",
       "          [-2.2886e-02],\n",
       "          [-5.5839e-02]],\n",
       "\n",
       "         [[ 4.4785e-02],\n",
       "          [-3.7795e-02],\n",
       "          [-5.2131e-03],\n",
       "          ...,\n",
       "          [ 2.6164e-02],\n",
       "          [-3.7699e-02],\n",
       "          [ 1.1352e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.3883e-02],\n",
       "          [-3.5244e-02],\n",
       "          [ 1.3954e-02],\n",
       "          ...,\n",
       "          [ 1.3820e-02],\n",
       "          [ 8.0167e-03],\n",
       "          [-2.2258e-02]],\n",
       "\n",
       "         [[ 2.7435e-02],\n",
       "          [ 4.4287e-04],\n",
       "          [-1.0105e-02],\n",
       "          ...,\n",
       "          [-3.6733e-03],\n",
       "          [ 1.3633e-02],\n",
       "          [-5.0657e-02]],\n",
       "\n",
       "         [[ 4.9171e-02],\n",
       "          [-5.3241e-02],\n",
       "          [ 1.0851e-02],\n",
       "          ...,\n",
       "          [-3.3069e-02],\n",
       "          [ 2.8770e-02],\n",
       "          [ 3.3882e-02]]]], requires_grad=True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('conv_across_time',nn.Conv2d(1,40,kernel_size=(1,51),stride = 1))\n",
    "model.add_module('conv_across_electrodes',nn.Conv2d(40,40,kernel_size=(22,1),stride = 1))\n",
    "model.add_module('BatchNorm2d',nn.BatchNorm2d(40,momentum=0.1))\n",
    "model.add_module('Nonlinearity', nn.ReLU())\n",
    "model.add_module('correct_dimensions',threed_to_twod())\n",
    "model.add_module('AvgPool2d',nn.AvgPool2d(kernel_size=(135,1),stride = (5,1)))\n",
    "model.add_module('drop', nn.Dropout(p=0.5))\n",
    "model.add_module('Flatten',Flatten())    \n",
    "model.add_module('Fc_layer',nn.Linear(164*40,10))\n",
    "torch.nn.init.xavier_uniform_(model.conv_across_time.weight, gain=1)\n",
    "torch.nn.init.xavier_uniform_(model.conv_across_electrodes.weight, gain=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "model.type(dtype)\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 0., 1.,  ..., 2., 1., 0.])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#N,C,H,W = 18,1,25,1000\n",
    "#x = Variable(torch.tensor(X_train.reshape((18,1, 25, 1000))))\n",
    "x = Variable(torch.tensor(X_train))\n",
    "y = Variable(torch.tensor(Y_train),requires_grad = False)\n",
    "dtype = torch.FloatTensor\n",
    "x.type(dtype)\n",
    "y.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor t in range(3):\\n    y_pred = model( x.float())\\n    loss = loss_fn(y_pred,y.type(torch.LongTensor))\\n    print(loss.data)\\n    model.zero_grad()\\n    loss.backward()\\nloss = loss_fn(y_pred,y.type(torch.LongTensor))\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for t in range(3):\n",
    "    y_pred = model( x.float())\n",
    "    loss = loss_fn(y_pred,y.type(torch.LongTensor))\n",
    "    print(loss.data)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "loss = loss_fn(y_pred,y.type(torch.LongTensor))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ouput, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    \n",
    "    \n",
    "    classes_predicted = torch.max(ouput, 1)[1]\n",
    "    corrects = (np.equal(classes_predicted.tolist(),target.tolist()).astype(int)).sum()\n",
    "\n",
    "    #corrects = (max_values[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()\n",
    "\n",
    "def threeD_to_fourDTensor(X):\n",
    "    return Variable(torch.tensor(X.reshape((X.shape[0],1,X.shape[1],X.shape[2],))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 1400) loss: 1.059805\n",
      "(Epoch 1 / 50) train acc: 52.000000; val_acc: 44.000000\n",
      "(Iteration 11 / 1400) loss: 0.991440\n",
      "(Iteration 21 / 1400) loss: 1.082917\n",
      "(Epoch 2 / 50) train acc: 52.000000; val_acc: 48.000000\n",
      "(Iteration 31 / 1400) loss: 1.030480\n",
      "(Iteration 41 / 1400) loss: 0.939563\n",
      "(Iteration 51 / 1400) loss: 0.945631\n",
      "(Epoch 3 / 50) train acc: 52.000000; val_acc: 56.000000\n",
      "(Iteration 61 / 1400) loss: 1.055991\n",
      "(Iteration 71 / 1400) loss: 0.765017\n",
      "(Iteration 81 / 1400) loss: 0.908475\n",
      "(Epoch 4 / 50) train acc: 60.000000; val_acc: 52.000000\n",
      "(Iteration 91 / 1400) loss: 0.908958\n",
      "(Iteration 101 / 1400) loss: 0.815839\n",
      "(Iteration 111 / 1400) loss: 1.008777\n",
      "(Epoch 5 / 50) train acc: 60.000000; val_acc: 56.000000\n",
      "(Iteration 121 / 1400) loss: 0.833951\n",
      "(Iteration 131 / 1400) loss: 0.918317\n",
      "(Epoch 6 / 50) train acc: 60.000000; val_acc: 50.000000\n",
      "(Iteration 141 / 1400) loss: 1.010829\n",
      "(Iteration 151 / 1400) loss: 1.060324\n",
      "(Iteration 161 / 1400) loss: 0.820162\n",
      "(Epoch 7 / 50) train acc: 68.000000; val_acc: 48.000000\n",
      "(Iteration 171 / 1400) loss: 0.862782\n",
      "(Iteration 181 / 1400) loss: 0.726822\n",
      "(Iteration 191 / 1400) loss: 0.897684\n",
      "(Epoch 8 / 50) train acc: 66.000000; val_acc: 52.000000\n",
      "(Iteration 201 / 1400) loss: 0.923826\n",
      "(Iteration 211 / 1400) loss: 0.856606\n",
      "(Iteration 221 / 1400) loss: 0.905006\n",
      "(Epoch 9 / 50) train acc: 58.000000; val_acc: 54.000000\n",
      "(Iteration 231 / 1400) loss: 0.918511\n",
      "(Iteration 241 / 1400) loss: 0.833787\n",
      "(Iteration 251 / 1400) loss: 1.000270\n",
      "(Epoch 10 / 50) train acc: 60.000000; val_acc: 52.000000\n",
      "(Iteration 261 / 1400) loss: 0.878132\n",
      "(Iteration 271 / 1400) loss: 0.958224\n",
      "(Epoch 11 / 50) train acc: 66.000000; val_acc: 52.000000\n",
      "(Iteration 281 / 1400) loss: 0.981965\n",
      "(Iteration 291 / 1400) loss: 0.953728\n",
      "(Iteration 301 / 1400) loss: 0.833272\n",
      "(Epoch 12 / 50) train acc: 62.000000; val_acc: 46.000000\n",
      "(Iteration 311 / 1400) loss: 0.944871\n",
      "(Iteration 321 / 1400) loss: 0.821961\n",
      "(Iteration 331 / 1400) loss: 1.006850\n",
      "(Epoch 13 / 50) train acc: 66.000000; val_acc: 40.000000\n",
      "(Iteration 341 / 1400) loss: 0.934204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-1b44ad2185c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_train = X_train.shape[0]\n",
    "num_valid = X_valid.shape[0]\n",
    "batch_size = 50\n",
    "num_epochs = 50\n",
    "iterations_per_epoch = max(num_train // batch_size, 1)\n",
    "num_iterations = num_epochs * iterations_per_epoch\n",
    "epoch = 1\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)   \n",
    "for t in range(num_iterations):\n",
    "    batch_mask = np.random.choice(num_train, batch_size)\n",
    "    X_batch = X_train[batch_mask]\n",
    "    y_batch = Y_train[batch_mask]\n",
    "    X_batch_tensor = threeD_to_fourDTensor(X_batch)\n",
    "    y_batch_tensor = Variable(torch.tensor(y_batch))\n",
    "    \n",
    "    y_pred = model( X_batch_tensor.float())\n",
    "    \n",
    "    loss = loss_fn(y_pred,y_batch_tensor.type(torch.LongTensor))\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if(t%10 == 0):\n",
    "        print('(Iteration %d / %d) loss: %f' % (\n",
    "                       t + 1, num_iterations, loss.detach().numpy()))\n",
    "    \n",
    "    epoch_end = (t + 1) % iterations_per_epoch == 0\n",
    "    \n",
    "    if epoch_end:\n",
    "                epoch += 1\n",
    "    \n",
    "    first_it = (t == 0)\n",
    "    last_it = (t == num_iterations - 1)\n",
    "\n",
    "    if first_it or last_it or epoch_end:\n",
    "        X_train_tensor =threeD_to_fourDTensor(X_train[0:50,:,:])\n",
    "        y_pred_train = model( X_train_tensor.float())\n",
    "        train_acc = get_accuracy(y_pred_train, Y_train[0:50],\n",
    "            batch_size=50)\n",
    "        \n",
    "        X_valid_tensor = threeD_to_fourDTensor(X_valid[0:50,:,:])\n",
    "        y_pred_valid = model( X_valid_tensor.float())\n",
    "        val_acc = get_accuracy(y_pred_valid, Y_valid[0:50],\n",
    "            batch_size=50)\n",
    "        print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n",
    "                           epoch, num_epochs, train_acc, val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.69627507163324\n"
     ]
    }
   ],
   "source": [
    "X_valid_tensor = threeD_to_fourDTensor(X_valid)\n",
    "y_pred_valid = model( X_valid_tensor.float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid,\n",
    "    batch_size=X_valid.shape[0])\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.11512415349887\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = threeD_to_fourDTensor(X_test)\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=X_test.shape[0])\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
