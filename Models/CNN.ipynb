{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Fix for issue loading Utils.preprocess_util\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "from torch.autograd import Variable\n",
    "from Utils.preprocess_util import *\n",
    "from Utils.visualize import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-61e5eea7dd03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_preprocess_eeg_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\eeg-Classification\\Utils\\preprocess_util.py\u001b[0m in \u001b[0;36mload_preprocess_eeg_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperson_train_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     person_test = crop_trials(X_train, y_train, X_valid, y_valid, X_test, y_test,\n\u001b[1;32m--> 220\u001b[1;33m                               person_train_valid, person_test)\n\u001b[0m\u001b[0;32m    221\u001b[0m     '''\n\u001b[0;32m    222\u001b[0m     \u001b[0mAfter\u001b[0m \u001b[0mcropping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\eeg-Classification\\Utils\\preprocess_util.py\u001b[0m in \u001b[0;36mcrop_trials\u001b[1;34m(X_train, y_train, X_valid, y_valid, X_test, y_test, person_tr, person_test)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;31m# training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_f\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mcrop_per_timestep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;31m# validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\eeg-Classification\\Utils\\preprocess_util.py\u001b[0m in \u001b[0;36mcrop_per_timestep\u001b[1;34m(X, y, X_file, y_file)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mnew_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_crops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mcrop_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHz\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0minterval_sec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0mX_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mX_new_trial_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        a= x.view(x.size(0), -1)\n",
    "        return a\n",
    "    \n",
    "class threed_to_twod(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        a = x.reshape(x.shape[0],x.shape[3],x.shape[1])\n",
    "        # print (a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0354],\n",
       "          [-0.0201],\n",
       "          [-0.0546],\n",
       "          ...,\n",
       "          [-0.0403],\n",
       "          [-0.0247],\n",
       "          [ 0.0454]],\n",
       "\n",
       "         [[ 0.0531],\n",
       "          [-0.0061],\n",
       "          [ 0.0152],\n",
       "          ...,\n",
       "          [-0.0487],\n",
       "          [ 0.0410],\n",
       "          [ 0.0578]],\n",
       "\n",
       "         [[ 0.0139],\n",
       "          [-0.0294],\n",
       "          [-0.0184],\n",
       "          ...,\n",
       "          [-0.0395],\n",
       "          [ 0.0205],\n",
       "          [-0.0304]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0119],\n",
       "          [ 0.0139],\n",
       "          [-0.0219],\n",
       "          ...,\n",
       "          [-0.0280],\n",
       "          [ 0.0356],\n",
       "          [-0.0134]],\n",
       "\n",
       "         [[ 0.0251],\n",
       "          [ 0.0477],\n",
       "          [-0.0061],\n",
       "          ...,\n",
       "          [-0.0378],\n",
       "          [-0.0442],\n",
       "          [ 0.0482]],\n",
       "\n",
       "         [[-0.0363],\n",
       "          [ 0.0270],\n",
       "          [-0.0271],\n",
       "          ...,\n",
       "          [-0.0385],\n",
       "          [ 0.0315],\n",
       "          [-0.0049]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0127],\n",
       "          [-0.0140],\n",
       "          [ 0.0008],\n",
       "          ...,\n",
       "          [ 0.0254],\n",
       "          [-0.0340],\n",
       "          [ 0.0244]],\n",
       "\n",
       "         [[ 0.0208],\n",
       "          [-0.0024],\n",
       "          [ 0.0258],\n",
       "          ...,\n",
       "          [ 0.0130],\n",
       "          [ 0.0338],\n",
       "          [ 0.0382]],\n",
       "\n",
       "         [[-0.0265],\n",
       "          [-0.0190],\n",
       "          [ 0.0577],\n",
       "          ...,\n",
       "          [-0.0451],\n",
       "          [-0.0171],\n",
       "          [ 0.0516]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0057],\n",
       "          [ 0.0328],\n",
       "          [ 0.0018],\n",
       "          ...,\n",
       "          [-0.0275],\n",
       "          [ 0.0200],\n",
       "          [ 0.0030]],\n",
       "\n",
       "         [[-0.0007],\n",
       "          [ 0.0205],\n",
       "          [ 0.0422],\n",
       "          ...,\n",
       "          [-0.0107],\n",
       "          [ 0.0258],\n",
       "          [ 0.0479]],\n",
       "\n",
       "         [[ 0.0518],\n",
       "          [-0.0141],\n",
       "          [-0.0287],\n",
       "          ...,\n",
       "          [-0.0122],\n",
       "          [-0.0538],\n",
       "          [ 0.0093]]],\n",
       "\n",
       "\n",
       "        [[[-0.0505],\n",
       "          [ 0.0463],\n",
       "          [-0.0045],\n",
       "          ...,\n",
       "          [ 0.0209],\n",
       "          [ 0.0179],\n",
       "          [ 0.0067]],\n",
       "\n",
       "         [[-0.0172],\n",
       "          [-0.0261],\n",
       "          [-0.0109],\n",
       "          ...,\n",
       "          [ 0.0465],\n",
       "          [ 0.0408],\n",
       "          [ 0.0330]],\n",
       "\n",
       "         [[ 0.0457],\n",
       "          [-0.0324],\n",
       "          [ 0.0508],\n",
       "          ...,\n",
       "          [ 0.0313],\n",
       "          [-0.0035],\n",
       "          [-0.0428]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0180],\n",
       "          [-0.0276],\n",
       "          [-0.0437],\n",
       "          ...,\n",
       "          [ 0.0214],\n",
       "          [ 0.0183],\n",
       "          [ 0.0359]],\n",
       "\n",
       "         [[-0.0410],\n",
       "          [ 0.0479],\n",
       "          [-0.0361],\n",
       "          ...,\n",
       "          [ 0.0209],\n",
       "          [-0.0185],\n",
       "          [ 0.0216]],\n",
       "\n",
       "         [[ 0.0030],\n",
       "          [ 0.0010],\n",
       "          [-0.0205],\n",
       "          ...,\n",
       "          [-0.0499],\n",
       "          [-0.0517],\n",
       "          [-0.0561]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0189],\n",
       "          [ 0.0548],\n",
       "          [ 0.0567],\n",
       "          ...,\n",
       "          [ 0.0431],\n",
       "          [-0.0542],\n",
       "          [ 0.0179]],\n",
       "\n",
       "         [[-0.0365],\n",
       "          [-0.0539],\n",
       "          [-0.0196],\n",
       "          ...,\n",
       "          [ 0.0191],\n",
       "          [-0.0241],\n",
       "          [ 0.0196]],\n",
       "\n",
       "         [[ 0.0240],\n",
       "          [ 0.0470],\n",
       "          [ 0.0091],\n",
       "          ...,\n",
       "          [ 0.0201],\n",
       "          [ 0.0580],\n",
       "          [-0.0496]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0153],\n",
       "          [-0.0083],\n",
       "          [ 0.0532],\n",
       "          ...,\n",
       "          [ 0.0495],\n",
       "          [ 0.0102],\n",
       "          [-0.0376]],\n",
       "\n",
       "         [[-0.0432],\n",
       "          [-0.0411],\n",
       "          [ 0.0457],\n",
       "          ...,\n",
       "          [-0.0560],\n",
       "          [ 0.0424],\n",
       "          [ 0.0370]],\n",
       "\n",
       "         [[-0.0085],\n",
       "          [ 0.0304],\n",
       "          [-0.0382],\n",
       "          ...,\n",
       "          [ 0.0222],\n",
       "          [-0.0155],\n",
       "          [ 0.0377]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0355],\n",
       "          [ 0.0141],\n",
       "          [ 0.0442],\n",
       "          ...,\n",
       "          [-0.0329],\n",
       "          [ 0.0048],\n",
       "          [-0.0133]],\n",
       "\n",
       "         [[ 0.0493],\n",
       "          [ 0.0321],\n",
       "          [ 0.0393],\n",
       "          ...,\n",
       "          [-0.0229],\n",
       "          [-0.0044],\n",
       "          [-0.0306]],\n",
       "\n",
       "         [[ 0.0329],\n",
       "          [ 0.0476],\n",
       "          [ 0.0362],\n",
       "          ...,\n",
       "          [ 0.0503],\n",
       "          [-0.0458],\n",
       "          [-0.0114]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0302],\n",
       "          [-0.0128],\n",
       "          [-0.0405],\n",
       "          ...,\n",
       "          [-0.0085],\n",
       "          [-0.0548],\n",
       "          [-0.0407]],\n",
       "\n",
       "         [[-0.0520],\n",
       "          [-0.0495],\n",
       "          [-0.0165],\n",
       "          ...,\n",
       "          [ 0.0215],\n",
       "          [ 0.0415],\n",
       "          [ 0.0078]],\n",
       "\n",
       "         [[ 0.0380],\n",
       "          [ 0.0536],\n",
       "          [-0.0457],\n",
       "          ...,\n",
       "          [-0.0564],\n",
       "          [ 0.0206],\n",
       "          [-0.0556]]],\n",
       "\n",
       "\n",
       "        [[[-0.0103],\n",
       "          [-0.0408],\n",
       "          [ 0.0526],\n",
       "          ...,\n",
       "          [-0.0120],\n",
       "          [ 0.0455],\n",
       "          [ 0.0516]],\n",
       "\n",
       "         [[-0.0545],\n",
       "          [ 0.0395],\n",
       "          [ 0.0343],\n",
       "          ...,\n",
       "          [ 0.0294],\n",
       "          [-0.0154],\n",
       "          [ 0.0004]],\n",
       "\n",
       "         [[ 0.0556],\n",
       "          [ 0.0467],\n",
       "          [ 0.0041],\n",
       "          ...,\n",
       "          [ 0.0210],\n",
       "          [ 0.0274],\n",
       "          [-0.0201]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0106],\n",
       "          [-0.0349],\n",
       "          [-0.0343],\n",
       "          ...,\n",
       "          [ 0.0539],\n",
       "          [ 0.0157],\n",
       "          [-0.0105]],\n",
       "\n",
       "         [[ 0.0110],\n",
       "          [ 0.0276],\n",
       "          [ 0.0361],\n",
       "          ...,\n",
       "          [ 0.0507],\n",
       "          [-0.0017],\n",
       "          [-0.0444]],\n",
       "\n",
       "         [[ 0.0192],\n",
       "          [-0.0371],\n",
       "          [ 0.0553],\n",
       "          ...,\n",
       "          [ 0.0057],\n",
       "          [-0.0578],\n",
       "          [ 0.0511]]]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droput = 0\n",
    "model = nn.Sequential()\n",
    "model.add_module('conv_across_time',nn.Conv2d(1,40,kernel_size=(1,51),stride = 1))\n",
    "model.add_module('conv_across_electrodes',nn.Conv2d(40,40,kernel_size=(22,1),stride = 1))\n",
    "model.add_module('BatchNorm2d',nn.BatchNorm2d(40,momentum=0.1))\n",
    "model.add_module('Nonlinearity', nn.ReLU())\n",
    "model.add_module('correct_dimensions',threed_to_twod())\n",
    "model.add_module('AvgPool2d',nn.AvgPool2d(kernel_size=(135,1),stride = (5,1)))\n",
    "model.add_module('drop', nn.Dropout(p=droput))\n",
    "model.add_module('Flatten',Flatten())    \n",
    "model.add_module('Fc_layer',nn.Linear(2560,10))\n",
    "torch.nn.init.xavier_uniform_(model.conv_across_time.weight, gain=1)\n",
    "torch.nn.init.xavier_uniform_(model.conv_across_electrodes.weight, gain=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "model.type(dtype)\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N,C,H,W = 18,1,25,1000\n",
    "# x = Variable(torch.tensor(X_train.reshape((18,1, 25, 1000))))\n",
    "x = Variable(torch.tensor(X_train))\n",
    "y = Variable(torch.tensor(Y_train),requires_grad=False)\n",
    "dtype = torch.FloatTensor\n",
    "x.type(dtype)\n",
    "y.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor t in range(3):\\n    y_pred = model( x.float())\\n    loss = loss_fn(y_pred,y.type(torch.LongTensor))\\n    print(loss.data)\\n    model.zero_grad()\\n    loss.backward()\\nloss = loss_fn(y_pred,y.type(torch.LongTensor))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for t in range(3):\n",
    "    y_pred = model( x.float())\n",
    "    loss = loss_fn(y_pred,y.type(torch.LongTensor))\n",
    "    print(loss.data)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "loss = loss_fn(y_pred,y.type(torch.LongTensor))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 88550) loss: 2.254832\n",
      "(Epoch 1 / 50) train acc: 0.000000; val_acc: 0.000000\n",
      "(Iteration 11 / 88550) loss: 2.243098\n",
      "(Iteration 21 / 88550) loss: 2.247763\n",
      "(Iteration 31 / 88550) loss: 2.246058\n",
      "(Iteration 41 / 88550) loss: 2.221097\n",
      "(Iteration 51 / 88550) loss: 2.230875\n",
      "(Iteration 61 / 88550) loss: 2.232251\n"
     ]
    }
   ],
   "source": [
    "num_train = X_train.shape[0]\n",
    "num_valid = X_valid.shape[0]\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "iterations_per_epoch = max(num_train // batch_size, 1)\n",
    "num_iterations = num_epochs * iterations_per_epoch\n",
    "epoch = 1\n",
    "train_loss = []\n",
    "iterations = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)   \n",
    "for t in range(num_iterations):\n",
    "    batch_mask = np.random.choice(num_train, batch_size)\n",
    "    X_batch = X_train[batch_mask]\n",
    "    y_batch = Y_train[batch_mask]\n",
    "    X_batch_tensor = threeD_to_fourDTensor(X_batch)\n",
    "    y_batch_tensor = Variable(torch.tensor(y_batch))\n",
    "    \n",
    "    y_pred = model( X_batch_tensor.float())\n",
    "    \n",
    "    loss = loss_fn(y_pred,y_batch_tensor.type(torch.LongTensor))\n",
    "    \n",
    "    train_loss.append(loss.data)\n",
    "    iterations.append(t)\n",
    "        \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if(t%10 == 0):\n",
    "        print('(Iteration %d / %d) loss: %f' % (\n",
    "                       t + 1, num_iterations, loss.detach().numpy()))\n",
    "    \n",
    "    epoch_end = (t + 1) % iterations_per_epoch == 0\n",
    "    \n",
    "    if epoch_end:\n",
    "                epoch += 1\n",
    "    \n",
    "    first_it = (t == 0)\n",
    "    last_it = (t == num_iterations - 1)\n",
    "\n",
    "    if first_it or last_it or epoch_end:\n",
    "        X_train_tensor =threeD_to_fourDTensor(X_train[0:100,:,:])\n",
    "        y_pred_train = model( X_train_tensor.float())\n",
    "        train_acc = get_accuracy(y_pred_train, Y_train[0:100],\n",
    "            batch_size=50)\n",
    "        \n",
    "        X_valid_tensor = threeD_to_fourDTensor(X_valid[0:50,:,:])\n",
    "        y_pred_valid = model( X_valid_tensor.float())\n",
    "        val_acc = get_accuracy(y_pred_valid, Y_valid[0:50],\n",
    "            batch_size=50)\n",
    "        print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n",
    "                           epoch, num_epochs, train_acc, val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 3GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b08c0ba82857>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mthreeD_to_fourDTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m val_acc = get_accuracy(y_pred_valid, Y_valid,\n\u001b[0;32m      4\u001b[0m     batch_size=X_valid.shape[0])\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validation accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 3GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_valid = model( threeD_to_fourDTensor(X_valid).float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid,\n",
    "    batch_size=X_valid.shape[0])\n",
    "print('validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87250\n",
      "174\n",
      "validation accuracy: 37.1183908045977\n"
     ]
    }
   ],
   "source": [
    "#Calculating the validation accruacy in baaches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_valid.shape[0]\n",
    "size_of_batches = int(datset_size/500)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start = 0\n",
    "\n",
    "valid_accuracies = []\n",
    "for i in range(500):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    y_pred_valid = model( threeD_to_fourDTensor(X_valid[start:end]).float())\n",
    "    val_acc = get_accuracy(y_pred_valid, Y_valid[start:end],\n",
    "    batch_size=len(Y_valid[start:end]))\n",
    "    start = end\n",
    "    valid_accuracies.append(val_acc)\n",
    "\n",
    "print('validation accuracy:', np.mean(valid_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177125\n",
      "354\n",
      "train accuracy: 47.509604519774015\n"
     ]
    }
   ],
   "source": [
    "#Calculating the training accruacy in batches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_train.shape[0]\n",
    "size_of_batches = int(datset_size/500)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start=end = 0\n",
    "\n",
    "train_accuracies = []\n",
    "for i in range(500):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    y_pred_train = model( threeD_to_fourDTensor(X_train[start:end]).float())\n",
    "    train_acc = get_accuracy(y_pred_train, Y_train[start:end],\n",
    "    batch_size=len(Y_train[start:end]))\n",
    "    start = end\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "print('train accuracy:', np.mean(train_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55375\n",
      "110\n",
      "Test accuracy: 35.74\n"
     ]
    }
   ],
   "source": [
    "#Calculating the test accruacy in baaches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_test.shape[0]\n",
    "size_of_batches = int(datset_size/500)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start = 0\n",
    "\n",
    "test_accuracies = []\n",
    "for i in range(500):\n",
    "    end = start + size_of_batches\n",
    "    y_pred_test = model( threeD_to_fourDTensor(X_test[start:end]).float())\n",
    "    test_acc = get_accuracy(y_pred_test, Y_test[start:end],\n",
    "    batch_size=len(Y_test[start:end]))\n",
    "    start = end\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "print('Test accuracy:', np.mean(test_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 11GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3bd85026ccb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_test_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreeD_to_fourDTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_test_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m test_acc = get_accuracy(y_pred_test, Y_test,\n\u001b[0;32m      4\u001b[0m     batch_size=X_test.shape[0])\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 320\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 11GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "X_test_tensor = threeD_to_fourDTensor(X_test)\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=X_test.shape[0])\n",
    "print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(iterations,train_loss)\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
