{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for issue loading Utils.preprocess_util\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "from torch.autograd import Variable\n",
    "from Utils.preprocess_util import *\n",
    "from Utils.visualize import *\n",
    "import torch.utils.data\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 22, 1000)\n",
      "Cropping trials\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "X_train = X_train[indices]\n",
    "Y_train = Y_train[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_valid.shape[0], X_valid.shape[0], replace=False)\n",
    "X_valid = X_valid[indices]\n",
    "Y_valid = Y_valid[indices]\n",
    "\n",
    "indices = np.random.choice(X_test.shape[0], X_test.shape[0], replace=False)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and targets tensor for train set\n",
    "features_train = torch.from_numpy(X_train)\n",
    "targets_train = torch.from_numpy(Y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set\n",
    "features_test = torch.from_numpy(X_test)\n",
    "targets_test = torch.from_numpy(Y_test).type(torch.LongTensor)\n",
    "\n",
    "features_valid = torch.from_numpy(X_valid)\n",
    "targets_valid = torch.from_numpy(Y_valid).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        a= x.view(x.size(0), -1)\n",
    "        return a\n",
    "    \n",
    "class threed_to_twod(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        a = x.reshape(x.shape[0],x.shape[3],x.shape[1])\n",
    "        print (\"a=\",a.shape)\n",
    "        return a\n",
    "\n",
    "class permute(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        a = x.permute(1, 0, 2) \n",
    "        #print (\"a=\",a.shape)\n",
    "        return a\n",
    "        #,((torch.zeros(num_layers, batch_size, n_neurons)),(torch.zeros(num_layers, batch_size, n_neurons)))\n",
    "\n",
    "class get_hidden(nn.Module):\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        lstm_out, (hidden, cellstate) = x  \n",
    "        print (\"hidden=\",hidden.shape)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs,n_layers,droput):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.num_layers = n_layers\n",
    "        self.cnn1 = nn.Conv2d(1,40,kernel_size=(1,51),stride = 1)\n",
    "        self.cnn2= nn.Conv2d(40,40,kernel_size=(22,1),stride = 1)\n",
    "        self.batchnorm= nn.BatchNorm2d(40,momentum=0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.threed_to_twod = threed_to_twod()\n",
    "        self.avgpool2d =  nn.AvgPool2d(kernel_size=(1,135),stride = (1,5))\n",
    "        self.dropout =  nn.Dropout(p=droput)\n",
    "        self.lstm = nn.LSTM(self.n_inputs, self.n_neurons,self.num_layers) \n",
    "        #self.lstm.weight_hh_l0.data.fill_(0)\n",
    "        #torch.nn.init.xavier_uniform_(self.lstm.weight_ih_l0.data )\n",
    "        #torch.nn.init.orthogonal_(self.lstm.weight_hh_l0.data)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.cnn1.weight, gain=1)\n",
    "        torch.nn.init.xavier_uniform_(self.cnn2.weight, gain=1)\n",
    "\n",
    "        \n",
    "        #initialising w(rec) to I and b(rec) to 0 \n",
    "        ih_size = list(self.lstm.weight_ih_l0.data.shape)\n",
    "        hh_size =list(self.lstm.weight_hh_l0.data.shape)\n",
    "        self.lstm.weight_ih_l0.data.copy_(torch.eye(ih_size[0],ih_size[1]))\n",
    "        self.lstm.weight_hh_l0.data.copy_(torch.eye(hh_size[0],hh_size[1]))\n",
    "        \n",
    "        self.lstm.bias_ih_l0.data.fill_(0)\n",
    "        self.lstm.bias_hh_l0.data.fill_(0)\n",
    "        \n",
    "        self.droput = nn.Dropout(p=droput)\n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "            # (num_layers, batch_size, n_neurons)\n",
    "            return (torch.zeros(self.num_layers, self.batch_size, self.n_neurons))\n",
    "            #return torch.nn.init.xavier_uniform_((self.num_layers, self.batch_size, self.n_neurons), gain=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "            # transforms X to (n_steps, batch_size, n_inputs0\n",
    "            conv_out1 = self.cnn1(X)\n",
    "            conv_out2 = self.cnn2(conv_out1)\n",
    "            batchnorm_out = self.batchnorm(conv_out2)\n",
    "            relu_out = self.relu(batchnorm_out)\n",
    "            AvgPool2d_out = self.avgpool2d(relu_out)\n",
    "            drop_out = self.dropout(AvgPool2d_out)\n",
    "            # transforms X to (n_steps, batch_size, n_inputs)\n",
    "            X_new = drop_out.view(drop_out.shape[0],drop_out.shape[1],drop_out.shape[3])  \n",
    "            X_new = X_new.permute(2, 0, 1) \n",
    "            self.batch_size = X_new.size(1)\n",
    "            self.hidden = self.init_hidden()\n",
    "            self.cellstate = self.init_hidden()\n",
    "            #torch.nn.init.xavier_uniform_(self.hidden)\n",
    "            #torch.nn.init.xavier_uniform_(self.cellstate)\n",
    "            lstm_out, (self.hidden, self.cellstate)= self.lstm(X_new, (self.hidden,self.cellstate))\n",
    "            hidden_out =self.hidden[self.num_layers-1]\n",
    "            dropout_out = self.droput(hidden_out)\n",
    "            out = self.FC(dropout_out)\n",
    "\n",
    "            return out.view(-1, self.n_outputs) # (batch_size, n_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(features_train, targets_train)\n",
    "valid = torch.utils.data.TensorDataset(features_valid, targets_valid)\n",
    "test = torch.utils.data.TensorDataset(features_test, targets_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# pprint.pprint(test_loader.dataset.tensors[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 22, 500])\n",
      "tensor([[ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742],\n",
      "        [ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742],\n",
      "        [ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742],\n",
      "        [ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742],\n",
      "        [ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742],\n",
      "        [ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742],\n",
      "        [ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742],\n",
      "        [ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742],\n",
      "        [ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742],\n",
      "        [ 0.0824,  0.0064, -0.0598, -0.1094,  0.0085,  0.0768,  0.0037,  0.0598,\n",
      "         -0.0587, -0.0742]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "N_STEPS = 500\n",
    "N_INPUTS = 40\n",
    "N_NEURONS = 75\n",
    "N_OUTPUTS = 10\n",
    "N_EPOCHS = 10\n",
    "N_LAYERS = 1# This actually corresponds to how many lsts are stacked one above the other\n",
    "droput = 0\n",
    "dataiter = iter(train_loader)\n",
    "signals, labels = dataiter.next()\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "signals_modified= threeD_to_fourDTensor(signals)\n",
    "print(signals_modified.shape)\n",
    "logits = model(signals_modified.float())\n",
    "print(logits[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs =  5\n",
      "n_iters =  10000\n",
      "starting training..\n",
      "starting training..\n",
      "Iteration: 1  Loss: 2.304326057434082  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 2  Loss: 2.3020730018615723  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 3  Loss: 2.289412498474121  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 4  Loss: 2.2851216793060303  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 5  Loss: 2.284088373184204  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 6  Loss: 2.2670066356658936  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 7  Loss: 2.2701377868652344  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 8  Loss: 2.2426254749298096  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 9  Loss: 2.2545735836029053  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 10  Loss: 2.2223055362701416  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 11  Loss: 2.218129873275757  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 12  Loss: 2.199347734451294  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 13  Loss: 2.1995859146118164  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 14  Loss: 2.18211030960083  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 15  Loss: 2.1774230003356934  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 16  Loss: 2.157465934753418  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 17  Loss: 2.142066240310669  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 18  Loss: 2.1294031143188477  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 19  Loss: 2.1236417293548584  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 20  Loss: 2.103649616241455  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 21  Loss: 2.097149610519409  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 22  Loss: 2.076235771179199  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 23  Loss: 2.074671745300293  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 24  Loss: 2.064671277999878  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 25  Loss: 2.0396928787231445  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 26  Loss: 2.019423484802246  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 27  Loss: 2.003647565841675  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 28  Loss: 1.9975554943084717  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 29  Loss: 1.9991950988769531  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 30  Loss: 1.963181495666504  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 31  Loss: 1.9541213512420654  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 32  Loss: 1.9397764205932617  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 33  Loss: 1.9361354112625122  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 34  Loss: 1.916304111480713  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 35  Loss: 1.908255934715271  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 36  Loss: 1.8982458114624023  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 37  Loss: 1.9045395851135254  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 38  Loss: 1.8587607145309448  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 39  Loss: 1.8680200576782227  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 40  Loss: 1.8404951095581055  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 41  Loss: 1.8354231119155884  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 42  Loss: 1.8316338062286377  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 43  Loss: 1.8180545568466187  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 44  Loss: 1.808517575263977  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 45  Loss: 1.7874609231948853  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 46  Loss: 1.7786256074905396  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 47  Loss: 1.7749420404434204  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 48  Loss: 1.7631281614303589  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 49  Loss: 1.7457265853881836  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 50  Loss: 1.7335789203643799  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 51  Loss: 1.7334389686584473  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 52  Loss: 1.7262927293777466  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 53  Loss: 1.719986081123352  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 54  Loss: 1.7026524543762207  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 55  Loss: 1.7052395343780518  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 56  Loss: 1.6912814378738403  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 57  Loss: 1.6858744621276855  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 58  Loss: 1.6796778440475464  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 59  Loss: 1.6770631074905396  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 60  Loss: 1.6502597332000732  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 61  Loss: 1.6555026769638062  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 62  Loss: 1.641883134841919  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 63  Loss: 1.6351779699325562  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 64  Loss: 1.6251378059387207  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 65  Loss: 1.6214007139205933  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 66  Loss: 1.6118669509887695  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 67  Loss: 1.6202332973480225  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 68  Loss: 1.6009914875030518  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 69  Loss: 1.6022696495056152  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 70  Loss: 1.593172550201416  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 71  Loss: 1.5842350721359253  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 72  Loss: 1.5725128650665283  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 73  Loss: 1.5737301111221313  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 74  Loss: 1.5685919523239136  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 75  Loss: 1.5604777336120605  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 76  Loss: 1.5554736852645874  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 77  Loss: 1.5607876777648926  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 78  Loss: 1.5438421964645386  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 79  Loss: 1.53891921043396  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 80  Loss: 1.5469611883163452  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 81  Loss: 1.5521926879882812  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 82  Loss: 1.525162935256958  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 83  Loss: 1.522983193397522  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 84  Loss: 1.5285236835479736  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 85  Loss: 1.5307071208953857  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 86  Loss: 1.5206962823867798  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 87  Loss: 1.5152311325073242  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 88  Loss: 1.526150107383728  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 89  Loss: 1.50262451171875  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 90  Loss: 1.496852993965149  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 91  Loss: 1.4957674741744995  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 92  Loss: 1.4983843564987183  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 93  Loss: 1.4984965324401855  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 94  Loss: 1.4871878623962402  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 95  Loss: 1.4924538135528564  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 96  Loss: 1.480272650718689  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 97  Loss: 1.4899924993515015  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 98  Loss: 1.4770786762237549  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 99  Loss: 1.49336576461792  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 100  Loss: 1.4775999784469604  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 101  Loss: 1.4696277379989624  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 102  Loss: 1.4721336364746094  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 103  Loss: 1.4697860479354858  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 104  Loss: 1.4696931838989258  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 105  Loss: 1.4641621112823486  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 106  Loss: 1.458518385887146  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 107  Loss: 1.4696862697601318  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 108  Loss: 1.4595115184783936  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 109  Loss: 1.459538221359253  Train Accuracy: 32.0 Valid Accuracy: 19.0 %\n",
      "Iteration: 110  Loss: 1.4555352926254272  Train Accuracy: 30.0 Valid Accuracy: 19.0 %\n",
      "Iteration: 111  Loss: 1.4590202569961548  Train Accuracy: 30.0 Valid Accuracy: 19.0 %\n",
      "Iteration: 112  Loss: 1.4571685791015625  Train Accuracy: 29.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 113  Loss: 1.4459887742996216  Train Accuracy: 27.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 114  Loss: 1.4543081521987915  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 115  Loss: 1.4508049488067627  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 116  Loss: 1.4502792358398438  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 117  Loss: 1.451844334602356  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 118  Loss: 1.4426159858703613  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 119  Loss: 1.4502112865447998  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 120  Loss: 1.4489586353302002  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 121  Loss: 1.4372869729995728  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 122  Loss: 1.4433590173721313  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 123  Loss: 1.4429926872253418  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 124  Loss: 1.4316296577453613  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 125  Loss: 1.430037260055542  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 126  Loss: 1.4401788711547852  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 127  Loss: 1.4360699653625488  Train Accuracy: 19.0 Valid Accuracy: 27.0 %\n",
      "Iteration: 128  Loss: 1.4470525979995728  Train Accuracy: 29.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 129  Loss: 1.4320311546325684  Train Accuracy: 28.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 130  Loss: 1.4359383583068848  Train Accuracy: 32.0 Valid Accuracy: 19.0 %\n",
      "Iteration: 131  Loss: 1.4361083507537842  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 132  Loss: 1.4244773387908936  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 133  Loss: 1.43157958984375  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 134  Loss: 1.4337519407272339  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 135  Loss: 1.424851417541504  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 136  Loss: 1.4265196323394775  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 137  Loss: 1.4324220418930054  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 138  Loss: 1.4340226650238037  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 139  Loss: 1.4265053272247314  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 140  Loss: 1.4246875047683716  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 141  Loss: 1.424758791923523  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 142  Loss: 1.4247876405715942  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 143  Loss: 1.4220494031906128  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 144  Loss: 1.4221500158309937  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 145  Loss: 1.4142199754714966  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 146  Loss: 1.4212636947631836  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 147  Loss: 1.4192827939987183  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 148  Loss: 1.4264743328094482  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 149  Loss: 1.433713674545288  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 150  Loss: 1.4184889793395996  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 151  Loss: 1.4253860712051392  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 152  Loss: 1.4125447273254395  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 153  Loss: 1.4128963947296143  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 154  Loss: 1.4172790050506592  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 155  Loss: 1.4166675806045532  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 156  Loss: 1.417791485786438  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 157  Loss: 1.4288084506988525  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 158  Loss: 1.4154211282730103  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 159  Loss: 1.4173082113265991  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 160  Loss: 1.4159623384475708  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 161  Loss: 1.420815110206604  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 162  Loss: 1.4170005321502686  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 163  Loss: 1.4160457849502563  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 164  Loss: 1.414219617843628  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 165  Loss: 1.4177173376083374  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 166  Loss: 1.4065757989883423  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 167  Loss: 1.4107613563537598  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 168  Loss: 1.413004755973816  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 169  Loss: 1.4091384410858154  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 170  Loss: 1.4076690673828125  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 171  Loss: 1.4107400178909302  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 172  Loss: 1.4123274087905884  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 173  Loss: 1.4074211120605469  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 174  Loss: 1.413020372390747  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 175  Loss: 1.408810019493103  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 176  Loss: 1.415441632270813  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 177  Loss: 1.4135850667953491  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 178  Loss: 1.4177746772766113  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 179  Loss: 1.4080212116241455  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 180  Loss: 1.4161845445632935  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 181  Loss: 1.4106577634811401  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 182  Loss: 1.4116076231002808  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 183  Loss: 1.4113796949386597  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 184  Loss: 1.410977840423584  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 185  Loss: 1.4040436744689941  Train Accuracy: 31.0 Valid Accuracy: 19.0 %\n",
      "Iteration: 186  Loss: 1.4079980850219727  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 187  Loss: 1.4077738523483276  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 188  Loss: 1.4094619750976562  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 189  Loss: 1.4073173999786377  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 190  Loss: 1.409542202949524  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 191  Loss: 1.4034225940704346  Train Accuracy: 21.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 192  Loss: 1.4068037271499634  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 193  Loss: 1.4099377393722534  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 194  Loss: 1.4007530212402344  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 195  Loss: 1.4133384227752686  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 196  Loss: 1.4023045301437378  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 197  Loss: 1.403874158859253  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 198  Loss: 1.4014315605163574  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 199  Loss: 1.4000166654586792  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 200  Loss: 1.4030815362930298  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 201  Loss: 1.4028164148330688  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 202  Loss: 1.3967251777648926  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 203  Loss: 1.3978402614593506  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 204  Loss: 1.4012694358825684  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 205  Loss: 1.3869317770004272  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 206  Loss: 1.4022630453109741  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 207  Loss: 1.4127694368362427  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 208  Loss: 1.4213075637817383  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 209  Loss: 1.4136089086532593  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 210  Loss: 1.4032825231552124  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 211  Loss: 1.3951013088226318  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 212  Loss: 1.398343801498413  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 213  Loss: 1.395721435546875  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 214  Loss: 1.3913365602493286  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 215  Loss: 1.4230239391326904  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 216  Loss: 1.4143943786621094  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 217  Loss: 1.3996896743774414  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 218  Loss: 1.4152151346206665  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 219  Loss: 1.405235767364502  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 220  Loss: 1.4002182483673096  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 221  Loss: 1.3973926305770874  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 222  Loss: 1.4017938375473022  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 223  Loss: 1.4040651321411133  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 224  Loss: 1.4006683826446533  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 225  Loss: 1.4005095958709717  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 226  Loss: 1.3970669507980347  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 227  Loss: 1.4014418125152588  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 228  Loss: 1.4031695127487183  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 229  Loss: 1.4027689695358276  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 230  Loss: 1.4014374017715454  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 231  Loss: 1.4034923315048218  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 232  Loss: 1.3986291885375977  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 233  Loss: 1.4029160737991333  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 234  Loss: 1.4065719842910767  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 235  Loss: 1.400091528892517  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 236  Loss: 1.3957600593566895  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 237  Loss: 1.3997230529785156  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 238  Loss: 1.3980543613433838  Train Accuracy: 26.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 239  Loss: 1.3982725143432617  Train Accuracy: 24.0 Valid Accuracy: 19.0 %\n",
      "Iteration: 240  Loss: 1.4025959968566895  Train Accuracy: 31.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 241  Loss: 1.3997575044631958  Train Accuracy: 23.0 Valid Accuracy: 19.0 %\n",
      "Iteration: 242  Loss: 1.401708960533142  Train Accuracy: 27.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 243  Loss: 1.397194266319275  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 244  Loss: 1.4025119543075562  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 245  Loss: 1.4043279886245728  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 246  Loss: 1.3974063396453857  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 247  Loss: 1.3987388610839844  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 248  Loss: 1.3976354598999023  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 249  Loss: 1.3945671319961548  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 250  Loss: 1.4001774787902832  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 251  Loss: 1.3901695013046265  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 252  Loss: 1.4004713296890259  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 253  Loss: 1.3971589803695679  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 254  Loss: 1.3993057012557983  Train Accuracy: 26.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 255  Loss: 1.3983863592147827  Train Accuracy: 21.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 256  Loss: 1.4033504724502563  Train Accuracy: 24.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 257  Loss: 1.4042621850967407  Train Accuracy: 25.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 258  Loss: 1.4077001810073853  Train Accuracy: 18.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 259  Loss: 1.3992958068847656  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 260  Loss: 1.3919398784637451  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 261  Loss: 1.3977817296981812  Train Accuracy: 19.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 262  Loss: 1.3957079648971558  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 263  Loss: 1.400396704673767  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 264  Loss: 1.4062718152999878  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 265  Loss: 1.3963192701339722  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 266  Loss: 1.3951488733291626  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 267  Loss: 1.3946456909179688  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 268  Loss: 1.3931612968444824  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 269  Loss: 1.3955028057098389  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 270  Loss: 1.3971153497695923  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 271  Loss: 1.4009617567062378  Train Accuracy: 33.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 272  Loss: 1.3992455005645752  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 273  Loss: 1.3987278938293457  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 274  Loss: 1.3974404335021973  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 275  Loss: 1.3957862854003906  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 276  Loss: 1.3956503868103027  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 277  Loss: 1.4027297496795654  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 278  Loss: 1.3848605155944824  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 279  Loss: 1.3946515321731567  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 280  Loss: 1.3964484930038452  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 281  Loss: 1.3840240240097046  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 282  Loss: 1.3896307945251465  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 283  Loss: 1.3967934846878052  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 284  Loss: 1.4027578830718994  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 285  Loss: 1.401173710823059  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 286  Loss: 1.3996374607086182  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 287  Loss: 1.406813144683838  Train Accuracy: 32.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 288  Loss: 1.3855993747711182  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 289  Loss: 1.4017324447631836  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 290  Loss: 1.4043142795562744  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 291  Loss: 1.3871876001358032  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 292  Loss: 1.3874008655548096  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 293  Loss: 1.4049818515777588  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 294  Loss: 1.4027214050292969  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 295  Loss: 1.3907406330108643  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 296  Loss: 1.3883028030395508  Train Accuracy: 30.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 297  Loss: 1.4024717807769775  Train Accuracy: 29.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 298  Loss: 1.3908989429473877  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 299  Loss: 1.395440697669983  Train Accuracy: 30.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 300  Loss: 1.3861552476882935  Train Accuracy: 29.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 301  Loss: 1.3966412544250488  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 302  Loss: 1.392880916595459  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 303  Loss: 1.392513632774353  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 304  Loss: 1.390041470527649  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 305  Loss: 1.401331901550293  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 306  Loss: 1.397135615348816  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 307  Loss: 1.3969683647155762  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 308  Loss: 1.3964953422546387  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 309  Loss: 1.397375464439392  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 310  Loss: 1.3957327604293823  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 311  Loss: 1.3957082033157349  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 312  Loss: 1.386893630027771  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 313  Loss: 1.3846298456192017  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 314  Loss: 1.3909409046173096  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 315  Loss: 1.3821144104003906  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 316  Loss: 1.3988325595855713  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 317  Loss: 1.388161301612854  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 318  Loss: 1.3944069147109985  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 319  Loss: 1.3820832967758179  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 320  Loss: 1.3862025737762451  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 321  Loss: 1.3927907943725586  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 322  Loss: 1.396912693977356  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 323  Loss: 1.395402193069458  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 324  Loss: 1.4085266590118408  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 325  Loss: 1.3993477821350098  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 326  Loss: 1.3978173732757568  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 327  Loss: 1.4026436805725098  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 328  Loss: 1.3784838914871216  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 329  Loss: 1.3949121236801147  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 330  Loss: 1.3982218503952026  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 331  Loss: 1.3909145593643188  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 332  Loss: 1.3972259759902954  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 333  Loss: 1.4070460796356201  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 334  Loss: 1.3960515260696411  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 335  Loss: 1.3905471563339233  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 336  Loss: 1.3945213556289673  Train Accuracy: 31.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 337  Loss: 1.3978092670440674  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 338  Loss: 1.386790156364441  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 339  Loss: 1.3871989250183105  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 340  Loss: 1.3944522142410278  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 341  Loss: 1.3937562704086304  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 342  Loss: 1.3975744247436523  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 343  Loss: 1.3964332342147827  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 344  Loss: 1.3979607820510864  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 345  Loss: 1.4011081457138062  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 346  Loss: 1.3891557455062866  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 347  Loss: 1.3926385641098022  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 348  Loss: 1.3900132179260254  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 349  Loss: 1.387984037399292  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 350  Loss: 1.3920344114303589  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 351  Loss: 1.3883843421936035  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 352  Loss: 1.3969677686691284  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 353  Loss: 1.403550148010254  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 354  Loss: 1.3945964574813843  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 355  Loss: 1.386875867843628  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 356  Loss: 1.3949995040893555  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 357  Loss: 1.3850353956222534  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 358  Loss: 1.3928608894348145  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 359  Loss: 1.3927159309387207  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 360  Loss: 1.3989403247833252  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 361  Loss: 1.4031338691711426  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 362  Loss: 1.3888038396835327  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 363  Loss: 1.3791687488555908  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 364  Loss: 1.3978385925292969  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 365  Loss: 1.3733208179473877  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 366  Loss: 1.4116477966308594  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 367  Loss: 1.397505521774292  Train Accuracy: 28.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 368  Loss: 1.3884215354919434  Train Accuracy: 33.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 369  Loss: 1.394161343574524  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 370  Loss: 1.3877331018447876  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 371  Loss: 1.4153977632522583  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 372  Loss: 1.3978239297866821  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 373  Loss: 1.4014801979064941  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 374  Loss: 1.3973722457885742  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 375  Loss: 1.3959237337112427  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 376  Loss: 1.3871257305145264  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 377  Loss: 1.3909993171691895  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 378  Loss: 1.3937758207321167  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 379  Loss: 1.3919363021850586  Train Accuracy: 19.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 380  Loss: 1.385652780532837  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 381  Loss: 1.391294240951538  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 382  Loss: 1.3922687768936157  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 383  Loss: 1.4013571739196777  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 384  Loss: 1.3885496854782104  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 385  Loss: 1.3919388055801392  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 386  Loss: 1.3978962898254395  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 387  Loss: 1.3896484375  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 388  Loss: 1.3974193334579468  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 389  Loss: 1.3935034275054932  Train Accuracy: 21.0 Valid Accuracy: 27.0 %\n",
      "Iteration: 390  Loss: 1.3912581205368042  Train Accuracy: 21.0 Valid Accuracy: 27.0 %\n",
      "Iteration: 391  Loss: 1.3913530111312866  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 392  Loss: 1.3929715156555176  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 393  Loss: 1.3932706117630005  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 394  Loss: 1.3914293050765991  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 395  Loss: 1.3932284116744995  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 396  Loss: 1.3903858661651611  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 397  Loss: 1.3913935422897339  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 398  Loss: 1.394842267036438  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 399  Loss: 1.3863030672073364  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 400  Loss: 1.3941528797149658  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 401  Loss: 1.3989875316619873  Train Accuracy: 21.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 402  Loss: 1.3925212621688843  Train Accuracy: 21.0 Valid Accuracy: 29.0 %\n",
      "Iteration: 403  Loss: 1.392024040222168  Train Accuracy: 21.0 Valid Accuracy: 29.0 %\n",
      "Iteration: 404  Loss: 1.3890756368637085  Train Accuracy: 21.0 Valid Accuracy: 29.0 %\n",
      "Iteration: 405  Loss: 1.3971846103668213  Train Accuracy: 21.0 Valid Accuracy: 29.0 %\n",
      "Iteration: 406  Loss: 1.3871147632598877  Train Accuracy: 24.0 Valid Accuracy: 30.0 %\n",
      "Iteration: 407  Loss: 1.3952218294143677  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 408  Loss: 1.4084628820419312  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 409  Loss: 1.4034128189086914  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 410  Loss: 1.4040025472640991  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 411  Loss: 1.4025312662124634  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 412  Loss: 1.3919967412948608  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 413  Loss: 1.383959174156189  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 414  Loss: 1.3976757526397705  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 415  Loss: 1.391176462173462  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 416  Loss: 1.394345998764038  Train Accuracy: 29.0 Valid Accuracy: 23.0 %\n",
      "Iteration: 417  Loss: 1.3973873853683472  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 418  Loss: 1.3953160047531128  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 419  Loss: 1.3888896703720093  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 420  Loss: 1.3893336057662964  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 421  Loss: 1.3963706493377686  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 422  Loss: 1.3794283866882324  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 423  Loss: 1.379297137260437  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 424  Loss: 1.382079005241394  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 425  Loss: 1.403436541557312  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 426  Loss: 1.380216121673584  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 427  Loss: 1.3978217840194702  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 428  Loss: 1.4228203296661377  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 429  Loss: 1.3947938680648804  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 430  Loss: 1.3847801685333252  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 431  Loss: 1.3880523443222046  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 432  Loss: 1.4044175148010254  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 433  Loss: 1.4075409173965454  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 434  Loss: 1.3956680297851562  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 435  Loss: 1.3942344188690186  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 436  Loss: 1.3963196277618408  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 437  Loss: 1.3959708213806152  Train Accuracy: 19.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 438  Loss: 1.3907806873321533  Train Accuracy: 27.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 439  Loss: 1.3914390802383423  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 440  Loss: 1.3943933248519897  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 441  Loss: 1.3890337944030762  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 442  Loss: 1.3993010520935059  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 443  Loss: 1.3873507976531982  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 444  Loss: 1.3925812244415283  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 445  Loss: 1.3965033292770386  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 446  Loss: 1.4045500755310059  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 447  Loss: 1.3873814344406128  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 448  Loss: 1.3821240663528442  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 449  Loss: 1.3849914073944092  Train Accuracy: 28.0 Valid Accuracy: 24.0 %\n",
      "Iteration: 450  Loss: 1.3866941928863525  Train Accuracy: 35.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 451  Loss: 1.4055432081222534  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 452  Loss: 1.3952534198760986  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 453  Loss: 1.3968850374221802  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 454  Loss: 1.3845791816711426  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 455  Loss: 1.3964974880218506  Train Accuracy: 33.0 Valid Accuracy: 20.0 %\n",
      "Iteration: 456  Loss: 1.3970409631729126  Train Accuracy: 33.0 Valid Accuracy: 22.0 %\n",
      "Iteration: 457  Loss: 1.3853745460510254  Train Accuracy: 28.0 Valid Accuracy: 25.0 %\n",
      "Iteration: 458  Loss: 1.3904980421066284  Train Accuracy: 29.0 Valid Accuracy: 23.0 %\n",
      "Iteration: 459  Loss: 1.3887780904769897  Train Accuracy: 29.0 Valid Accuracy: 28.0 %\n",
      "Iteration: 460  Loss: 1.394964575767517  Train Accuracy: 37.0 Valid Accuracy: 19.0 %\n",
      "Iteration: 461  Loss: 1.3875532150268555  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n",
      "Iteration: 462  Loss: 1.390191674232483  Train Accuracy: 32.0 Valid Accuracy: 21.0 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-f24ad0dce1bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mX_train_tensor\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mthreeD_to_fourDTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                 \u001b[0my_pred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_train_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m                 train_acc = get_accuracy(y_pred_train, Y_train[0:100],\n\u001b[0;32m     59\u001b[0m                     batch_size=100)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-e9038325b007>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;31m#torch.nn.init.xavier_uniform_(self.hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;31m#torch.nn.init.xavier_uniform_(self.cellstate)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mhidden_out\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mdropout_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdroput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "n_iters = 10000\n",
    "num_epochs = int(n_iters / (len(X_train)/batch_size))\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "# batch GD\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(),lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "\n",
    "train_loss = []\n",
    "iterations = []\n",
    "train_acc = []\n",
    "\n",
    "#X_valid_tensor = threeD_to_fourDTensor(X_valid)\n",
    "#X_train_tensor = threeD_to_fourDTensor(X_train)\n",
    "\n",
    "#print(\"X=\",X_train_tensor.shape)\n",
    "print(\"num_epochs = \", num_epochs)\n",
    "print(\"n_iters = \", n_iters)\n",
    "print(\"starting training..\")\n",
    "\n",
    "num_train = X_train.shape[0]\n",
    "num_valid = X_valid.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "count = 0\n",
    "num_epochs = 2\n",
    "print(\"starting training..\")\n",
    "for t in range(num_iterations):\n",
    "        batch_mask = np.random.choice(num_train, batch_size,replace = False)\n",
    "        X_batch = X_train[batch_mask]\n",
    "        y_batch = Y_train[batch_mask]\n",
    "        X_batch_tensor = threeD_to_fourDTensor(X_batch)\n",
    "        y_batch_tensor = Variable(torch.tensor(y_batch))\n",
    "\n",
    "        y_pred = model( X_batch_tensor.float())                \n",
    "        \n",
    "                \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = loss_fn(y_pred,y_batch_tensor.type(torch.LongTensor))\n",
    "              \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                    \n",
    "        #print(\"parameters===\",list(model.parameters())[0].data)\n",
    "\n",
    "        count += 1\n",
    "        train_loss.append(loss.data)\n",
    "        iterations.append(count)\n",
    "        if count % 1 == 0:\n",
    "                X_train_tensor =threeD_to_fourDTensor(X_train[0:100,:,:])\n",
    "                y_pred_train = model( X_train_tensor.float())\n",
    "                train_acc = get_accuracy(y_pred_train, Y_train[0:100],\n",
    "                    batch_size=100)\n",
    "\n",
    "                X_valid_tensor = threeD_to_fourDTensor(X_valid[0:100,:,:])\n",
    "                y_pred_valid = model( X_valid_tensor.float())\n",
    "                val_acc = get_accuracy(y_pred_valid, Y_valid[0:100],\n",
    "                    batch_size=100)\n",
    "                \n",
    "                print('Iteration: {}  Loss: {}  Train Accuracy: {} Valid Accuracy: {} %'.format(count, loss.data,train_acc,\n",
    "                                                                                            val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(iterations,train_loss)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
