{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for issue loading Utils.preprocess_util\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "from torch.autograd import Variable\n",
    "from Utils.preprocess_util import *\n",
    "from Utils.visualize import *\n",
    "import torch.utils.data\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 22, 1000)\n",
      "Cropping trials\n",
      "(177125, 22, 500)\n",
      "After cropping:\n",
      "Training data: (177125, 22, 500)\n",
      "Training target: (177125,)\n",
      "Validation data: (87250, 22, 500)\n",
      "Validation target: (87250,)\n",
      "Test data: (55375, 22, 500)\n",
      "Test target: (55375,)\n",
      "Person train/validation: (2115, 1)\n",
      "Person test: (443, 1)\n",
      "\n",
      "After cropping:\n",
      "Training data: (177125, 22, 500)\n",
      "Training target: (177125,)\n",
      "Validation data: (87250, 22, 500)\n",
      "Validation target: (87250,)\n",
      "Test data: (55375, 22, 500)\n",
      "Test target: (55375,)\n",
      "Person train/validation: (2115, 1)\n",
      "Person test: (443, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "X_train = X_train[indices]\n",
    "Y_train = Y_train[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_valid.shape[0], X_valid.shape[0], replace=False)\n",
    "X_valid = X_valid[indices]\n",
    "Y_valid = Y_valid[indices]\n",
    "\n",
    "indices = np.random.choice(X_test.shape[0], X_test.shape[0], replace=False)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and targets tensor for train set\n",
    "features_train = torch.from_numpy(X_train)\n",
    "targets_train = torch.from_numpy(Y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set\n",
    "features_test = torch.from_numpy(X_test)\n",
    "targets_test = torch.from_numpy(Y_test).type(torch.LongTensor)\n",
    "\n",
    "features_valid = torch.from_numpy(X_valid)\n",
    "targets_valid = torch.from_numpy(Y_valid).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        a= x.view(x.size(0), -1)\n",
    "        return a\n",
    "    \n",
    "class threed_to_twod(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        a = x.reshape(x.shape[0],x.shape[3],x.shape[1])\n",
    "        print (\"a=\",a.shape)\n",
    "        return a\n",
    "\n",
    "class permute(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        a = x.permute(1, 0, 2) \n",
    "        #print (\"a=\",a.shape)\n",
    "        return a\n",
    "        #,((torch.zeros(num_layers, batch_size, n_neurons)),(torch.zeros(num_layers, batch_size, n_neurons)))\n",
    "\n",
    "class get_hidden(nn.Module):\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        lstm_out, (hidden, cellstate) = x  \n",
    "        print (\"hidden=\",hidden.shape)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs,n_layers,droput):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.num_layers = n_layers\n",
    "        self.cnn1 = nn.Conv2d(1,40,kernel_size=(1,51),stride = 1)\n",
    "        self.cnn2= nn.Conv2d(40,40,kernel_size=(22,1),stride = 1)\n",
    "        self.batchnorm= nn.BatchNorm2d(40,momentum=0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.threed_to_twod = threed_to_twod()\n",
    "        self.avgpool2d =  nn.AvgPool2d(kernel_size=(1,135),stride = (1,5))\n",
    "        self.dropout =  nn.Dropout(p=droput)\n",
    "        self.lstm = nn.LSTM(self.n_inputs, self.n_neurons,self.num_layers) \n",
    "        #self.lstm.weight_hh_l0.data.fill_(0)\n",
    "        #torch.nn.init.xavier_uniform_(self.lstm.weight_ih_l0.data )\n",
    "        #torch.nn.init.orthogonal_(self.lstm.weight_hh_l0.data)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.cnn1.weight, gain=1)\n",
    "        torch.nn.init.xavier_uniform_(self.cnn2.weight, gain=1)\n",
    "\n",
    "        \n",
    "        #initialising w(rec) to I and b(rec) to 0 \n",
    "        ih_size = list(self.lstm.weight_ih_l0.data.shape)\n",
    "        hh_size =list(self.lstm.weight_hh_l0.data.shape)\n",
    "        self.lstm.weight_ih_l0.data.copy_(torch.eye(ih_size[0],ih_size[1]))\n",
    "        self.lstm.weight_hh_l0.data.copy_(torch.eye(hh_size[0],hh_size[1]))\n",
    "        \n",
    "        self.lstm.bias_ih_l0.data.fill_(0)\n",
    "        self.lstm.bias_hh_l0.data.fill_(0)\n",
    "        \n",
    "        self.droput = nn.Dropout(p=droput)\n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "            # (num_layers, batch_size, n_neurons)\n",
    "            return (torch.zeros(self.num_layers, self.batch_size, self.n_neurons))\n",
    "            #return torch.nn.init.xavier_uniform_((self.num_layers, self.batch_size, self.n_neurons), gain=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "            # transforms X to (n_steps, batch_size, n_inputs0\n",
    "            conv_out1 = self.cnn1(X)\n",
    "            conv_out2 = self.cnn2(conv_out1)\n",
    "            batchnorm_out = self.batchnorm(conv_out2)\n",
    "            relu_out = self.relu(batchnorm_out)\n",
    "            AvgPool2d_out = self.avgpool2d(relu_out)\n",
    "            drop_out = self.dropout(AvgPool2d_out)\n",
    "            # transforms X to (n_steps, batch_size, n_inputs)\n",
    "            X_new = drop_out.view(drop_out.shape[0],drop_out.shape[1],drop_out.shape[3])  \n",
    "            X_new = X_new.permute(2, 0, 1) \n",
    "            self.batch_size = X_new.size(1)\n",
    "            self.hidden = self.init_hidden()\n",
    "            self.cellstate = self.init_hidden()\n",
    "            #torch.nn.init.xavier_uniform_(self.hidden)\n",
    "            #torch.nn.init.xavier_uniform_(self.cellstate)\n",
    "            lstm_out, (self.hidden, self.cellstate)= self.lstm(X_new, (self.hidden,self.cellstate))\n",
    "            hidden_out =self.hidden[self.num_layers-1]\n",
    "            hidden_out = hidden_out.view(1,hidden_out.shape[0],hidden_out.shape[1])\n",
    "            cellstate_out =self.hidden[self.num_layers-1]\n",
    "            cellstate_out  = cellstate_out.view(1,cellstate_out.shape[0],cellstate_out.shape[1])\n",
    "            lstm_out, (self.hidden, self.cellstate)= self.lstm(X_new, (hidden_out,cellstate_out))\n",
    "            hidden_out =self.hidden[self.num_layers-1]\n",
    "            dropout_out = self.droput(hidden_out)\n",
    "            out = self.FC(dropout_out)\n",
    "\n",
    "            return out.view(-1, self.n_outputs) # (batch_size, n_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(features_train, targets_train)\n",
    "valid = torch.utils.data.TensorDataset(features_valid, targets_valid)\n",
    "test = torch.utils.data.TensorDataset(features_test, targets_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# pprint.pprint(test_loader.dataset.tensors[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaish\\OneDrive\\Desktop\\UCLA\\deep learning\\final_project\\eeg-Classification\\Utils\\preprocess_util.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return Variable(torch.tensor(X.reshape((X.shape[0],1,X.shape[1],X.shape[2],))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 22, 500])\n",
      "tensor([[ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088],\n",
      "        [ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088],\n",
      "        [ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088],\n",
      "        [ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088],\n",
      "        [ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088],\n",
      "        [ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088],\n",
      "        [ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088],\n",
      "        [ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088],\n",
      "        [ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088],\n",
      "        [ 0.0277,  0.0647, -0.0345, -0.0914, -0.1033,  0.0945,  0.0047,  0.1039,\n",
      "         -0.0379,  0.0088]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "N_STEPS = 500\n",
    "N_INPUTS = 40\n",
    "N_NEURONS = 75\n",
    "N_OUTPUTS = 10\n",
    "N_EPOCHS = 10\n",
    "N_LAYERS = 1# This actually corresponds to how many lsts are stacked one above the other\n",
    "droput = 0\n",
    "dataiter = iter(train_loader)\n",
    "signals, labels = dataiter.next()\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "signals_modified= threeD_to_fourDTensor(signals)\n",
    "print(signals_modified.shape)\n",
    "logits = model(signals_modified.float())\n",
    "print(logits[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs =  5\n",
      "n_iters =  10000\n",
      "starting training..\n",
      "starting training..\n",
      "epoch= 0\n",
      "Iteration: 1  Loss: 2.3781588077545166  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 2  Loss: 2.373640298843384  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 3  Loss: 2.3761074542999268  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 4  Loss: 2.3711183071136475  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 5  Loss: 2.369534969329834  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 6  Loss: 2.3681063652038574  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 7  Loss: 2.3719542026519775  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 8  Loss: 2.3704841136932373  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 9  Loss: 2.3711140155792236  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 10  Loss: 2.362912654876709  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 11  Loss: 2.3683536052703857  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 12  Loss: 2.367074728012085  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 13  Loss: 2.3624064922332764  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 14  Loss: 2.3557214736938477  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 15  Loss: 2.3603532314300537  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 16  Loss: 2.357832431793213  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 17  Loss: 2.353689432144165  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 18  Loss: 2.3520352840423584  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 19  Loss: 2.3525538444519043  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 20  Loss: 2.354213237762451  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "n_iters = 10000\n",
    "num_epochs = int(n_iters / (len(X_train)/batch_size))\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "# batch GD\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(),lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.1)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = 0.0001, momentum = 0.9)\n",
    "\n",
    "train_loss = []\n",
    "iterations = []\n",
    "train_acc = []\n",
    "\n",
    "#X_valid_tensor = threeD_to_fourDTensor(X_valid)\n",
    "#X_train_tensor = threeD_to_fourDTensor(X_train)\n",
    "\n",
    "#print(\"X=\",X_train_tensor.shape)\n",
    "print(\"num_epochs = \", num_epochs)\n",
    "print(\"n_iters = \", n_iters)\n",
    "print(\"starting training..\")\n",
    "\n",
    "num_train = X_train.shape[0]\n",
    "num_valid = X_valid.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "count = 0\n",
    "num_epochs = 2\n",
    "print(\"starting training..\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch=\",epoch)\n",
    "    # reset hidden states\n",
    "    \n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        #train  = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "        X_batch_tensor = threeD_to_fourDTensor(signals)\n",
    "        labels = Variable(labels )\n",
    "        '''\n",
    "        for t in range(n_iters):\n",
    "        batch_mask = np.random.choice(num_train, batch_size,replace = False)\n",
    "        X_batch = X_train[batch_mask]\n",
    "        y_batch = Y_train[batch_mask]\n",
    "        X_batch_tensor = threeD_to_fourDTensor(X_batch)\n",
    "        y_batch_tensor = Variable(torch.tensor(y_batch))\n",
    "\n",
    "        y_pred = model( X_batch_tensor.float())                \n",
    "        '''\n",
    "        \n",
    "        y_pred = model( X_batch_tensor.float())\n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = loss_fn(y_pred,labels.type(torch.LongTensor))\n",
    "              \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                    \n",
    "        #print(\"parameters===\",list(model.parameters())[0].data)\n",
    "\n",
    "        count += 1\n",
    "        train_loss.append(loss.data)\n",
    "        iterations.append(count)\n",
    "        if count % 1 == 0:\n",
    "                X_train_tensor =threeD_to_fourDTensor(X_train[0:100,:,:])\n",
    "                y_pred_train = model( X_train_tensor.float())\n",
    "                train_acc = get_accuracy(y_pred_train, Y_train[0:100],\n",
    "                    batch_size=100)\n",
    "\n",
    "                X_valid_tensor = threeD_to_fourDTensor(X_valid[0:100,:,:])\n",
    "                y_pred_valid = model( X_valid_tensor.float())\n",
    "                val_acc = get_accuracy(y_pred_valid, Y_valid[0:100],\n",
    "                    batch_size=100)\n",
    "                \n",
    "                print('Iteration: {}  Loss: {}  Train Accuracy: {} Valid Accuracy: {} %'.format(count, loss.data,train_acc,\n",
    "                                                                                            val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(iterations,train_loss)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
