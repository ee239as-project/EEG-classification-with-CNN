{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for issue loading Utils.preprocess_util\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from Utils.preprocess_util import *\n",
    "from Utils.visualize import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 1)\n"
     ]
    }
   ],
   "source": [
    "person_train_valid = np.load('../Data/person_train_valid.npy')\n",
    "print(person_train_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(person_train_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41]\n",
      " [43]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,4,5,1,4,1,5])\n",
    "c = np.argwhere(a==4)\n",
    "\n",
    "b = np.array([11,21,41,15,11,43,13,56])\n",
    "print(b[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 22, 1000)\n",
      "Cropping trials\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data(person=None,crop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "X_train = X_train[indices]\n",
    "Y_train = Y_train[indices]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train[0:1000]\n",
    "Y_train_small = Y_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_valid.shape[0], X_valid.shape[0], replace=False)\n",
    "X_valid = X_valid[indices]\n",
    "Y_valid = Y_valid[indices]\n",
    "\n",
    "indices = np.random.choice(X_test.shape[0], X_test.shape[0], replace=False)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177125, 22, 500)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and targets tensor for train set\n",
    "features_train = torch.from_numpy(X_train)\n",
    "targets_train = torch.from_numpy(Y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set\n",
    "features_test = torch.from_numpy(X_test)\n",
    "targets_test = torch.from_numpy(Y_test).type(torch.LongTensor)\n",
    "\n",
    "features_valid = torch.from_numpy(X_valid)\n",
    "targets_valid = torch.from_numpy(Y_valid).type(torch.LongTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs,n_layers,droput):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.num_layers = n_layers\n",
    "        self.lstm = nn.LSTM(self.n_inputs, self.n_neurons,self.num_layers) \n",
    "        #self.lstm.weight_hh_l0.data.fill_(0)\n",
    "        #torch.nn.init.xavier_uniform_(self.lstm.weight_ih_l0.data )\n",
    "        #torch.nn.init.orthogonal_(self.lstm.weight_hh_l0.data)\n",
    "        \n",
    "        #initialising w(rec) to I and b(rec) to 0 \n",
    "        ih_size = list(self.lstm.weight_ih_l0.data.shape)\n",
    "        hh_size =list(self.lstm.weight_hh_l0.data.shape)\n",
    "        self.lstm.weight_ih_l0.data.copy_(torch.eye(ih_size[0],ih_size[1]))\n",
    "        self.lstm.weight_hh_l0.data.copy_(torch.eye(hh_size[0],hh_size[1]))\n",
    "        \n",
    "        self.lstm.bias_ih_l0.data.fill_(0)\n",
    "        self.lstm.bias_hh_l0.data.fill_(0)\n",
    "        \n",
    "        self.droput = nn.Dropout(p=droput)\n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "            # (num_layers, batch_size, n_neurons)\n",
    "            return (torch.zeros(self.num_layers, self.batch_size, self.n_neurons))\n",
    "            #return torch.nn.init.xavier_uniform_((self.num_layers, self.batch_size, self.n_neurons), gain=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "            # transforms X to (n_steps, batch_size, n_inputs)\n",
    "            X = X.permute(1, 0, 2) \n",
    "            self.batch_size = X.size(1)\n",
    "            self.hidden = self.init_hidden()\n",
    "            self.cellstate = self.init_hidden()\n",
    "            lstm_out, (self.hidden, self.cellstate)= self.lstm(X, (self.hidden,self.cellstate))\n",
    "            hidden_out =self.hidden[self.num_layers-1]\n",
    "            dropout_out = self.droput(hidden_out)\n",
    "            out = self.FC(dropout_out)\n",
    "\n",
    "            return out.view(-1, self.n_outputs) # (batch_size, n_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(features_train, targets_train)\n",
    "valid = torch.utils.data.TensorDataset(features_valid, targets_valid)\n",
    "test = torch.utils.data.TensorDataset(features_test, targets_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# pprint.pprint(test_loader.dataset.tensors[0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5539d3429dc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mN_LAYERS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;31m# This actually corresponds to how many lsts are stacked one above the other\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdroput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdataiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_STEPS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_INPUTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_NEURONS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_OUTPUTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_LAYERS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdroput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "N_STEPS = 500\n",
    "N_INPUTS = 22\n",
    "N_NEURONS = 75\n",
    "N_OUTPUTS = 10\n",
    "N_EPOCHS = 10\n",
    "N_LAYERS = 1# This actually corresponds to how many lsts are stacked one above the other\n",
    "droput = 0\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# (batch_size, n_steps, n_inputs)\n",
    "images_modified = images.view(-1, 500, 22)\n",
    "logits = model(images_modified.float())\n",
    "print(logits[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7f5c03813514>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mn_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iters\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_STEPS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_INPUTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_NEURONS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_OUTPUTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_LAYERS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdroput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "n_iters = 10000\n",
    "num_epochs = int(n_iters / (len(X_train)/batch_size))\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "# batch GD\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01,weight_decay =0,betas=(0.9, 0.999),amsgrad=False)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(),lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.1)\n",
    "\n",
    "# Create RNN\n",
    "input_dim = 22\n",
    "seq_dim = 500\n",
    "\n",
    "train_loss = []\n",
    "iterations = []\n",
    "train_acc = []\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "\n",
    "print(\"X=\",X_train_tensor.shape)\n",
    "print(\"num_epochs = \", num_epochs)\n",
    "print(\"n_iters = \", n_iters)\n",
    "print(\"starting training..\")\n",
    "\n",
    "count = 0\n",
    "num_epochs = 2\n",
    "print(\"starting training..\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch=\",epoch)\n",
    "    # reset hidden states\n",
    "    \n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        train  = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden() \n",
    "                \n",
    "        # Forward propagation\n",
    "        outputs = model(train.float())\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "                    \n",
    "        #print(\"parameters===\",list(model.parameters())[0].data)\n",
    "\n",
    "        count += 1\n",
    "        train_loss.append(loss.data)\n",
    "        iterations.append(count)\n",
    "        if count % 1 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            #indices = np.random.choice(X_train.shape[0], 50, replace=False)\n",
    "            #X_train_tensor = torch.from_numpy(X_train[indices].reshape(-1, seq_dim, input_dim))\n",
    "            #y_pred_valid = model( X_valid_tensor.float())\n",
    "            #val_acc = get_accuracy(y_pred_valid, Y_valid,batch_size=X_valid.shape[0])\n",
    "            \n",
    "            y_pred_train = model( train.float())\n",
    "            train_acc = get_accuracy(y_pred_train,labels,batch_size=labels.shape[0])\n",
    "            \n",
    "            indices = np.random.choice(X_valid.shape[0], 50, replace=False)\n",
    "            \n",
    "            X_valid_tensor = torch.from_numpy(X_valid[indices].reshape(-1, seq_dim, input_dim))\n",
    "            \n",
    "            y_pred_valid = model( X_valid_tensor.float())\n",
    "            val_acc = get_accuracy(y_pred_valid, Y_valid[indices],\n",
    "            batch_size=50)\n",
    "            \n",
    "            '''           \n",
    "            for f in model.parameters():\n",
    "                print('data is')\n",
    "                print(f.data)\n",
    "                print('grad is')\n",
    "                print(f.grad)\n",
    "            '''\n",
    "            \n",
    "            #print('Iteration: {}  Loss: {}' .format(count, loss.data))\n",
    "\n",
    "            print('Iteration: {}  Loss: {}  Train Accuracy: {} Valid Accuracy: {} %'.format(count, loss.data,train_acc,\n",
    "                                                                                            val_acc))\n",
    "            #if(train_acc> 35 and val_acc>35):\n",
    "                #return\n",
    "            '''\n",
    "            # Iterate through test dataset\n",
    "            for signals, labels in valid_loader:\n",
    "                signals = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "                #print(signals.shape)\n",
    "                # Forward propagation\n",
    "                outputs_valid = model(signals.float())\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs_valid.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            train_loss.append(loss.data)\n",
    "            iterations.append(count)\n",
    "            train_acc.append(accuracy)\n",
    "            print('Iteration: {}  Loss: {}  Valid Accuracy: {} %'.format(count, loss.data, accuracy))\n",
    "          '''  \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 500, 22])\n",
      "validation accuracy: 17.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In case running this cell gives you an out-of-memory error, you can run the next cell \n",
    "#which breaks up the datasets into chunks to calculate the accuracy\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "print(X_train_tensor.shape)\n",
    "y_pred_train = model( X_train_tensor.float())\n",
    "train_acc = get_accuracy(y_pred_train, Y_train,\n",
    "    batch_size=len(Y_train))\n",
    "print('train accuracy:', train_acc)\n",
    "\n",
    "\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "print(X_valid_tensor.shape)\n",
    "y_pred_valid = model( X_valid_tensor.float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid,\n",
    "    batch_size=len(Y_valid))\n",
    "print('validation accuracy:', val_acc)\n",
    "\n",
    "X_test_tensor = torch.from_numpy(X_test.reshape(-1, seq_dim, input_dim))\n",
    "print(X_test_tensor.shape)\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=len(Y_test))\n",
    "print('test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55375, 500, 22])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-23214970c3ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_test_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_test_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m test_acc = get_accuracy(y_pred_test, Y_test,\n\u001b[0;32m      5\u001b[0m     batch_size=len(Y_test))\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-18c943cb3006>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mhidden_out\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mdropout_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdroput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.from_numpy(X_test.reshape(-1, seq_dim, input_dim))\n",
    "print(X_test_tensor.shape)\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=len(Y_test))\n",
    "print('test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87250\n",
      "4362\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "validation accuracy: 25.196011004126547\n"
     ]
    }
   ],
   "source": [
    "#Calculating the validation accruacy in baaches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_valid.shape[0]\n",
    "size_of_batches = int(datset_size/20)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start = 0\n",
    "\n",
    "valid_accuracies = []\n",
    "for i in range(20):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    X_valid_tensor = torch.from_numpy(X_valid[start:end].reshape(-1, seq_dim, input_dim))\n",
    "    print(X_valid_tensor.shape)\n",
    "    y_pred_valid = model( X_valid_tensor.float())\n",
    "    val_acc = get_accuracy(y_pred_valid, Y_valid[start:end],\n",
    "    batch_size=len(Y_valid[start:end]))\n",
    "    start = end\n",
    "    valid_accuracies.append(val_acc)\n",
    "\n",
    "print('validation accuracy:', np.mean(valid_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55375\n",
      "2768\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "Test accuracy: 23.6235549132948\n"
     ]
    }
   ],
   "source": [
    "#Calculating the test accruacy in baaches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_test.shape[0]\n",
    "size_of_batches = int(datset_size/20)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start = 0\n",
    "\n",
    "test_accuracies = []\n",
    "for i in range(20):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    X_test_tensor = torch.from_numpy(X_test[start:end].reshape(-1, seq_dim, input_dim))\n",
    "    print(X_test_tensor.shape)\n",
    "    y_pred_test = model( X_test_tensor.float())\n",
    "    test_acc = get_accuracy(y_pred_test, Y_test[start:end],\n",
    "    batch_size=len(Y_test[start:end]))\n",
    "    start = end\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "print('Test accuracy:', np.mean(test_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177125\n",
      "3542\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "train accuracy: 25.92603049124788\n"
     ]
    }
   ],
   "source": [
    "#Calculating the training accruacy in batches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_train.shape[0]\n",
    "size_of_batches = int(datset_size/50)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start=end = 0\n",
    "\n",
    "train_accuracies = []\n",
    "for i in range(50):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    X_train_tensor = torch.from_numpy(X_train[start:end].reshape(-1, seq_dim, input_dim))\n",
    "    print(X_train_tensor.shape)\n",
    "    y_pred_train = model( X_train_tensor .float())\n",
    "    train_acc = get_accuracy(y_pred_train, Y_train[start:end],\n",
    "    batch_size=len(Y_train[start:end]))\n",
    "    start = end\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "print('train accuracy:', np.mean(train_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 23.90153582688275\n"
     ]
    }
   ],
   "source": [
    "print('train_accuracy:', np.mean(train_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot loss vs iterations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(iterations,train_loss)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
