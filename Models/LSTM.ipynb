{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for issue loading Utils.preprocess_util\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from Utils.preprocess_util import *\n",
    "from Utils.visualize import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 1)\n"
     ]
    }
   ],
   "source": [
    "person_train_valid = np.load('../Data/person_train_valid.npy')\n",
    "print(person_train_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(person_train_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41]\n",
      " [43]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,4,5,1,4,1,5])\n",
    "c = np.argwhere(a==4)\n",
    "\n",
    "b = np.array([11,21,41,15,11,43,13,56])\n",
    "print(b[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 22, 1000)\n",
      "Cropping trials\n",
      "(177125, 22, 500)\n",
      "After cropping:\n",
      "Training data: (177125, 22, 500)\n",
      "Training target: (177125,)\n",
      "Validation data: (87250, 22, 500)\n",
      "Validation target: (87250,)\n",
      "Test data: (55375, 22, 500)\n",
      "Test target: (55375,)\n",
      "Person train/validation: (2115, 1)\n",
      "Person test: (443, 1)\n",
      "\n",
      "After cropping:\n",
      "Training data: (177125, 22, 500)\n",
      "Training target: (177125,)\n",
      "Validation data: (87250, 22, 500)\n",
      "Validation target: (87250,)\n",
      "Test data: (55375, 22, 500)\n",
      "Test target: (55375,)\n",
      "Person train/validation: (2115, 1)\n",
      "Person test: (443, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test = load_preprocess_eeg_data(person=None,crop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "X_train = X_train[indices]\n",
    "Y_train = Y_train[indices]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train[0:1000]\n",
    "Y_train_small = Y_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(X_valid.shape[0], X_valid.shape[0], replace=False)\n",
    "X_valid = X_valid[indices]\n",
    "Y_valid = Y_valid[indices]\n",
    "\n",
    "indices = np.random.choice(X_test.shape[0], X_test.shape[0], replace=False)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177125, 22, 500)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and targets tensor for train set\n",
    "features_train = torch.from_numpy(X_train)\n",
    "targets_train = torch.from_numpy(Y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set\n",
    "features_test = torch.from_numpy(X_test)\n",
    "targets_test = torch.from_numpy(Y_test).type(torch.LongTensor)\n",
    "\n",
    "features_valid = torch.from_numpy(X_valid)\n",
    "targets_valid = torch.from_numpy(Y_valid).type(torch.LongTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs,n_layers,droput):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.num_layers = n_layers\n",
    "        self.lstm = nn.LSTM(self.n_inputs, self.n_neurons,self.num_layers) \n",
    "        #self.lstm.weight_hh_l0.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.lstm.weight_ih_l0.data )\n",
    "        torch.nn.init.orthogonal_(self.lstm.weight_hh_l0.data)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.droput = nn.Dropout(p=droput)\n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "            # (num_layers, batch_size, n_neurons)\n",
    "            return (torch.zeros(self.num_layers, self.batch_size, self.n_neurons))\n",
    "            #return torch.nn.init.xavier_uniform_((self.num_layers, self.batch_size, self.n_neurons), gain=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "            # transforms X to (n_steps, batch_size, n_inputs)\n",
    "            X = X.permute(1, 0, 2) \n",
    "            self.batch_size = X.size(1)\n",
    "            self.hidden = self.init_hidden()\n",
    "            self.cellstate = self.init_hidden()\n",
    "            lstm_out, (self.hidden, self.cellstate)= self.lstm(X, (self.hidden,self.cellstate))\n",
    "            hidden_out =self.hidden[self.num_layers-1]\n",
    "            dropout_out = self.droput(hidden_out)\n",
    "            out = self.FC(dropout_out)\n",
    "\n",
    "            return out.view(-1, self.n_outputs) # (batch_size, n_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(features_train, targets_train)\n",
    "valid = torch.utils.data.TensorDataset(features_valid, targets_valid)\n",
    "test = torch.utils.data.TensorDataset(features_test, targets_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# pprint.pprint(test_loader.dataset.tensors[0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.0938e-02,  1.1078e-01,  5.5751e-02,  5.1325e-03, -2.1825e-01,\n",
      "          6.4642e-02,  1.8658e-01,  1.4150e-01, -1.1474e-01,  1.4080e-02],\n",
      "        [ 3.1348e-03,  5.0169e-02,  2.5656e-02,  7.4184e-02, -2.5890e-01,\n",
      "          9.6748e-02,  4.3071e-02,  1.2010e-01, -1.5874e-01, -1.2705e-01],\n",
      "        [ 2.6565e-02,  9.4159e-02,  1.1076e-01,  4.2320e-02, -2.1824e-01,\n",
      "          2.1971e-02,  1.0631e-01,  6.6020e-02, -9.0511e-02, -4.4705e-02],\n",
      "        [ 1.1798e-01,  8.2558e-02,  1.0475e-01, -6.7000e-03, -1.3948e-01,\n",
      "         -1.5196e-02,  4.8185e-02, -4.9154e-02, -1.4231e-01, -8.0459e-02],\n",
      "        [ 1.1463e-01,  1.2327e-01,  1.3499e-01, -1.6218e-02, -1.5673e-01,\n",
      "         -4.9857e-03,  1.3610e-01,  1.7531e-02, -9.3932e-02,  1.4780e-02],\n",
      "        [ 5.3907e-02,  9.1934e-02,  7.3751e-02,  8.2888e-02, -2.5294e-01,\n",
      "         -2.4061e-02,  1.2611e-01,  6.1292e-02, -1.1320e-01,  6.4318e-02],\n",
      "        [-3.0535e-03,  6.9088e-02,  8.4586e-02,  6.4395e-02, -2.3948e-01,\n",
      "          4.7716e-02,  9.1047e-02,  5.2411e-02, -1.3428e-01, -3.5045e-02],\n",
      "        [ 1.8187e-02,  2.9629e-02,  7.4298e-02,  3.9459e-02, -1.3558e-01,\n",
      "          4.9926e-02, -1.1751e-04,  1.4533e-02, -1.7486e-01, -1.1980e-01],\n",
      "        [ 6.1107e-02, -1.8263e-02,  8.4324e-02,  4.4680e-02, -1.5544e-01,\n",
      "          2.8761e-03, -3.7960e-02, -1.0724e-01, -1.1658e-01, -9.5416e-02],\n",
      "        [ 8.6769e-02,  6.3996e-02,  9.5003e-02, -3.7618e-02, -4.3594e-02,\n",
      "         -5.4470e-02,  4.7695e-02, -4.7936e-02, -1.0678e-01, -7.0978e-02]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "N_STEPS = 500\n",
    "N_INPUTS = 22\n",
    "N_NEURONS = 75\n",
    "N_OUTPUTS = 10\n",
    "N_EPOCHS = 10\n",
    "N_LAYERS = 1# This actually corresponds to how many lsts are stacked one above the other\n",
    "droput = 0\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# (batch_size, n_steps, n_inputs)\n",
    "images_modified = images.view(-1, 500, 22)\n",
    "logits = model(images_modified.float())\n",
    "print(logits[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs =  28\n",
      "n_iters =  10000\n",
      "starting training..\n",
      "starting training..\n",
      "epoch= 0\n",
      "Iteration: 1  Loss: 2.397505044937134  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 2  Loss: 2.3810787200927734  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 3  Loss: 2.3618788719177246  Train Accuracy: 0.0 Valid Accuracy: 0.0 %\n",
      "Iteration: 4  Loss: 2.3514292240142822  Train Accuracy: 0.2 Valid Accuracy: 0.0 %\n",
      "Iteration: 5  Loss: 2.3593451976776123  Train Accuracy: 0.6 Valid Accuracy: 0.0 %\n",
      "Iteration: 6  Loss: 2.353055715560913  Train Accuracy: 0.6 Valid Accuracy: 0.0 %\n",
      "Iteration: 7  Loss: 2.2910029888153076  Train Accuracy: 4.6 Valid Accuracy: 0.0 %\n",
      "Iteration: 8  Loss: 2.328693151473999  Train Accuracy: 1.8 Valid Accuracy: 2.0 %\n",
      "Iteration: 9  Loss: 2.3139712810516357  Train Accuracy: 3.0 Valid Accuracy: 6.0 %\n",
      "Iteration: 10  Loss: 2.3320772647857666  Train Accuracy: 5.0 Valid Accuracy: 4.0 %\n",
      "Iteration: 11  Loss: 2.3054423332214355  Train Accuracy: 11.2 Valid Accuracy: 8.0 %\n",
      "Iteration: 12  Loss: 2.3245198726654053  Train Accuracy: 3.2 Valid Accuracy: 16.0 %\n",
      "Iteration: 13  Loss: 2.319277763366699  Train Accuracy: 8.2 Valid Accuracy: 10.0 %\n",
      "Iteration: 14  Loss: 2.274322271347046  Train Accuracy: 22.2 Valid Accuracy: 16.0 %\n",
      "Iteration: 15  Loss: 2.2838423252105713  Train Accuracy: 6.0 Valid Accuracy: 32.0 %\n",
      "Iteration: 16  Loss: 2.242995500564575  Train Accuracy: 33.8 Valid Accuracy: 30.0 %\n",
      "Iteration: 17  Loss: 2.238448143005371  Train Accuracy: 22.0 Valid Accuracy: 26.0 %\n",
      "Iteration: 18  Loss: 2.234696388244629  Train Accuracy: 37.2 Valid Accuracy: 28.0 %\n",
      "Iteration: 19  Loss: 2.1905994415283203  Train Accuracy: 40.8 Valid Accuracy: 24.0 %\n",
      "Iteration: 20  Loss: 2.2215912342071533  Train Accuracy: 5.8 Valid Accuracy: 28.0 %\n",
      "Iteration: 21  Loss: 2.158245086669922  Train Accuracy: 24.4 Valid Accuracy: 24.0 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9960e58be62d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# Calculating gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "n_iters = 10000\n",
    "num_epochs = int(n_iters / (len(X_train)/batch_size))\n",
    "model = LSTMModel(batch_size, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS,N_LAYERS,droput)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "# batch GD\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01,weight_decay =0,betas=(0.9, 0.999),amsgrad=False)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(),lr=0.001, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.1)\n",
    "\n",
    "# Create RNN\n",
    "input_dim = 22\n",
    "seq_dim = 500\n",
    "\n",
    "train_loss = []\n",
    "iterations = []\n",
    "train_acc = []\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "\n",
    "print(\"num_epochs = \", num_epochs)\n",
    "print(\"n_iters = \", n_iters)\n",
    "print(\"starting training..\")\n",
    "\n",
    "count = 0\n",
    "num_epochs = 2\n",
    "print(\"starting training..\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch=\",epoch)\n",
    "    # reset hidden states\n",
    "    \n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        train  = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden() \n",
    "                \n",
    "        # Forward propagation\n",
    "        outputs = model(train.float())\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "                    \n",
    "        #print(\"parameters===\",list(model.parameters())[0].data)\n",
    "\n",
    "        count += 1\n",
    "        train_loss.append(loss.data)\n",
    "        iterations.append(count)\n",
    "        if count % 1 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            #indices = np.random.choice(X_train.shape[0], 50, replace=False)\n",
    "            #X_train_tensor = torch.from_numpy(X_train[indices].reshape(-1, seq_dim, input_dim))\n",
    "            #y_pred_valid = model( X_valid_tensor.float())\n",
    "            #val_acc = get_accuracy(y_pred_valid, Y_valid,batch_size=X_valid.shape[0])\n",
    "            \n",
    "            y_pred_train = model( train.float())\n",
    "            train_acc = get_accuracy(y_pred_train,labels,batch_size=labels.shape[0])\n",
    "            \n",
    "            indices = np.random.choice(X_valid.shape[0], 50, replace=False)\n",
    "            \n",
    "            X_valid_tensor = torch.from_numpy(X_valid[indices].reshape(-1, seq_dim, input_dim))\n",
    "            \n",
    "            y_pred_valid = model( X_valid_tensor.float())\n",
    "            val_acc = get_accuracy(y_pred_valid, Y_valid[indices],\n",
    "            batch_size=50)\n",
    "            \n",
    "            #print('Iteration: {}  Loss: {}' .format(count, loss.data))\n",
    "\n",
    "            print('Iteration: {}  Loss: {}  Train Accuracy: {} Valid Accuracy: {} %'.format(count, loss.data,train_acc,\n",
    "                                                                                            val_acc))\n",
    "            #if(train_acc> 35 and val_acc>35):\n",
    "                #return\n",
    "            '''\n",
    "            # Iterate through test dataset\n",
    "            for signals, labels in valid_loader:\n",
    "                signals = Variable(signals.view(-1, seq_dim, input_dim))\n",
    "                #print(signals.shape)\n",
    "                # Forward propagation\n",
    "                outputs_valid = model(signals.float())\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs_valid.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            train_loss.append(loss.data)\n",
    "            iterations.append(count)\n",
    "            train_acc.append(accuracy)\n",
    "            print('Iteration: {}  Loss: {}  Valid Accuracy: {} %'.format(count, loss.data, accuracy))\n",
    "          '''  \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 500, 22])\n",
      "validation accuracy: 17.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In case running this cell gives you an out-of-memory error, you can run the next cell \n",
    "#which breaks up the datasets into chunks to calculate the accuracy\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train.reshape(-1, seq_dim, input_dim))\n",
    "print(X_train_tensor.shape)\n",
    "y_pred_train = model( X_train_tensor.float())\n",
    "train_acc = get_accuracy(y_pred_train, Y_train,\n",
    "    batch_size=len(Y_train))\n",
    "print('train accuracy:', train_acc)\n",
    "\n",
    "\n",
    "\n",
    "X_valid_tensor = torch.from_numpy(X_valid.reshape(-1, seq_dim, input_dim))\n",
    "print(X_valid_tensor.shape)\n",
    "y_pred_valid = model( X_valid_tensor.float())\n",
    "val_acc = get_accuracy(y_pred_valid, Y_valid,\n",
    "    batch_size=len(Y_valid))\n",
    "print('validation accuracy:', val_acc)\n",
    "\n",
    "X_test_tensor = torch.from_numpy(X_test.reshape(-1, seq_dim, input_dim))\n",
    "print(X_test_tensor.shape)\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=len(Y_test))\n",
    "print('test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([55375, 500, 22])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-23214970c3ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_test_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_test_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m test_acc = get_accuracy(y_pred_test, Y_test,\n\u001b[0;32m      5\u001b[0m     batch_size=len(Y_test))\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-18c943cb3006>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcellstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mhidden_out\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mdropout_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdroput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn-hw4\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.from_numpy(X_test.reshape(-1, seq_dim, input_dim))\n",
    "print(X_test_tensor.shape)\n",
    "y_pred_test = model( X_test_tensor.float())\n",
    "test_acc = get_accuracy(y_pred_test, Y_test,\n",
    "    batch_size=len(Y_test))\n",
    "print('test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87250\n",
      "4362\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "torch.Size([4362, 500, 22])\n",
      "validation accuracy: 23.784961027051807\n"
     ]
    }
   ],
   "source": [
    "#Calculating the validation accruacy in baaches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_valid.shape[0]\n",
    "size_of_batches = int(datset_size/20)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start = 0\n",
    "\n",
    "valid_accuracies = []\n",
    "for i in range(20):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    X_valid_tensor = torch.from_numpy(X_valid[start:end].reshape(-1, seq_dim, input_dim))\n",
    "    print(X_valid_tensor.shape)\n",
    "    y_pred_valid = model( X_valid_tensor.float())\n",
    "    val_acc = get_accuracy(y_pred_valid, Y_valid[start:end],\n",
    "    batch_size=len(Y_valid[start:end]))\n",
    "    start = end\n",
    "    valid_accuracies.append(val_acc)\n",
    "\n",
    "print('validation accuracy:', np.mean(valid_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55375\n",
      "2768\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "torch.Size([2768, 500, 22])\n",
      "Test accuracy: 28.648843930635838\n"
     ]
    }
   ],
   "source": [
    "#Calculating the test accruacy in baaches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_test.shape[0]\n",
    "size_of_batches = int(datset_size/20)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start = 0\n",
    "\n",
    "test_accuracies = []\n",
    "for i in range(20):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    X_test_tensor = torch.from_numpy(X_test[start:end].reshape(-1, seq_dim, input_dim))\n",
    "    print(X_test_tensor.shape)\n",
    "    y_pred_test = model( X_test_tensor.float())\n",
    "    test_acc = get_accuracy(y_pred_test, Y_test[start:end],\n",
    "    batch_size=len(Y_test[start:end]))\n",
    "    start = end\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "print('Test accuracy:', np.mean(test_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177125\n",
      "3542\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "torch.Size([3542, 500, 22])\n",
      "train accuracy: 24.491812535290798\n"
     ]
    }
   ],
   "source": [
    "#Calculating the training accruacy in batches, since out-of-memory error arises when calculating using the whole set!\n",
    "datset_size =  X_train.shape[0]\n",
    "size_of_batches = int(datset_size/50)\n",
    "\n",
    "print(datset_size)\n",
    "print(size_of_batches)\n",
    "\n",
    "start=end = 0\n",
    "\n",
    "train_accuracies = []\n",
    "for i in range(50):\n",
    "    end = start + size_of_batches\n",
    "    \n",
    "    X_train_tensor = torch.from_numpy(X_train[start:end].reshape(-1, seq_dim, input_dim))\n",
    "    print(X_train_tensor.shape)\n",
    "    y_pred_train = model( X_train_tensor .float())\n",
    "    train_acc = get_accuracy(y_pred_train, Y_train[start:end],\n",
    "    batch_size=len(Y_train[start:end]))\n",
    "    start = end\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "print('train accuracy:', np.mean(train_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 23.90153582688275\n"
     ]
    }
   ],
   "source": [
    "print('train_accuracy:', np.mean(train_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztvXd4JFeZ7/891Tm3WmmkkTSa7Mn2WONxAifAAWMvsMAaL5jg6/WSF5bfwrJLWO4ud2FhExew8RobMBgcsOFiDNiAx2HsyePJeTSjUY6d8/n9UXVK1a3qJLXUrdb7eZ55pOkuVZ2u7v6e93zPe97DOOcgCIIgagup0g0gCIIgyg+JO0EQRA1C4k4QBFGDkLgTBEHUICTuBEEQNQiJO0EQRA1C4k4QBFGDkLgTBEHUICTuBEEQNYixUhduaGjgnZ2dlbo8QRDEvGT37t3DnPPGQsdVTNw7Ozuxa9euSl2eIAhiXsIY6y7mOLJlCIIgahASd4IgiBqExJ0gCKIGIXEnCIKoQUjcCYIgahASd4IgiBqExJ0gCKIGmXfifn40jK/86hASqXSlm0IQBFG1zDtxP9YfwA9ePouf7jhX6aYQBEFULfNO3G9Y04TLl/nwH8+dgD+aqHRzCIIgqpJ5J+6MMXzhlrUYDcXxzd8eQzxJ9gxBEEQ2807cAWBDmwfv7mrDw9u7sfVfnsMv9vZUukkEQRBVxbwUdwD42js24qEPbkFngwOfe+IATgwE1Oce3XEOj+8mwScIYuEyb8XdIDFcu7oJ973vUjgsRnzy0X2IJlLYfmoEn//FATzw4ulKN5EgCKJiVKzkb7loclnxf96xAff8aDfe/O8vIJZIg3Og3x+tdNMIgiAqxryN3LW8Zd0i/OjDl8FhNmIiksAtGxZhPJxANJHK+3fj4Tj59QRB1CTzPnIXvGFlI379iQYEogk8d2QQzxzoR/9EFJ0Njpx/c9+20/jun05hY5sXyxudc9hagiCI2aUmIneBQWLw2s1Y5LYC0LdmOOfq788dHgAA7D03PjcNJAiCmCNqStwFizyKuE9kinsilcYd338VX3vmCLpHQjgxGAQA7D03NudtJAiCmE1qxpbRoop7VuT+w+3dePX0KHacGcVERF7duqzBQZE7QRA1R01G7k6LES6LMSNyH/RH8e+/P46tS31wmI14dOd5rGp24q0bW3C0349wPFnBFhMEQZSXmhR3AGj2WDPE/etKqYL/886NuPfa5QCAG9Y045IOL9IceL1nolJNJQiCKDs1acsAQIvHij7Fljna78cTe3pw99VLsbTBgQ9dtRRDgRju3NoBu1m+BfvOj+PyZfWVbDJBEETZqFlxb3ZbcWJgGADwjWePwWkx4iPXrgAA2MwGfPm2deqxnfV27OmmSVWCIGqHmrVlWjxWDAai2Hl2FM8fHcRfX7scdQ6z7rFXLK/HSyeHEYgm0DsewUce2Y2RYGyOW0wQBFE+albcm91WpDnwzd8dg8tixAeu7Mx57Hu2dCAcT+Gpfb34z+dO4JkD/dh2YmjuGksQBFFmalbcW5R0yFdPj+Idmxer3roem9o8WNvixv3bTuGJPXI5gkMX/HPSToIgiNmgoLgzxtoZY39kjB1hjB1ijH1S55g7GWOvK/9eYYxtmp3mFk+zskoVAN67dUneYxljeO/WDpwfjUCSGJbU23Gol8SdIIj5SzGRexLAZzjnawBcDuCjjLG1WcecAXAN53wjgK8CuL+8zSwdEbl3LanD6kWugsf/2SWL4bWbcNcVS3DVigYc6p3IKFVAEAQxnygo7pzzPs75HuX3AIAjABZnHfMK51ykm7wKoK3cDS0Vn8OMP7+0DZ95y+qijndajHjhs9fhczevwbpWN/zRJHrGIrPcSoIgiNmhpFRIxlgngEsAvJbnsA8D+E2Ov78HwD0A0NHRUcqlS4Yxhn97V2nukMdmAgCsb/UAAA71TqDdZy972wiCIGaboidUGWNOAE8A+BTnXNeQZoxdB1nc/07vec75/ZzzLs55V2Nj43TaOyesXuSCQWLkuxMEMW8pKnJnjJkgC/sjnPMncxyzEcADAG7mnI+Ur4lzj9VkwMomJw5eoJIEBEHMT4rJlmEA/gfAEc75t3Ic0wHgSQDv45wfL28TK8PaVjd2nBnF1589igvj5L0TBDG/KCZyvwrA+wAcYIztUx77ewAdAMA5/x6ALwKoB/AduS9AknPeVf7mzh3vv6ITPWMR3LftNP5wdBDPfOINkCRW6WYRBEEUBatUul9XVxfftWtXRa5dCk/tvYBP/WwfvveXm3HT+pZKN4cgiAUOY2x3McFzza5QLRdv29SKZQ0O/MdzJ5BOU947QRDzAxL3Ahgkho9dvwJH+wN44TjVmyEIYn5A4l4Et2yQ7ZhDvXL2zLMH+/HgS2cq2SSCIIi8kLgXgdVkQIPTjAvj8uYfP361G/dvO13hVhEEQeSGxL1IWr029CopkefHwhgKxpAiD54giCqFxL1IWj2yuKfSXP05EqINPQiCqE5I3ItERO4D/igSKTliH/STuBMEUZ2QuBdJq9eKUDyVUZJgQNmAmyAIotogcS+SxV4bAOC1M6PqYwMUuRMEUaWUVPJ3IdOqivsImFKFoJ8id4IgqhQS9yIR4n64149mlxUpzjFI4k4QRJVC4l4k9Q4zzEYJ8WQa7T4bIokUee4EQVQt5LkXiSQxtCr7srbV2dHsspLnThBE1ULiXgLCmmmvs6HJbcVggCJ3giCqE7JlSkCIe5vPDkliGA7GkUilYTJQH0kQRHVBqlQCqrjX2dDsli2aoQBZMwRBVB8k7iWwqtkJo8SwvNGJZrcFAC1kIgiiOiFbpgRuWd+CTX/rRbPbqkbsNKlKEEQ1QpF7CUgSQ7vPDgCqLUOTqgRBVCMk7tOk3mGGUWLY0z2GSu1DSxAEkQsS92kiSQx3bu3AU/t68Tc/24dkKl3pJhEEQaiQuM+AL9+2Dp+8YSWe2teL548OVro5BEEQKiTuM4Axho9ctxwmA8Oec2OVbg5BEIQKifsMsRgNWNvixr5z45VuCkEQhAqJexm4uN2LAxcmaE9VgiCqBhL3MnBxhxfheAonBgOVbgpBEASAIsSdMdbOGPsjY+wIY+wQY+yTOscwxth/McZOMsZeZ4xtnp3mVieb2rwAQNYMQRBVQzGRexLAZzjnawBcDuCjjLG1WcfcDGCl8u8eAN8tayurnKUNDnhsJuw7T+JOEER1UFDcOed9nPM9yu8BAEcALM467HYAP+QyrwLwMsZayt7aKoUxhk3tXhJ3giCqhpI8d8ZYJ4BLALyW9dRiAOc1/+/B1A6gprm43YvjAwEEY8lKN4UgCKJ4cWeMOQE8AeBTnHN/9tM6fzIldYQxdg9jbBdjbNfQ0FBpLa1yupbUIc2BPd2U704QROUpStwZYybIwv4I5/xJnUN6ALRr/t8GoDf7IM75/ZzzLs55V2Nj43TaW7VsXlIHiQE7z44inkzj0z/fhwM9E5VuFkEQC5RismUYgP8BcIRz/q0ch/0SwPuVrJnLAUxwzvvK2M6qx2kxYl2rBzvPjuKF40N4cs8F/GLvhUo3iyCIBUoxkftVAN4H4HrG2D7l3y2MsXsZY/cqxzwD4DSAkwC+D+Ajs9Pc6qarsw57z43jZzvPAQAOXpi9yP3TP9+Hl04Mz9r5CYKY3xTcrINz/hL0PXXtMRzAR8vVqPnKZZ0+/ODls3juyCCMEsPBXnnVqkHKe/tKJhJP4ck9F9DiseLqlQ1lPTdBELUBrVAtI12dPvX3v7x8CcLxFE4PBct+ndFwHACQpHIHBEHkgMS9jDS6LFjW6MDKJifeu7UDAHBgFqyZ0aAs7qkUiTtBEPrQHqpl5r/vuARmg4RljU7YzQa83jOBd2xuK+s1KHInCKIQJO5lZl2rR/O7e1Yi97GQErmTuBMEkQOyZWaRDYu9ONzrL/sWfCNC3GnvVoIgckDiPotsavcgkkjhaH95SwGrkTt57gRB5IDEfRa5crmcpvjC8fKWWiDPnSCIQpC4zyKNLgs2LPbgT8fKu3m2mi2TLq/dQxBE7UDiPstct7oRu7vHMBFOlO2cFLkTBFEIEvdZ5prVTUhzYNuJ8lkzlC1DEEQhSNxnmYvbvfDaTfjTsTKKO0XuBEEUgMR9ljFIDFctb8BrZ0bKcr50mmNMsXgocicIIhck7nNAq9eKEWUSdKb4owlV1ClyJwgiFyTuc0Cdw4xIIoVIPDXjc42GJjsJypYhCCIXJO5zgM9uBjDplc8ErbgnaRETQRA5IHGfA+ocsrhrhXm6iHO4rEakqfwAQRA5IHGfA3xlFHcR/Te5LOS5EwSRExL3OUCIezlsGVE0rNFloWwZgiByQuI+BwjPvSyReygOq0mC02Iiz50giJyQuM8BbpsJEptcWToTRkMJ1DssMEqMIneCIHJC4j4HGCQGr92s1oSZCWPhOLx2EwwGhiSlQhIEkQMS9zmizm7CWGjmxcPGFXGnyJ0giHyQuM8RPoe5LJ77RCQBj80Eg8QoW4YgiJyQuM8RdXZzWbJlJiJJeGxmGBhF7gRB5IbEfY4oR+TOOYdfidyNBorcCYLIDYn7HFHnkCN3PoNVpdFEGvFUWrVlKHInCCIXJO5zhM9uRiLFEYwlp32OiYg8IeuxmWCUJBJ3giByUlDcGWMPMsYGGWMHczzvYYz9ijG2nzF2iDH2wfI3c/6jrS/zx6ODiCdLT2Mcj8i2DkXuBEEUopjI/SEAN+V5/qMADnPONwG4FsA3GWPmmTettvA5TACAp/b24oMP7cS246XvzCT2YZUjd8pzJwgiNwXFnXO+DcBovkMAuBhjDIBTOXb63kONUqeUIPjJjm4AQCBWes671pahyJ0giHyUw3P/NoA1AHoBHADwSc65bkjJGLuHMbaLMbZraKh8e4rOB0TxsAF/DIA8OVoqmZ47ZcsQBJGbcoj7jQD2AWgFcDGAbzPG3HoHcs7v55x3cc67Ghsby3Dp+YPw3AXRROm7MmVG7hI4l/dUJQiCyKYc4v5BAE9ymZMAzgC4qAznrSlcFiOMEoPDbAAwvcjdH0mAMXmjDqOBAaB9VAmC0Kcc4n4OwA0AwBhrBrAawOkynLemYIyhs8GBt29eDGD6kbvbaoIkMRgkWdzJdycIQg9joQMYYz+FnAXTwBjrAfAlACYA4Jx/D8BXATzEGDsAgAH4O8758Ky1eB7z1Eevgtkg4ec7exBNTk/cPTY568bAROSeBmAoZzMJgqgBCoo75/yOAs/3AnhL2VpUwzgt8u22mCTEpjmhqoo7Re4EQeSBVqhWAKvJMG1bRog7ee4EQeSDxL0CWE3SjMVdRO6ULUMQhB4k7hXAajRMM889CbeI3CWK3AmCyA2JewWwmgwlT6hqy/0CgEGS3zry3AmC0IPEvQLYpuG5RxIptdwvQJE7QRD5IXGvABaTVLIto12dCmizZah4GEEQUyFxrwDTyZbJFneK3AmCyAeJewWwmgyIlVjPXZT79dozI/dkisSdIIipkLhXAKux9FTIKZG7gRYxEQSRGxL3ClAOW0ZiZMsQBJEbEvcKYJ3GhKrYe9VllUsYGCkVkiCIPJC4VwCR58558cIsPHqLUS4SpnrulC1DEIQOJO4VwGoygHMgnipemMWG2ibFaxeeO2k7QRB6kLhXAItRvu2lWDOJVBoSA4wG+W8pcicIIh8k7hXAapKtlVgJk6rxZBpm4+TbZaSSvwRB5IHEvQIIcS8lco8l0zAbJt8uAy1iIggiDyTuFcBqUmyZEoqHxVPZkTtlyxAEkRsS9wpgNYrIvXhxT1DkThBECZC4VwBhy0TiM4ncqXAYQRC5KbiHKlF+Jm2Z0lIhteJeztoyR/r8eHTHORwbCOCBu7aoe70SBDF/oW9xBZicUC0tW8akY8vM1HP/0faz+OIvD0Gspzra50dXp29G5yQIovKQLVMB1Mi9FHHPYcvMxHN/4MXT+MenD+H61U144q+vAACcHwtP+3wEQVQPFLlXAFFCIFZCKmQ8x4TqTCL3x3f3YHOHF/e971K1kzg/Gpn2+QiCqB4ocq8Aqi1T4VTIQDSJzgYHjAYJVpMBjS4Lzo8uzMh9//lx7O4eq3QzCKJskLhXgGnZMtmRexnquQdjSbitJvX/7XW2BWvL/OuzR/FP/+9wpZtBEGWDxL0CTGeFaqLMnjvnHMFYMiMzpt1nX7C2TDCWxFgoXulmVIRUmuNrzxxBzwLt2GuVguLOGHuQMTbIGDuY55hrGWP7GGOHGGMvlLeJtYfJIMEgsdIjd51UyOnmuUcSKaTSHE6rRtzr7Oj3R5EsoVplrRCKJTEWXpjifm40jPu2ncYfjg5WuilEGSkmcn8IwE25nmSMeQF8B8BtnPN1AN5VnqbVNvJWezOYUJ3hTkzBqLz5R2bkbkMqzdE3EZ3WOecz4XgKgWhyQXZsolMLxUrbHYyobgqKO+d8G4DRPIe8F8CTnPNzyvHU/ReB2LCjWOKpNEyayF2SGCQ2fc89kLWzEyBH7gAW5KRqSLkfYjvDhYSwo8Q9IGqDcnjuqwDUMcb+xBjbzRh7fxnOWfOUuo9qduQOyBkz5Yzc24S4V7n3eqBnArf+94uYCJdHiDnnCCulIMYXoLiPCnGPk7jXEuUQdyOASwG8FcCNAP6RMbZK70DG2D2MsV2MsV1DQ0NluPT8xWKSSstzT6XVTT4EkjQ1co/EU7jx37dhd3e+wZZ2T9bJbJkWrxUSm3mu+0gwhqf3XZjROQDg+EBA9/Hd3aM4eMGP7adHZnwNQL63opMcX4C++7jSSYbJlqkpyiHuPQCe5ZyHOOfDALYB2KR3IOf8fs55F+e8q7GxsQyXnr9YjdOI3I06kXtWbZmhQAzHBgIFc7YDOpG7ySChxTPzdMgn91zAJx/dp0aE0+FAzwTe8u/bsPfc1NcxqohRoQ6sWLSiNl6m0cB8YlTp0IIUudcU5RD3pwG8gTFmZIzZAWwFcKQM561prCapaM89mUojzZFRWwaQM2ays2XiKfmcI4qw/nTHOXzzd8emnDOo47kD8qTqTD13f1QWyJmI+4BfntTVm9wdDcUAADvPlmfRkdaOGFuA4i489zB57jVFMamQPwWwHcBqxlgPY+zDjLF7GWP3AgDn/AiAZwG8DmAHgAc45znTJgkZ2XMvzpZJKNH51MidTfHcY0qlydGg/IX99et9+NX+3innDCgCnF0BcsNiD/aeH8czB/qKapseYlQwE4tDCK7eBOdYSH7s4IWJksom5yIc10buC8+WoWyZ2qRgbRnO+R1FHPMNAN8oS4sWCFaToejMjLgi2NkTqgaJIc257rEiah4KxBBUvrTJVBoPb+/GX17eoU6oOrLE/dNvXo3d3WP41KP70Oy24NIlpVeIFOJeahQ8EU4glkyhyW1VRxZ6NslIKAaD0rHtOz+OK5bXl9xGLdoskYVoy4jOkiZUawtaoVohrCapaM89plgtupF7Sl/ch4W4B2MIK1/aXd1j+Or/O4yXTgwjGEvCYpSmnNNmNuDBD2yBw2LAT147X/oLAxCMyWJRyqKgdJrjfQ++hr/68W75HNH8kXvXkjr5NZ2due+ujf7HIwsvch8NUypkLUJVISuEPKFanC2TM3I3sCnZMvGUiNxjSKTSagSfTnM1oh7wxxCIJTMyZbR47WasbHJNe2J1OrbMU/su4PWeCSz22gBo886nnmM0HMfmJV6MhxPYWYZiXyGNuC9Ez128T6EyWFxE9UCRe4WwmAyIFTmhmttzn5rnHtd47iPBSWGMJFKqYA4FYghGk1MmU7W01dlwYWx6KZH5LBU9IvEUvvFbedJXTMYKKyk7cuecYywUR53djDUtLpweCk6rjVrEyMZrN5Utdz6bPx4dxI9e7Z6Vc8+EdJqrHRpF7rUFiXuFkG2ZEiN3o162jP6EaiieyigEFYonVdEdDESnFA3Lpq3Ohr6JCBLTWI4fLNFz/83BPvRNRLGlsw7BWBLpNM+5YtQfTSKZ5vA5zHBajWURJDGRuNhrm7X6Mo+81o3v/vHkrJx7JgSiSbnGkMWIcDyFNG24XjOQuFeIUlao5rJl5GyZtO6xAHC0f3IRUCiWGbkHoon84u6zI82B/mnUmfGXaMsI6+iKZfXgXOmI4vrRvzjW5zDDYTGWxUoQkXur1zZrE6pj4YTqbVcTojNrq5PtsEgJay+I6obEvUJYjQYk0xy3/OeL+Noz+ZcFiNx1UxGRu1bcj2WIe1IV98FADIFoMqMiZDbiyz6dnPdSJ1RFKmKj2wpAjiZzTagKca9zmOEwGxFPpqc1utCijdxnKxVyPBxHNJEuS+pmORlVxV0uPUHWTO1A4l4hLl/mw6Y2D9Kc475tp3GodyLnsfGk4rnrpEJOyXNP6Yt7OJ5SfWw5PTIJV57IXRQR6ynRd0+k0qrdVLTnnkjBZGCos8sTvIHoZEeU7YELca93mGE3y3XxZ7psPhyXM4fqHWaE4qmMDrJciHtRbWWFxQIm0ZnTpGrtQOJeIbYuq8fTH7saP/urK+CxmfD1Z6euIhWIDJhiPPdMW8av/h6KJ7NsmfyR+yKPXGem1A0cRMQNFC9kkXgKNpNBzd4JRBPq/EAgllmGV4hRnd2s2kozzc8OxZNwWIzwOswAyp8OyTlXC5LNZNXubCDmRVRxp8i9ZiBxrzAemwkfuXY5Xjg+hNdyFMISgp1dOCxfnjsge99K2XeEYpM+djyVxkQkkTdbRtSZKTVyF6Jc7zBjLJwA54Un6CLxFGxmg9qeQDSZIdh+TYchyirUO82wK+IenqG4h2Mp2M0GeG1y51LujBm/MmkJVHPkPje2TLV1brUMiXsVcNeVnQCAV07lF3f92jL64m5S9lht9cgRWVgzoSpwWvTz3AVt09hTVeS4t/vsiCfTRU3QhRMp2M1GuBVx90cTCMVScCi2i9Z3HwvHYTFKsJkM6vPBGdoyoXgSDrMRXsUWKneuu9bHHw3FkUpz/OS1c7Ni/5TKaDgOo8TQ7LYAyBwFPfTyGRy8kNsuLJXXTo9gyz8/h+6RUNnOSeSGxL0KsCpCFYjqR02JHLaMUZKQyi4/kErBIDHUO+Qva2eDEpEptozYexVAXlsGkKO5UiN3UbOm3SdftxihjMSTGbZMMCZPqC5WrIJscax3mMEYU0snzLTgVTiegt1iQJ3dPOV65UB7D8bDCew4M4q//8UBbDte+bLX4+E46hwai0vpKE8NBfHlXx3Gz3dNb5WyHqeHQ0ilOU4MzHxtQjmIJlL4yq8O1Ww9IRL3KsFlNanCmE2+PHe9RUxmgwSf4h8vqXcAmJxQ7ai3T14zz4QqIEfu/f5oSRGmsGXaFWEuZtPpSCLTlhkNxhFPpdXVqtrIfTQkixEAOMzCc59h5B6TI3ePYsuUOx1yLKtzujAeUX8vBc55SWWii2E0FIfPPmlxidHdY7t6ABS3M9WBngk8e7C/qGsBQN9EdWzCvvfcOH7w8llsOzFc6abMCiTuVYLLaswZuYsMGL089yklf5W67/VOWQAXe20wGZiaCrmswaEemy/PHZDFnfPSvoxC3DuUyL0YcQjHZc/bZjLAIDH0K+V+ReSeLe6i47JbZFtmpj6xuL7oNMrti2sjw7FwHH1C3Eu8zpN7LuCKrz1f1nTKsVACXrsJTk1HmUyl8eQeWdz9Rbx/X//tUXz2sf0F51eEuPdWcI/e/37+BO5+eCcAYDgol44eDsQq1p7ZhMS9SnBZjQjECkTueqmQ2ROqKUXcFaFqdFpgNxtVcW92W2E1yecpxpYBSkuH9Gs8d6A4oYzEU7CaDGCMwWU1qgunWnNE7kLcS82WOTkYxJ+OTd3iV2TLOMwGGCWmlkAoF6LqYp3dhNFQHL1KZ1nMqEbLyaEgxsIJnCpDyQW1bWG5lIPoKMOxJF48MYzBQAxmo1Swc06lOfaeG0cgllRHJLlQI/cCx80me8+P47UzcrE5VdyDJO7ELCLbMiV67jqFw2KqLSN77o0uCxxmA0LxlFpyoNFlUa6ZX9zbfaUvZBKpkCJPvijPPZFSc9ZdVqO6QYdqy2jOIerKACg5z/2+F07h/3v89SmPi2wZ0bn4I+XNGBkPx8GYbJGNhePoHZdfX6m2jLCLTg6WT9zHIwnUOUwwGeQKocF4Er/a34s6uwnXrGosKO7H+gPqaO1IXwDpNMcTu3t06yaNVEHkPh6OIxBNIhJPkbgTc0M+Wya35y7pZstYNLZMg9MCu8UIfySBWDINh8WIJpe8EtRVIFtmkdsKg8RKityDsQQMEsMij3yN8SIETNgiok3CBvLYTHCYDWqOeCyZQiCWVEcldsVKCBZpy4xHErpReTieUidn3TZT2SP38UgCHpsJDU4zxkIJ9fWVKu6iQuaJQVlEv/T0Qew/Pz7tdnHOMRFOwGMTcxgGhGMpHBsIYGObFw1Oc0Yaqh7arQ6P9vmx7cQQPvPYfvz69ambvYxVgecuOsjBQFQtrDc0i7bMc4cHyj5PUiwk7lVCoQlVg8Rg0GS6APo7MQnPfXmjAxajhLY6GxwWIwaVD7DDYkSjU47cC9kyRoOEFo81YyFTMpXGu773iq69AcipkC6rEWajBKfFWFTkHlVsGUDu5MTfuKzyJKeIHsUXUyw2MkgMNpOh6Dz3QDSBaCKzXEEqzeUJXeX6bqtJ9Zl/tP0s3n3f9qLOnY+xcAJemwl1dnNm5F6i5y5e/4mBIE4OBfHw9m48f2Rg2u2KJFKIp9JqCqjDItt3Z4dDWNrggNtqKhi57+4eQ5PLgg6fHUf7A3hJmZw81OufcqzozPonohUrUCZswsFATBO5z062zImBAO7+4S78Yu/MN4ufDiTuVYLbaswZJcVTaTVvXYvE9Ou5m40Sbly3CK9+/galBotBjU6cFgOalJxmh+Kz5qOtLnMh00gojp1nx/Dqaf1NMoLRyWqTXrtJnUzknOsWIeOcK3nuQtwnRxMOixFum0kVNfFTlCkQr6HYbBkxMtJOwIo8fHEv3LbJ92HvuXHsODM640h+PByH126Gz2HGgD+qjjRK9dy1tswOxTcuFFnnYyzrfjrMRpwZCSEUT8nibjMhnkznjTx3dY/h0iV1WNPiwpE+P146KYv7YR02UQ8WAAAgAElEQVRxHwnFYDcbkEjxilgh6TRXO6sBfxRDiqjPVlsO98n34GyF8vpJ3KsEl1UugqXnVYr0xmxyVYU0GyQwxtTsD7vZqIq7w2LEdRc14daNLbAYC4t7e509YyFTIZ8yoCklXGc3YzgURzSRwmce24/Lv/Y8jg8EMo6Pp9JIpbkmcp4cTYiFRX41cp8sPSAQk8XFIMRda3+JHHlh8Wgjd2EHnR6a2ZdTnrQ0oc5hhuiLG5zmaXju8vFnR0JqhFxMNouWiUgCn3vidQSiCfV8wpaxWww4oghSZ4NDTQ3NdY0BfxQ9YxFcuqQOFy1y48xICEf7AzAbJBzu82dkz4TjSUQTaaxtcQOojO/ujybU+z/oj6lZMsPBWM5Mn5/vPI/PPrZ/WtcTn/We0crYUCTuVcJkXZWpQiVH41OFWHcnpmQaFlPm2+qwGNT6NA6LEdetbsK337u5qHa11dkx4I+pnY4QpFziHowm4VZeS7Pbgm3Hh3DpV3+PJ/fIQ9MBf+aXOhqX22VTxFU7yeu0yLaMqPUixFaIjng9xW7sHFA3Apm8xyLqVyN366TnLsRvphuCjIUSqLOb4dN0SmtbPfBHkyVVtByPJNDksiDNgecUO6bUUcWec2N4dOd57OoeUyeqhS3jtBjVom/LNOKey5rZreyC1dXpw5oWF4Q+vv2SxZiIJDIEXHxu1i/2AJiaMXPwwgQ++9j+KZ/ncqK1CIUtYzFKSKR4ztf46wN9+PU0N4sXhfumu6PZTCFxrxK0dVWyEZOk2eh67qmpUb6ISoHCue3ZiIJSwicuNAkViCVUL/9f3rEB/3T7Oty4fhE+/eZVADBFiMMJETnr2zJem1njucvX9mptGXNxnjvnk9sMZoh7duRum8yWETbITFMPhS2jbff6VnfGNQoRS6YQjqewZam8Ybl430vN7IkpFstwIKZ2lqJd4j0wGyS0em1wFxD3XWfHYDFKWNvixholIvfaTXhXVxsA4JCmdIEQ93Wt+pH7Q6+cxWO7e9A9EgLnHP/yzBHsOTfzLRS1aNcbnB4KIpZMY1WzC0DuYOXUUBDheGpak6LHlMh9OmWzywGJe5WgrYiYTTyp77nnqi2TnVXj1HjrDvP0xF1Mqo4UEbmLDqTJZcX7r+jEt959MW6/uBXA1AVHYkGOTTOhCsiZQWajBI9d9tw55xrPXWPLWIqzZSKJlCqI2sqVopa8Q2PLRBJy2V+tLTMYiGLLPz+H7Tnq/+QinkwjFE+hzm5S8/MNEsPqRbKoFLtgSgjsJe1eiHn1pQ2OohaJaRFzDEPB2OQEtciWUd63dp8NBolN2jI5Rge7u0exqd0Ls1FCe50dLosRV61owNpWNxib9JyByc/NskYnrCYpI3JPp7k6QX9mOISRUBz3bzuNx3f3lPTasnl0xzk8o4m6xes1GZjatouU92FQJ1iJxFNq7v6IjoX2+ScP4BM/3at77VAsifOjEbiVBIFiM7rKCYl7leAuELlnCzYgVqjqiXumhTOjyF1ZjHRe8Q1HFFEfCcZ1Mx6CMf29WR05FhwJcbVlRe6infUOM2KKQI5HEjAZmBphyscVN6Gqva+BDFtGidzVCdXJaFVEeqeGgvjT0SEMBWLYdVZ/IjkX6mjDYVbnQJpdFjVjaTQUx9P7LuDZg/mH/sJCaXZbsaTegTq7CZd0eEu2ZSKKDTYciKt2l1czoQoASxucAJDXlonEUzjU60fXkjoAgCQxPPShy/APb10Du9mIpQ2OjEnV0eBkHf5Wj01dywAABy5MqBkrZ4ZDah7/iaz5mVK5/8XT+LFm31rRkS5rcKpJAmLEoZcxc2Y4pFpNozrP7z03plpT2Qi//bqLmgBUJnonca8StJH747t7MiKCREpf3A06G2THdCZftVkxxWTIaFnktsIoMTVyF8PrZHqyRrkWf4468UKssyMYEUlmR+6inQ2KCA4FYhgPx+GxyUXDBHazsajCYdoRUUbkHsuK3G3yz97xCNJc3uv27HAYfzgqR5ZnR0r7kmozUoTn3uq1TZY6CMXx9WePqRuEFzqPsD0+eNVSeG3mkidUxf0eDsYwEU7AYpTUNFTRAS9Vis2JgEOvBPL+nnEk0xyXKuIOAJcuqUOLUoV0bYs7I3IXwupzmtHitaqrdAHgD0cHwZj8GTg7MinuxweCGROdn31sP773wqmiX+tIMJ7hs4vfVynROgBc1KLYMjqRu9aOGwlNfX4wEEO/P6o7TyDE/YY1zQBI3Bc0LrXcbRLPHxnAL/f3qkKq56MDOSJ3nY5AG7k7SozcDRJDq3cyHVIb4WRbM7GkbGfoFSSzGCUYJDZlNamwZbQrVIFJsRWraYcVG0GbBikfZyhqyKtNGQxqyjyokbt5ckIVAM4pX8aNbV7EU2l1ArPUcrXaDB+3zQSJAS1em2rRnBkJ4cJ4BKeGQuqoqNB5PnLtCnzihpVw24xqLZhiEd6x3FkmpsxfAHKmDDA5itFLtxQRq1bctaxpcaNnLKJaZiOhOEwGBpfFiFaPDRc06bV/PDaIS9q9WLXIlRG5T0QS6udtKBDD43t68FiBKpXiHsaT6YzRFyDfQ4kByxsn6yutaHTCZGC6NqNW3LMzm2LJlFq+eTAwNfPnWH8QVpOEK5fXAwDOl1hdtRyQuFcJbk22TK/i8+07L3+BYsn0lFruwKTnro1u9CZfRRRslJjuxGwh5Fx3EbnH1M4je1JVTJbqWT+MyXZKthDnsmWEyAtx1xMj+bUZEY6nChat0toy2shdiI92hSowKe5CvJJpDp/DPO3I3Ws3wSAxXL2yEVctr1dfxysnJz38XEN8QD9TyJ0nwyoXojMdDsYwHomrfjsAtTLkUkXcTQYJDrNB15bZdXYUK5qc8GrmP7SI0hHCfhkNymUjGGNY0eTEoDISGw7G8HrPBK6/qAlL6+04OxzGqaGgumDvxKAcAf/h6AA4B04NhXKmkO7uHkPXPz+HAz0T6khBe+xYOA6PzYQWZfU0Y/JG6/UOi26CwKmhkPo+ZV9Te/wFHeE+PhDAqmYX6pV1JhS5L2CcqueeUCdx9nTLS8vzee4AMqL3WDI15VgRBTssxgxLo1jkTTsmJ5ZWNsmebHa0I6wPbcaLFqfO5Gc0y5ZxWyfbCkzaMsPBmPLlzBQTh8WIZJojVqAssdaW0Xruvzs0gEaXRRVNNXJXRPzSDsVTZsC7Lm3DcDCWcyVxNv0TUfzn8yfk7BPFrvjhhy7DX1zWAYvRAKfFiB2Kh2+QGHblEffstEVAG1kn8Mhr3bjzgVcLrvyMZk2oas/X4bPDapLUDBJxjWxxT6c59pwbV++NHkJAxcK1EU3BN+FzH+7zY4/ymq9YXo+lDU5cGI/gcK8fW5WsIBHF//7woPp5z9UJPnuwD5wDJ4cCalZXLDm5Kbk88jOr5Td8djOMBgkNLrN+5D4YxKY2L0wGNmVCVZvSm10wbSQYw67uUWxq84IxhnafvTrFnTH2IGNskDF2sMBxWxhjKcbYn5eveQsHg8TgMBswHIypQ9G9SuSeSOmnQhqUDJqDvX78bOc5APoLnoRQljqZKmivs2MoEEM4nsRoMK5megwFYkiluZqrLaKb7Oha245cE6p2Nc99cik8IEdWEpOvNRGZassIOyUQTeLRHefw7ME+DPqnDpNFdGuQmNrB7Dgziu2nR3DvNcvVSFF47iJyX9ooT15ubPPi4nYvAKC7iOg9lkzhXfe9gnMjITxwV5fqsWupc8grQJtcFlzS7s07WTsekXdM0r6H6s5VkSReOTWCl0+O4MWT+WuTC899PJzAUDCW8V69aU0TdnzhTWqHCsgjhWxffzgovxfrFrtzXkd4771qHZ2YWu9IiPuRvgD294zDIDGsbfGoG8uMhOK4akUDXFYjTgwEEYmn8NLJIfz5pW0wGRh2devfJzEv0j8Ry/DIRRQvOjMxGhSvs9FpmTKhmk5znB4OYnmjE3V285QJ1QH/5PlFmrDgh9u7EU2kcdeVSwDIa0UqketeTOT+EICb8h3AGDMA+FcAvy1DmxYsLqsJx/vlSMVjM2H/+Qmk0jxn5G5QovAHXjyNf3zqEJKpNNJ8aoExIYClTqYKViqR3MELfgRiSSytd8BskDAUjOHffncMt337ZQCT6WQiMspGb8GRyFHPnlAV9cUNEoPPYVE9dz1bBpB92889eQD3/ngPbvjmC1MEXkTbzS6Lag391/Mn0OC04L2XdajHZXvuXpsJX75tHT5/80XqxifZ4j4SjOHuh3dmeObnRyM4PxrBl962Dm9c1ah7P8QE69pWNy7trMOBCxNqZD0YiKqrRYFJYdKOvLSR+4ASIf9o+1ndawm02x6eGwln2DKMMfX1a6+RHbmLKFbbCWTT7JGfE5H7mBI1A7LV1uC04GifH6/3TGB1sws2s0G1gwBgeaMTK5ucODEYwEsnhxFNpHHrxlasX+zB7rNTI/fukRBOKSuJB/yTRcHka8fVn167WS2/0eCaLK6Xbcv0TkQQTaSxvMkBn8OcM3I3GZhqowKy7fXD7WfxpjXNWNEkf2/afTacH40UtZ9wOSko7pzzbQAK5X99HMATAPSrSRFF4bIacaRf/kLftG4RgrEkTgwGlNoy+p47IHuD8VRaFa0ptowl0+ooFZEL/MopOSpscFlQ7zRjOBDHc4cHcKzfj1Saq18Q8eXJxmE25LZllA7IbpY37NC2tdFlQc9YBJFEaorHKywnEfV+587NCMWTuH/b6YzjAtEkJAY0ua0IROXiWC+dHMbdb1iqXlt7/V5NZcrbL16MrcvqsUTZxSq7Vsjec+N47shghq0i7oVYJ6CHiObXtrixZYkPiRTH/vPjSKc5/tfDu3DPj3apx46HExl+OzDZEfkjCQwEomAMeP7oYF4LQLsYJ5nmOUdZ2mtki7uoiVOXw28HAIvRgAanWa0AORKMqdU8AWBNiwuH+/zYf34cm9rlVaudGnFf0eTEyiYXjvUH8B/PHYfXbsJlS33oWlKH13smpiwqElG7y2rEgD+aYbNoaxN57SbUOyyQmCZyd1kwFIzhn399WE3fFB3F8kYn6p1mjGZlywz4YzAZGFY0uTJsmcf39GAsnMC91yxTH1va4EAkkcKLc7zj04w9d8bYYgBvB/C9Io69hzG2izG2a2io8vtHVhvasr+3bmoBIAtHvtoyAHBmWI72xdBy6gpVWbyma8t0+OywmQzq5J/PYUajy4LjAwGcGAwizeWh+lAgBsaQ8SXW4rAYdSdUjRJTOyTGGP7p9nV4z5Z29ZhGl0X1XrMFTuSn7+4eQ4PTgls2tODPLl6MR147lxFJB5TFVS6r3IbsCVOBqOnOufx+GDX30qHUwj87nCnuorqjtjCaEBdhAeihjdy7OutgMjB850+n8Mv9vdjfM5ERTY5H4lM6NmEhTUQSGPDHcOvGVjAAjyoWnR6ReAraaRdPAXH32KbuMyCiWGGz5KJFyWePJ9PwR5PqHgOAbM0c6vXDH01iU5tsd7mtcllko8SwpN6Olc1OjIUTONLnx7fevQlmo4SuTh/iqTS+v+00th0fwm8O9OHpfRfw1L5eLGt0YMNiDwb80SkTqeJnnd0Mg8Tw1o2teONKeUR1y4YWXNpRh4df6cbf/+IAAKijptXNLvgcFt3IvcllxWKvLSNy33lmFIu9NnR1+tTH3n7JYqxuduGjP9kz49z9UijHhOp/APg7znnBlSSc8/s5512c867GRv2h6kJG+M2MAVuX1sPnMGPvubHcee6K8Ih6IOIDPXWFamZ6YalIEsOqRS51DqDBaUaD04IDmuXl/RNRDAbk6Myo0xGJdmR77tpyu4I7ty5RfX1xPZF1kR0titd2aiiENUrO8keuW4FoMoUHXjqjHuePJOCymmRxjyZVIV7knmohiYhYL6rtrLdPsWUm65RPirsQ5nziLiL3da0eeO1mfPm2dXjh+BD+VilUFU1MVmQcV8oGZ7RT+f/5sTDiyTQubvdiQ5sXe8/lrvEeTaTRonnNXlt+gfbo2DJjOgXc9FjksaJ/Iqp2zMJTB6C+V4CcbipY1uDE0gYHTAYJG5Q6NF+8dS2uv0jOF9+61Ic6uwnf/P1xvP/BHfjrR/bgk4/uw/7z47hp3SIsclsx4I9hJBhXV3WPhRNq+QYxZ/Pfd1yCd14ql0lYv9iDn997Be66cgkO9/mRSKVxqNePVo8VdQ4z6h16nnsUzW4LFnutGZF792g4w14C5O/1/3ygCxajAXf/cNecrVad3rc9ky4AjypeYAOAWxhjSc75U2U494JC+M3NLivMRgnrF3tw8IJfXpiUJ1tGICLVXHnu07VlAOCiZpe6MYTPMbnCUtDvj2IoEMvrwzosBt08d60toodWILMFV7taVdhHK5qceOuGFvzwlbP4qzcug9cubzrhshrhVEYPYp9WPQtJRMR64tVZ78ALxzNHnSLdsV+zMGcoKA/bs0caWrYu9eFovx9LlFXAd25dghMDQTz0ylm8dUMLfn2gD+PhBBZ5DBgPJzI6PECel2BMXuwDyIXaVjQ68eKJ3KPiSCKFNp9dre1S0JaxyfcrmUqrnXahiXNBi8eK106PqIuZRF0ZYHJSVc7OcaqPf/Fta9UidZct9WH7569XJ2fla5qx8wtvwoXxCAYDMTgt8t4BnMsd77/97jgGA7Its6TegZODQYyF4ppso9wd0oY2L+LJMzg+EMDh3gmsbZU7F5/DjEAsiVgypVZSHfBHsXqRC61eGwLRJPzRBNxWE7pHQnjrhpYp526rs+O7f7kZ77lvO7741EF86z0X57135WDGkTvnfCnnvJNz3gngcQAfIWGfHiJyb/XKkdW6VjeODwQQTaR0bZnszTuGlS9ddmaN2SjBZGAZNWZK5SJNpFXvNKuTUauVydYBfxRDgWjeSNVh1rdlCop7VvZG9jnVNi6aFI+PXb8CoXgKD758FoA8oeq2muC0mOTI3R+Fz2HWLXssInc9Ye5scGAwEMNBzaglV+Te4LTkTT19y7pFeOTuyyFp3scvvW0tXv7c9bh1oywQIkqWM4UyhUmS5EVBIjJe5LaqOeS5yhJEE3L0KhaaZY8GshH3QGvNjIbkfHG9eSAtLR4b/NEkdp0dhdUkqWUNADlCNxkY1rd6MkZ66xd7cOkS2dJgjGUIu8BokLCk3oEtnT6saXFjeaMTK5qcMBokNLstSKQ4Tg4F0eKxKhvGxDUrhfOIuzJS2HFmFKeHQ2pn5FNXE2uqSvpjaHJZ1X1+e8cjmAgnMB5OqHMz2Wzp9OHj16/Ek3sv4Kk52MCjmFTInwLYDmA1Y6yHMfZhxti9jLF7Z711CwyR2iY+MOtbPUimORIpXlTkPprDcweAj1+/Em/b1DrttomoUawyFBH6zRsWwWRg6J+QI/dcmTKAPHKIJdMZKyr1bJlstB1GdkqhdjSi7YAuWuTGjeua8YOXz8AfTSAQTcJtM8JpNSIYT6JvPIJmHUsGmBR3PSF428ZWtHiseOd3X8FvlKJUqufuz/Tc83V0uWCMYbHXpnrh4+EE4kl5slxPiN02k7pqttltVVdfnsqxz6q43w1K24rx3IHcm5TnQ+S6P390EBctcmcEI2ajhLuu6MQdmkylciBstu6RMOodZmXDmITaSeYbbSzx2eGyGvHzXT3gfHKkIeaQRHplKJZEQNlsfnHdpLh3j8rvg8iq0uPj16/AG1c1zmppY0HBcTrn/I5iT8Y5/8CMWrPAEbaM+MBoh7HFRO7iw6fXEXzihpUzapuIiusdloyI6srlDXhsV48s7gUETS0eFkvBY5fbGNHsn5oLbeSeLXDa1bcrmpwZz338+pX47aEBPLG7B4FYAi6rCy6LPFl6ejiE5Y2ZxwuELaMnBB31dvzq41fjzu+/hm/+/jhu3tCSEblzzsEYw1AgpuvnF4vwwicicVVY9drjtprQw2U7qNFlQTwlv6ZTQyFcoiwy+sPRAQRjKdy2qVW1wRqdFpwZDuW1KcT55XZkinv2egM9hLgPBWJ4y9rmKc//w61rC56jVJo099znsKhbG+qVi85GkuSRxPbTcuLAusWTtgwwaUeJNMhFHou6EvfCeFRN880VuQPyqOPhD26Z1mLCUqEVqlWEsGXEB6bDZ1eHz/qRu/xYu08+XuT26h07U3wOM5pcFvWDfsOaJvzgA1uwpbMOTW4LjvYHkEhxNOURd2ELBTWTqpFEYVtGRJnZFSEBOT+eMTllLdtiWb/Yg7Y6G3aeHVX3dhUrgc+PhgtG7rksiwanBVcsr1cnZUXkHk+m1eF/ofmHQtQ55GuPhRPqxtgeHSGenB8wwWoyoMNnh8nAMuqi/N8/nsK3/3ACgHy/LUaDaqsVEmkhhtrSxHLkXvi1aS2VdYp/PduIjdkB2T702k0YCyfUqqZ6No+WjW1yOz02E1qVc4msoElxl4OoZpcVjU4LHGZ5Bysxgurw5RZ3AHMi7ACJe1UhInexVF2SGNYo0Xu+PPd1LfIHUo3cC3ih0+Xm9YtwhVIIyWSQcN1FTWCMYZHbqlbByxe5i4ldbRXHcDwFmyn/AFJE7l67ecoXgzEGp9k4ZbJRsLmjDru7xybFXeks01w/UwaYzELJF9W2eKwIxpLKdnUJVch7xyNIpTlGQvFp2TICEbmPhxMYVMQkexIbgGbXK/m1mBQ/+qTGlukeCameeSyRhs1sQJPLCotRKmiJiVGkNiNkLByHz1E4chcLmQA53XMu0N6jBqcZdXYzxsNxHOydQIvHWtBOEjtFrWt1q5810ZGJ4EkUCmtyWyFJDFeuaMC240M4OxJGk8uSUaivkpC4VxHLG50wG6UM73i9EvHk89xXNMkbIMxm5A4AX7l9Pf5RZyjd7LaqpYfzR+5Ty/5G4smCkbvHZoJRYjkj6f/99vX4yHXLdZ/b3OHFgF8uk+CymjLKES/y6LdVzH3kG8KLCLF3PIrxcFwVr/6JKMbCcrXAmYi7zWyAxShhPBxXvfxm3cweuY1aO2JFo1ON3ANRubJiICpnvMRTadhMBnz46qX4zp2bC0aRzS4rzAZJXRfAOS86chcLmQwSUzOZZhuzUVI9ctmWMWEsFMehXn9Ro4cNGnEXeJVqniJyFxVSxWfgjasa0TMWwUsnhvNaMnMNiXsVsandi8NfuRFtdZMfEPEh06/nLn8xO+rtcFlN6kKL2RL3XGiHwsV67oJIIgV7gehRkhganJacYnv7xYszMmW0bNYsUnJZjRnliHPaMrbcE6oCEfUfGwggzaFu/NynWR05E3EHoE4G9qseb+6c/GbNtZY3OdA9Iue+i5z8YCyp3nebyYB2n12tNZ4PSWJyVVDF1gjGkkikeFGROyDbIMsbHWrN+LlAvK+yLSOnwZ4eCmYIdi6W1Nvx2RtX471bl6iPSRKDz2FW1y4c7Q+grc6mBivXKIuh+v3RvJOpc011jB8IlewFQBd3yAs89IRGiN2aRW64rEacUVZOTqes70zQ2htNeSYRhV8ezLZlCkTugJwJ06IjboVY0+KGxSghlkzrRO765xOinKuMAjDp3YqVjCubnDBKDP0TEQwF5M55Jp47IFszY+E4bH4DXFaj7nBfeO7a17KiyYlUmuPcaChjwdVQUO4krEXcby3tPrsauY8WUXpAy2fesgpzW1FFHuEc7gMaHJNzRGk+abnkgzGGj163YsrjK5tcar7+od4JtTMH5OBqWYMDp4dD6pqFaoDEvcpZ3ujEs596A1Y2TR3WXtzuxR8+cw2WNTrVLBAAMBvmLkoCJiMlm8mgbvigh4h0tBtaR4uYUAWA77+/C9I0JqJMBgkb2zzYeXYsw3MHgBa3/uTaVcsb8LN7Ls87jBfCL2qRNLgsaHZb0aekhAJlitwjCUiMFZz81XaqIgvo+EAwow6OmAi0ltj5t/ts2KcsYBstsvSA4NrVTSVdqxxkRu6TI4xiIvdcXNLhxf3bTmM0FMeZ4RBuy0orfuOqRlncG6oncidbZh6QnSMsYIxhmfJF1tZQr5Qt0+jKv2hn0paRxT2RSiOR4gVtGUAWab17UAyblZRAt9UIl0W+T1aTpEa92UgSw9Zl9XnPaTUZ4HOY1cjdZzery+3LKe4Tii1TaPJXa8usXuSC1SRhx5nRjJ2jxERgMZ2plg6fHRORBCYiiaJLD1SSLZ0+bGrzwG42qO30OczTGvkJLumoQzLN8fju8+AaG05w0/pFSuniuZk4LgYS9xpBG5HOubgrwpNvMhXQTqjK3m/2LkyzxbWrm2A2Smirs6t58Yvc1hmnpDW7rWqZY6/dpIr7cDBWcBRTDCJHW65joi9MIl1PW8/EYjRgS6cPL58cxtmRsDrxLrJuCmXIZNNeJzZJD6uT9sUsYqoU77y0DU9/7GowxlRx12a/TIdLFHv0J6/JRdmys38uX1aPvV9885S1FpWExL1GcGm85Ln23G1mA9xWY8FI1WqSIDE5cv/oT/bgzd96Qf372eSK5fU4/JUb0ey2wmiQ0/9yiWUpaCNBn8OMdmVThldOjaDBNTVts1Q8yoTqUCCWM7PniuX1eO7T16g19wVXrWjAicEgDl2YUNNEB6Yr7oqP3DMWntzouorFXYuwZWaaZ9/gtKDDZ8fZkTA8NpO6FkVLdi38SkPiXiNU0pYBgL9586qCS8kZY3CYjRgNx/Hbg/2os5tx+TIftmjKo84W2olqj82klniYCcKOMhsl2M0GfOiqTrR4bDjU69fNSS8Vr82MeCqNZJrn7IzEnqTZXL2iAQAQiqfU9L6BwPQmVDuU9L5zo2F1o+vplo+ea1q9NtxxWTvesXnxjM8love1LTMbBcwV8+MdIgoiskAYm1pzZi744FVLizrOYTFi99kxJNMcf/Pmlbhp/dQKerPNt96zqeBKxWIQdpRPWVzV5Lbikbu34t33bc8okjVdtKtHSx1prG1xq6mUG9o8eHTneXV3KqtOsbR8uK0meGwmnB+NIJZMweeY+ZinaN0AAAidSURBVKhkrjBIDF97x8aynOuSdi+e3tc7ZwuyZgqJe40gFt6YDVJVf/EcFgOOKatZtXW855IrlzeU5TwictcWM2v32fH8Z65RS0PMBG2mR6l1aiSJ4crl9XjmQD/Wt3rA2OQ2iNOxwTqUdEiTQarqydTZRGzAIUoUVDsk7jWC8NwrYcmUgsiYaXBaZpS9UA2okXvWgp5yLT/3aDbSmM4cwa0bW/Hq6VGsaHLCaTGqBa9K9dwBOR3ytdOjYAw5F4zVOusXe/D4vVeoBdmqnepWAqJonEqK31xPppaKqL++qc1T1SOMYhCdU6HKitNFFA+T9/ss/Rq3bGjB7n94ExwWI9xWk7pj13TEfWmDAyOhONw2E/7mzTOrMDqf6er0TTsld66hyL1GcGlsmWpGRO6b2itjyZQTYcv4ZkncRfGwRpcl59aFhRAdqNtmUot/Wc2ln+t/vWEZLltaj6tXNMwbcVvokLjXCPPFlhFlf+eLb5kPl9WEq1c0YMvS2cn2EZ77TOrCC1yaCffpBABeuxnXrKJ9j+cTJO41wnwRd7sSuVdqMrXc/PjurbN2bqvJAKtJyluvp1hEDrZc/54i74UAiXuNIPLcq13c37ymGUalyh5RmK4lPmzpnPkEnii1MB2/nZifkLjXCPPFc7/uoiZcd9HcF5Oar5RrZCAi97ksvUtUlupWAqJobCYDDBKr+sidqAyiwNhsl3ogqgdSghqBMXlJuLnE1YfEwkAscrOa6Cu/UKB3uoZwWoxVb8sQlUE7oUosDMhzryGuu6gRS3zVs1kAUT2ICVXy3BcOJO41xP/+sw2VbgJRpVDkvvCgMTxBLABoQnXhQeJOEAsAkSpbarlfYv5SUNwZYw8yxgYZYwdzPH8nY+x15d8rjLFN5W8mQRAzQbVlKHJfMBQTuT8E4KY8z58BcA3nfCOArwK4vwztIgiijIjI3UKpkAuGghOqnPNtjLHOPM+/ovnvqwDaZt4sgiDKidEg4R/eugZXryzPRiVE9VPubJkPA/hNmc9JEEQZuPsNyyrdBGIOKZu4M8augyzuV+c55h4A9wBAR0f+zZQJgiCI6VMWA44xthHAAwBu55yP5DqOc34/57yLc97V2Ei1oQmCIGaLGYs7Y6wDwJMA3sc5Pz7zJhEEQRAzpaAtwxj7KYBrATQwxnoAfAmACQA4598D8EUA9QC+o2wCkOScd81WgwmCIIjCFJMtc0eB5+8GcHfZWkQQBEHMGEp6JQiCqEFI3AmCIGoQEneCIIgahHHOK3NhxoYAdE/jTxsADJe5ObMFtXV2oLbODtTW2aHcbV3COS+YS14xcZ8ujLFd8yUbh9o6O1BbZwdq6+xQqbaSLUMQBFGDkLgTBEHUIPNR3OdTSWFq6+xAbZ0dqK2zQ0XaOu88d4IgCKIw8zFyJwiCIAowb8SdMXYTY+wYY+wkY+xzlW6PFsZYO2Psj4yxI4yxQ4yxTyqPf5kxdoExtk/5d0ul2woAjLGzjLEDSpt2KY/5GGO/Z4ydUH7WVUE7V2vu3T7GmJ8x9qlqua96W1Dmuo9M5r+Uz+/rjLHNVdDWbzDGjirt+QVjzKs83skYi2ju7/eqoK0533PG2OeV+3qMMXZjFbT1Z5p2nmWM7VMen9v7yjmv+n8ADABOAVgGwAxgP4C1lW6Xpn0tADYrv7sAHAewFsCXAfxtpdun096zABqyHvs6gM8pv38OwL9Wup06n4F+AEuq5b4CeCOAzQAOFrqPAG6BvJENA3A5gNeqoK1vAWBUfv9XTVs7tcdVyX3Vfc+V79l+ABYASxWdMFSyrVnPfxPAFytxX+dL5H4ZgJOc89Oc8ziARwHcXuE2qXDO+zjne5TfAwCOAFhc2VaVzO0AHlZ+fxjAn1WwLXrcAOAU53w6C99mBc75NgCjWQ/nuo+3A/ghl3kVgJcx1jI3LdVvK+f8d5zzpPLfqtkiM8d9zcXtAB7lnMc452cAnISsF3NCvrYyuUzuuwH8dK7ao2W+iPtiAOc1/+9BlYqnst/sJQBeUx76mDLsfbAarA4FDuB3jLHdyu5YANDMOe8D5M4KQFPFWqfPXyDzS1KN9xXIfR+r/TP8IWRukbmUMbaXMfYCY+wNlWpUFnrveTXf1zcAGOCcn9A8Nmf3db6IO9N5rOrSfBhjTgBPAPgU59wP4LsAlgO4GEAf5CFaNXAV53wzgJsBfJQx9sZKNygfjDEzgNsAPKY8VK33NR9V+xlmjH0BQBLAI8pDfQA6OOeXAPg0gJ8wxtyVap9Crve8au8rgDuQGZDM6X2dL+LeA6Bd8/82AL0VaosujDETZGF/hHP+JABwzgc45ynOeRrA9zGHw8V8cM57lZ+DAH4BuV0DwiZQfg5WroVTuBnAHs75AFC991Uh132sys8wY+wuALcCuJMrxrBicYwov++G7GOvqlwr877n1XpfjQDeAeBn4rG5vq/zRdx3AljJGFuqRHF/AeCXFW6TiuKt/Q+AI5zzb2ke13qqbwdwMPtv5xrGmIMx5hK/Q55UOwj5ft6lHHYXgKcr00JdMiKgaryvGnLdx18CeL+SNXM5gAlh31QKxthNAP4OwG2c87Dm8UbGmEH5fRmAlQBOV6aVaptyvee/BPAXjDELY2wp5LbumOv26fAmAEc55z3igTm/r3M1c1uGWelbIGehnALwhUq3J6ttV0MeCr4OYJ/y7xYAPwJwQHn8lwBaqqCtyyBnF+wHcEjcS8hbJT4P4ITy01fptirtsgMYAeDRPFYV9xVyh9MHIAE5gvxwrvsI2T74v8rn9wCAripo60nIfrX4zH5POfadymdjP4A9AN5WBW3N+Z4D+IJyX48BuLnSbVUefwjAvVnHzul9pRWqBEEQNch8sWUIgiCIEiBxJwiCqEFI3AmCIGoQEneCIIgahMSdIAiiBiFxJwiCqEFI3AmCIGoQEneCIIga5P8HAGDFyozD4F0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot loss vs iterations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(iterations,train_loss)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
